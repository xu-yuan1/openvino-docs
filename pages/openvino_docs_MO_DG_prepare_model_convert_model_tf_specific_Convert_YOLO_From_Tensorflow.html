
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Converting TensorFlow YOLO Models &#8212; OpenVINOâ„¢  documentation</title>
    
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <link rel="stylesheet" type="text/css" href="../_static/doxyrest-pygments.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <link href="../_static/css/media/favicon.ico" rel="shortcut icon">
    <link rel="stylesheet" href="../_static/css/openvino_sphinx_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/button.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/input.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/textfield.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/tabs.css" type="text/css" />
    <script src="../_static/js/openvino_sphinx_theme.js"></script>
    <link rel="stylesheet" href="../_static/css/viewer.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />

    <script src="https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-datalabels"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/chartjs-plugin-annotation/0.5.7/chartjs-plugin-annotation.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-barchart-background@1.3.0/build/Plugin.Barchart.Background.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-deferred@1"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/PapaParse/5.3.1/papaparse.min.js"></script>
    <script src="../_static/js/viewer.min.js"></script>
    <script src="/assets/versions_raw.js"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/tabs.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/js/custom.js"></script>
    <script src="../_static/js/graphs.js"></script>
    <script src="../_static/js/graphs_ov_tf.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/target-highlight.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <link rel="canonical" href="https://docs.openvino.ai/latest/pages/openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_YOLO_From_Tensorflow.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Converting an ONNX Faster R-CNN Model" href="openvino_docs_MO_DG_prepare_model_convert_model_onnx_specific_Convert_Faster_RCNN.html" />
    <link rel="prev" title="Converting a TensorFlow XLNet Model" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_XLNet_From_Tensorflow.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
      <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/logo.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="documentation.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../tutorials.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/api_reference.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../model_zoo.html">
  Model Zoo
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="resources.html">
  Resources
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/openvinotoolkit/openvino" rel="noopener" target="_blank" title="GitHub">
            <span><i class="sst-github"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
</ul>
      </div>
      
      <div class="navbar-end-item">
        
<div class="dropdown sst-dropdown sst-dropdown-navbar">
  <button class="btn sst-btn dropdown-toggle" type="button" id="version-selector" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"></button>
  <div class="dropdown-menu" aria-labelledby="version-selector">
  </div>
</div>
      </div>
      
      <div class="navbar-end-item">
        

<div class="dropdown sst-dropdown sst-dropdown-navbar">
  <button class="btn sst-btn dropdown-toggle" type="button" id="language-selector" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">English</button>
  <div class="dropdown-menu" aria-labelledby="language-selector">
    
      
        <a class="dropdown-item font-weight-bold" href="/latest/pages/openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_YOLO_From_Tensorflow.html">English</a>
      
    
      
        <a  class="dropdown-item" href="/cn/latest/pages/openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_YOLO_From_Tensorflow.html">Chinese</a>
      
    
  </div>
</div>

      </div>
      
    </div>
  </div>
</div>
        <div id="collapse-nav-wrapper" class="container-xl">
          <button id="collapse-nav" class="button bttn-prm button-size-m" type="button" data-toggle="collapse" data-target="#nav-tree" aria-expanded="false" aria-controls="nav-tree">
            Documentation navigation <i class="fas fa-chevron-down"></i>
          </button>
        </div>
      </nav>
      <div class="transition-banner container-fluid alert alert-info alert-dismissible fade show" role="alert">
        <p>OpenVINO 2022.1 introduces a new version of OpenVINO API (API 2.0). For more information on the changes and transition steps, see the <a href="https://docs.openvino.ai/latest/openvino_2_0_transition_guide.html">transition guide</a></p>
        <button type="button" class="close" data-dismiss="alert" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
    </div>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar" id="nav-tree"><form class="searchForm bd-search d-flex align-items-center" action="../search.html" method="get">
    <i class="icon fas fa-search"></i>
    <input type="search" class="form-control" name="query" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  API 2.0
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_2_0_transition_guide.html">
   OpenVINOâ„¢ API 2.0 Transition Guide
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_2_0_deployment.html">
     Installation &amp; Deployment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_2_0_inference_pipeline.html">
     Inference Pipeline
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_2_0_configure_devices.html">
     Configuring Devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_2_0_preprocessing.html">
     Preprocessing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_2_0_model_creation.html">
     Model Creation in OpenVINOâ„¢ Runtime
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Converting and Preparing Models
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_model_processing_introduction.html">
   Introduction to Model Processing
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html">
   Converting Models with Model Optimizer
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Converting_Model.html">
     Setting Input Shapes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_Model_Optimization_Techniques.html">
     Model Optimization Techniques
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Cutting_Model.html">
     Cutting Off Parts of a Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_Additional_Optimization_Use_Cases.html">
     Embedding Preprocessing Computation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_FP16_Compression.html">
     Compressing a Model to FP16
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_TensorFlow.html">
     Converting a TensorFlow Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_ONNX.html">
     Converting an ONNX Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_PyTorch.html">
     Converting a PyTorch Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_Paddle.html">
     Converting a PaddlePaddle Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_MxNet.html">
     Converting an MXNet Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_Caffe.html">
     Converting a Caffe Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_Kaldi.html">
     Converting a Kaldi Model
    </a>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tutorials.html">
     Model Conversion Tutorials
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_AttentionOCR_From_Tensorflow.html">
       Converting a TensorFlow Attention OCR Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_BERT_From_Tensorflow.html">
       Converting a TensorFlow BERT Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_CRNN_From_Tensorflow.html">
       Converting a TensorFlow CRNN Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_DeepSpeech_From_Tensorflow.html">
       Converting a TensorFlow DeepSpeech Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_EfficientDet_Models.html">
       Converting TensorFlow EfficientDet Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_FaceNet_From_Tensorflow.html">
       Converting TensorFlow FaceNet Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_GNMT_From_Tensorflow.html">
       Converting a TensorFlow GNMT Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_lm_1b_From_Tensorflow.html">
       Converting a TensorFlow Language Model on One Billion Word Benchmark
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_NCF_From_Tensorflow.html">
       Converting a TensorFlow Neural Collaborative Filtering Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_Object_Detection_API_Models.html">
       Converting TensorFlow Object Detection API Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_RetinaNet_From_Tensorflow.html">
       Converting a TensorFlow RetinaNet Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_Slim_Library_Models.html">
       Converting TensorFlow Slim Image Classification Model Library Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_WideAndDeep_Family_Models.html">
       Converting TensorFlow Wide and Deep Family Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_XLNet_From_Tensorflow.html">
       Converting a TensorFlow XLNet Model
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       Converting TensorFlow YOLO Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_onnx_specific_Convert_Faster_RCNN.html">
       Converting an ONNX Faster R-CNN Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_onnx_specific_Convert_GPT2.html">
       Converting an ONNX GPT-2 Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_onnx_specific_Convert_Mask_RCNN.html">
       Converting an ONNX Mask R-CNN Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_Bert_ner.html">
       Converting a PyTorch BERT-NER Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_Cascade_RCNN_res101.html">
       Converting a PyTorch Cascade RCNN R-101 Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_F3Net.html">
       Converting a PyTorch F3Net Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_QuartzNet.html">
       Converting a PyTorch QuartzNet Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_RCAN.html">
       Converting a PyTorch RCAN Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_RNNT.html">
       Converting a PyTorch RNN-T Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_YOLACT.html">
       Converting a PyTorch YOLACT Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_mxnet_specific_Convert_GluonCV_Models.html">
       Converting MXNet GluonCV Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_mxnet_specific_Convert_Style_Transfer_From_MXNet.html">
       Converting an MXNet Style Transfer Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_kaldi_specific_Aspire_Tdnn_Model.html">
       Converting a Kaldi ASpIRE Chain Time Delay Neural Network (TDNN) Model
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_Model_Optimizer_FAQ.html">
     Model Optimizer Frequently Asked Questions
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Optimization and Performance
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_optimization_guide_dldt_optimization_guide.html">
   Introduction to Performance Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_MO_DG_Getting_Performance_Numbers.html">
   Getting Performance Numbers
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_model_optimization_guide.html">
   Model Optimization Guide
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="pot_introduction.html">
     Optimizing models post-training
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="pot_default_quantization_usage.html">
       Quantizing Model
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
      <label for="toctree-checkbox-6">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="pot_compression_algorithms_quantization_default_README.html">
         DefaultQuantization Method
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="pot_accuracyaware_usage.html">
       Quantizing Model with Accuracy Control
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
      <label for="toctree-checkbox-7">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="accuracy_aware_README.html">
         AccuracyAwareQuantization Method
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="pot_docs_BestPractices.html">
       Quantization Best Practices
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
      <label for="toctree-checkbox-8">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="pot_saturation_issue.html">
         Saturation Issue
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="pot_compression_api_README.html">
       API Reference
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="pot_compression_cli_README.html">
       Command-line Interface
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
      <label for="toctree-checkbox-9">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="pot_docs_simplified_mode.html">
         Simplified Mode
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="pot_configs_README.html">
         Configuration File Description
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="pot_examples_description.html">
       Examples
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
      <label for="toctree-checkbox-10">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4 has-children">
        <a class="reference internal" href="pot_example_README.html">
         API Examples
        </a>
        <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
        <label for="toctree-checkbox-11">
         <i class="fas fa-chevron-down">
         </i>
        </label>
        <ul>
         <li class="toctree-l5">
          <a class="reference internal" href="pot_example_classification_README.html">
           Quantizatiing Image Classification Model
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="pot_example_object_detection_README.html">
           Quantizatiing Object Detection Model with Accuracy Control
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="pot_example_face_detection_README.html">
           Quantizatiing Cascaded Model
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="pot_example_segmentation_README.html">
           Quantizatiing Semantic Segmentation Model
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="pot_example_3d_segmentation_README.html">
           Quantizatiing 3D Segmentation Model
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="pot_example_speech_README.html">
           Quantizatiing for GNA Device
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="pot_configs_examples_README.html">
         Command-line Example
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="pot_docs_FrequentlyAskedQuestions.html">
       Post-training Optimization Tool Frequently Asked Questions
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="docs_nncf_introduction.html">
     Neural Network Compression Framework
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="pot_range_supervision_README.html">
     (Experimental) Protecting Model
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_deployment_optimization_guide_dldt_optimization_guide.html">
   Runtime Inference Optimizations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_deployment_optimization_guide_common.html">
     General Optimizations
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_deployment_optimization_guide_latency.html">
     Optimizing for the Latency
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
    <label for="toctree-checkbox-13">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Model_caching_overview.html">
       Model Caching Overview
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_deployment_optimization_guide_tput.html">
     Optimizing for Throughput
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_deployment_optimization_guide_tput_advanced.html">
     Using Advanced Throughput Options: Streams and Batching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_deployment_optimization_guide_internals.html">
     Further Low-Level Implementation Details
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_tuning_utilities.html">
   Tuning Utilities
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_inference_engine_tools_cross_check_tool_README.html">
     Cross Check Tool
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_performance_benchmarks.html">
   Performance Benchmarks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_performance_benchmarks_openvino.html">
     IntelÂ® Distribution of OpenVINOâ„¢ toolkit Benchmark Results
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
    <label for="toctree-checkbox-16">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_performance_benchmarks_faq.html">
       Performance Information Frequently Asked Questions
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference external" href="https://docs.openvino.ai/downloads/benchmark_files/OV-2022.1-Download-Excel.xlsx">
       Download Performance Data Spreadsheet in MS Excel Format
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_performance_int8_vs_fp32.html">
       Model Accuracy for INT8 and FP32 Precision
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_performance_benchmarks_ovms.html">
     OpenVINOâ„¢ Model Server Benchmark Results
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Deploying Inference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_deployment_guide_introduction.html">
   Introduction to OpenVINOâ„¢ Deployment
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_OV_UG_OV_Runtime_User_Guide.html">
   Performing Inference with OpenVINO Runtime
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_OV_UG_Integrate_OV_with_your_application.html">
     Integrate OpenVINOâ„¢ with Your Application
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
    <label for="toctree-checkbox-18">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Model_Representation.html">
       Model Representation in OpenVINOâ„¢ Runtime
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Infer_request.html">
       OpenVINOâ„¢ Inference Request
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Python_API_exclusives.html">
       OpenVINOâ„¢ Python API Exclusives
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_OV_UG_ShapeInference.html">
     Changing Input Shapes
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_OV_UG_Working_with_devices.html">
     Working with devices
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
    <label for="toctree-checkbox-19">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_query_api.html">
       Query Device Properties - Configuration
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_CPU.html">
       CPU Device
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_GPU.html">
       GPU Device
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
      <label for="toctree-checkbox-20">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_GPU_RemoteTensor_API.html">
         Remote Tensor API of GPU Plugin
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_VPU.html">
       VPU Devices
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
      <label for="toctree-checkbox-21">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_MYRIAD.html">
         MYRIAD Device
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_HDDL.html">
         HDDL Device
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_GNA.html">
       GNA Device
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_ARM_CPU.html">
       ArmÂ® CPU Device
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_OV_UG_Preprocessing_Overview.html">
     Optimize Preprocessing
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
    <label for="toctree-checkbox-22">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Preprocessing_Details.html">
       Preprocessing API - details
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Layout_Overview.html">
       Layout API Overview
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Preprocess_Usecase_save.html">
       Use Case - Integrate and Save Preprocessing Steps Into IR
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_OV_UG_DynamicShapes.html">
     Dynamic Shapes
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
    <label for="toctree-checkbox-23">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_NoDynamicShapes.html">
       When Dynamic Shapes API is Not Applicable
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_AUTO.html">
     Automatic Device Selection
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
    <label for="toctree-checkbox-24">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_AUTO_debugging.html">
       Debugging Auto-Device Plugin
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_OV_UG_Running_on_multiple_devices.html">
     Running on Multiple Devices Simultaneously
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_OV_UG_Hetero_execution.html">
     Heterogeneous execution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_OV_UG_Performance_Hints.html">
     High-level Performance Hints
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_OV_UG_Automatic_Batching.html">
     Automatic Batching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_OV_UG_network_state_intro.html">
     Stateful models
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_deployment_guide.html">
   Deploying Your Applications with OpenVINOâ„¢
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
  <label for="toctree-checkbox-25">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_install_guides_deployment_manager_tool.html">
     Deploying Your Application with Deployment Manager
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_deploy_local_distribution.html">
     Libraries for Local Distribution
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_inference_engine_tools_compile_tool_README.html">
   Compile Tool
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  THE Ecosystem
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="ovsa_get_started.html">
   OpenVINOâ„¢ Security Add-on
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="workbench_docs_Workbench_DG_Introduction.html">
   OpenVINOâ„¢ Deep Learning Workbench Overview
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/>
  <label for="toctree-checkbox-26">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Install.html">
     Installation
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/>
    <label for="toctree-checkbox-27">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Prerequisites.html">
       Prerequisites
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Run_Locally.html">
       Run the DL Workbench Locally
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/>
      <label for="toctree-checkbox-28">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Advanced_Configurations.html">
         Advanced DL Workbench Configurations
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Docker_Container.html">
         Work with Docker Container
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Start_DL_Workbench_in_DevCloud.html">
       Run the DL Workbench in the IntelÂ® DevCloud for the Edge
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Work_with_Models_and_Sample_Datasets.html">
     Get Started
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/>
    <label for="toctree-checkbox-29">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Select_Model.html">
       Import Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_Create_Project.html">
       Create Project
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Additional_Resources.html">
       Educational Resources about DL Workbench
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/>
      <label for="toctree-checkbox-30">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Key_Concepts.html">
         DL Workbench Key Concepts
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorials.html">
     Tutorials
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/>
    <label for="toctree-checkbox-31">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_Import_YOLO.html">
       Object Detection Model (YOLOv4)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Measure_Accuracy_Object_detection.html">
       Object Detection Model (SSD_mobilenet)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_Classification.html">
       Classification Model (mobilenet)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Measure_Accuracy_Classification.html">
       Classification Model (squeezenet)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_Instance_Segmentation.html">
       Instance Segmentation Model (mask R-cnn)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_Semantic_Segmentation.html">
       Semantic Segmentation Model (deeplab)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_Style_Transfer.html">
       Style Transfer Model (fast-nst-onnx)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_NLP.html">
       NLP Model (BERT)
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_User_Guide.html">
     User Guide
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" type="checkbox"/>
    <label for="toctree-checkbox-32">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Select_Models.html">
       Obtain Models
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-33" name="toctree-checkbox-33" type="checkbox"/>
      <label for="toctree-checkbox-33">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_OMZ_Models.html">
         Import Open Model Zoo Models
        </a>
       </li>
       <li class="toctree-l4 has-children">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Original_Model_Import.html">
         Import Original Model
        </a>
        <input class="toctree-checkbox" id="toctree-checkbox-34" name="toctree-checkbox-34" type="checkbox"/>
        <label for="toctree-checkbox-34">
         <i class="fas fa-chevron-down">
         </i>
        </label>
        <ul>
         <li class="toctree-l5">
          <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_Import_Original.html">
           Import Original Model Recommendations
          </a>
         </li>
        </ul>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Generate_Datasets.html">
       Obtain Datasets
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-35" name="toctree-checkbox-35" type="checkbox"/>
      <label for="toctree-checkbox-35">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4 has-children">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Dataset_Types.html">
         Dataset Types
        </a>
        <input class="toctree-checkbox" id="toctree-checkbox-36" name="toctree-checkbox-36" type="checkbox"/>
        <label for="toctree-checkbox-36">
         <i class="fas fa-chevron-down">
         </i>
        </label>
        <ul>
         <li class="toctree-l5">
          <a class="reference internal" href="workbench_docs_Workbench_DG_Download_and_Cut_Datasets.html">
           Cut Datasets
          </a>
         </li>
        </ul>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Select_Environment.html">
       Select Environment
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-37" name="toctree-checkbox-37" type="checkbox"/>
      <label for="toctree-checkbox-37">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4 has-children">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Remote_Profiling.html">
         Work with Remote Targets
        </a>
        <input class="toctree-checkbox" id="toctree-checkbox-38" name="toctree-checkbox-38" type="checkbox"/>
        <label for="toctree-checkbox-38">
         <i class="fas fa-chevron-down">
         </i>
        </label>
        <ul>
         <li class="toctree-l5">
          <a class="reference internal" href="workbench_docs_Workbench_DG_Profile_on_Remote_Machine.html">
           Profile on Remote Machine
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="workbench_docs_Workbench_DG_Setup_Remote_Target.html">
           Set Up Remote Target
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="workbench_docs_Workbench_DG_Add_Remote_Target.html">
           Register Remote Target in DL Workbench
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="workbench_docs_Workbench_DG_Remote_Machines.html">
           Manipulate Remote Machines
          </a>
         </li>
        </ul>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Int_8_Quantization.html">
       Optimize Model Performance
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Run_Inference.html">
       Explore Inference Configurations
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-39" name="toctree-checkbox-39" type="checkbox"/>
      <label for="toctree-checkbox-39">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Run_Single_Inference.html">
         Run Inference
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_View_Inference_Results.html">
         View Inference Results
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Compare_Performance_between_Two_Versions_of_Models.html">
         Compare Performance between Two Versions of a Model
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Visualize_Model.html">
         Visualize Model
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Visualize_Accuracy.html">
       Visualize Model Output
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Measure_Accuracy.html">
       Create Accuracy Report
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-40" name="toctree-checkbox-40" type="checkbox"/>
      <label for="toctree-checkbox-40">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Accuracy_Configuration.html">
         Accuracy Configuration
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Configure_Accuracy_Settings.html">
         Set Accuracy Configuration
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Accuracy_Report_Results.html">
         Interpret Accuracy Report Results
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Deployment_Package.html">
       Create Deployment Package
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-41" name="toctree-checkbox-41" type="checkbox"/>
      <label for="toctree-checkbox-41">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Deploy_and_Integrate_Performance_Criteria_into_Application.html">
         Deploy and Integrate Performance Criteria into Application
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Export_Project.html">
       Export Project
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Jupyter_Notebooks_CLI.html">
       Learn OpenVINO in DL Workbench
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-42" name="toctree-checkbox-42" type="checkbox"/>
      <label for="toctree-checkbox-42">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Jupyter_Notebooks.html">
         Learn Model Inference with OpenVINOâ„¢ API in JupyterLab* Environment
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Persist_Database.html">
       Restore DL Workbench State
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="workbench_docs_security_Workbench.html">
       Run DL Workbench Securely
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-43" name="toctree-checkbox-43" type="checkbox"/>
      <label for="toctree-checkbox-43">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Authentication.html">
         Enable Authentication in DL Workbench
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Configure_TLS.html">
         Configure Transport Layer Security (TLS)
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Troubleshooting.html">
     Troubleshooting
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-44" name="toctree-checkbox-44" type="checkbox"/>
    <label for="toctree-checkbox-44">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_DC_Troubleshooting.html">
       Troubleshooting for DL Workbench in the IntelÂ® DevCloud for the Edge
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Media Processing and Computer Vision Libraries
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_dlstreamer.html">
   IntelÂ® Deep Learning Streamer
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_gapi_gapi_intro.html">
   Introduction to OpenCV Graph API (G-API)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-45" name="toctree-checkbox-45" type="checkbox"/>
  <label for="toctree-checkbox-45">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_gapi_kernel_api.html">
     Graph API Kernel API
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_gapi_face_beautification.html">
     Implementing a Face Beautification Algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_gapi_gapi_face_analytics_pipeline.html">
     Building a Face Analytics Pipeline
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://docs.opencv.org/master/">
   OpenCV* Developer Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://software.intel.com/en-us/openclsdk-devguide">
   OpenCLâ„¢ Developer Guide
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  OpenVINO Extensibility
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_Extensibility_UG_Intro.html">
   OpenVINO Extensibility Mechanism
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-46" name="toctree-checkbox-46" type="checkbox"/>
  <label for="toctree-checkbox-46">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_Extensibility_UG_add_openvino_ops.html">
     Custom OpenVINOâ„¢ Operations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_Extensibility_UG_Frontend_Extensions.html">
     Frontend Extensions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_Extensibility_UG_GPU.html">
     How to Implement Custom GPU Operations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_Extensibility_UG_VPU_Kernel.html">
     How to Implement Custom Layers for VPU (IntelÂ® Neural Compute Stick 2)
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_customize_model_optimizer_Customize_Model_Optimizer.html">
     Model Optimizer Extensibility
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-47" name="toctree-checkbox-47" type="checkbox"/>
    <label for="toctree-checkbox-47">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_customize_model_optimizer_Extending_Model_Optimizer_With_Caffe_Python_Layers.html">
       Extending Model Optimizer with Caffe Python Layers
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_transformations.html">
   Overview of Transformations API
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-48" name="toctree-checkbox-48" type="checkbox"/>
  <label for="toctree-checkbox-48">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_Extensibility_UG_model_pass.html">
     OpenVINO Model Pass
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_Extensibility_UG_matcher_pass.html">
     OpenVINO Matcher Pass
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_Extensibility_UG_graph_rewrite_pass.html">
     OpenVINO Graph Rewrite Pass
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_ie_plugin_dg_overview.html">
   OpenVINO Plugin Developer Guide
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-49" name="toctree-checkbox-49" type="checkbox"/>
  <label for="toctree-checkbox-49">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_ie_plugin_dg_plugin.html">
     Implement Plugin Functionality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_ie_plugin_dg_executable_network.html">
     Implement Executable Network Functionality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_ie_plugin_dg_infer_request.html">
     Implement Synchronous Inference Request
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_ie_plugin_dg_async_infer_request.html">
     Implement Asynchronous Inference Request
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_ie_plugin_dg_plugin_build.html">
     Build Plugin Using CMake*
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_ie_plugin_dg_plugin_testing.html">
     Plugin Testing
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_ie_plugin_detailed_guides.html">
     Advanced Topics
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-50" name="toctree-checkbox-50" type="checkbox"/>
    <label for="toctree-checkbox-50">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_ie_plugin_dg_quantized_networks.html">
       Quantized networks compute and restrictions
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="openvino_docs_OV_UG_lpt.html">
       OpenVINOâ„¢ Low Precision Transformations
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-51" name="toctree-checkbox-51" type="checkbox"/>
      <label for="toctree-checkbox-51">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4 has-children">
        <a class="reference internal" href="openvino_docs_OV_UG_lpt_attributes.html">
         Attributes
        </a>
        <input class="toctree-checkbox" id="toctree-checkbox-52" name="toctree-checkbox-52" type="checkbox"/>
        <label for="toctree-checkbox-52">
         <i class="fas fa-chevron-down">
         </i>
        </label>
        <ul>
         <li class="toctree-l5">
          <a class="reference internal" href="openvino_docs_OV_UG_lpt_AvgPoolPrecisionPreserved.html">
           AvgPoolPrecisionPreserved
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="openvino_docs_OV_UG_lpt_IntervalsAlignment.html">
           IntervalsAlignment
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="openvino_docs_OV_UG_lpt_PrecisionPreserved.html">
           PrecisionPreserved
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="openvino_docs_OV_UG_lpt_Precisions.html">
           Precisions
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="openvino_docs_OV_UG_lpt_QuantizationAlignment.html">
           QuantizationAlignment
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="openvino_docs_OV_UG_lpt_QuantizationGranularity.html">
           QuantizationGranularity
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_lpt_step1_prerequisites.html">
         Step 1. Prerequisites transformations
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_lpt_step2_markup.html">
         Step 2. Markup transformations
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_lpt_step3_main.html">
         Step 3. Main transformations
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_lpt_step4_cleanup.html">
         Step 4. Cleanup transformations
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_ie_plugin_api_references.html">
     Plugin API Reference
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-53" name="toctree-checkbox-53" type="checkbox"/>
    <label for="toctree-checkbox-53">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="simple">
    </ul>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Use OpenVINOâ„¢ Toolkit Securely
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_security_guide_introduction.html">
   Introduction to OpenVINOâ„¢ Security
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_security_guide_workbench.html">
   Deep Learning Workbench Security
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_OV_UG_protecting_model_guide.html">
   Using Encrypted Models with OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ovsa_get_started.html">
   OpenVINOâ„¢ Security Add-on
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#converting-a-yolov4-model-to-ir">
   Converting a YOLOv4 Model to IR
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#converting-yolov3-model-to-the-openvino-format">
   Converting YOLOv3 Model to the OpenVINO format
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#overview-of-yolov3-model-architecture">
     Overview of YOLOv3 Model Architecture
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dumping-a-yolov3-tensorflow-model">
     Dumping a YOLOv3 TensorFlow Model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#converting-a-yolov3-tensorflow-model-to-the-openvino-format">
     Converting a YOLOv3 TensorFlow Model to the OpenVINO format
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#converting-yolov1-and-yolov2-models-to-the-ir">
   Converting YOLOv1 and YOLOv2 Models to the IR
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                <div class="tocsection download-docs">
  <div class="dropdown sst-dropdown">
    <button class="button bttn-prm button-size-m" data-display="static" type="button" id="download-options"
      data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
      Download Docs
    </button>
    <div class="dropdown-menu" aria-labelledby="download-options">
      <a class="dropdown-item" href="#" onclick="window.print()">.pdf</a>
      <a id="download-zip-btn" class="dropdown-item" href="#">.zip</a>
    </div>
  </div>
</div>
              </div>
              
            
          </div>
          

          
          
              
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">

<div class="tocsection editthispage">
    <a href="None">
        <i class="fas fa-pencil-alt"></i> Edit this page
    </a>
</div>

            
                <div>
                  
  <section id="converting-tensorflow-yolo-models">
<span id="doxid-openvino-docs-m-o-d-g-prepare-model-convert-model-tf-specific-convert-y-o-l-o-from-tensorflow"></span><span id="index-0"></span><h1>Converting TensorFlow YOLO Models<a class="headerlink" href="#converting-tensorflow-yolo-models" title="Permalink to this headline">Â¶</a></h1>
<p><span class="target" id="doxid-openvino-docs-m-o-d-g-prepare-model-convert-model-tf-specific-convert-y-o-l-o-from-tensorflow-1md-openvino-docs-mo-dg-prepare-model-convert-model-tf-specific-convert-yolo-from-tensorflow"></span> This document explains how to convert real-time object detection YOLOv1, YOLOv2, YOLOv3 and YOLOv4 public models to the Intermediate Representation (IR). All YOLO models are originally implemented in the DarkNet framework and consist of two files:</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">.cfg</span></code> file with model configurations</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">.weights</span></code> file with model weights</p></li>
</ul>
<p>Depending on a YOLO model version, the Model Optimizer converts it differently:</p>
<ul class="simple">
<li><p>YOLOv4 must be first converted from Keras to TensorFlow 2.</p></li>
<li><p>YOLOv3 has several implementations. This tutorial uses a TensorFlow implementation of YOLOv3 model, which can be directly converted to an IR.</p></li>
<li><p>YOLOv1 and YOLOv2 models must be first converted to TensorFlow using DarkFlow.</p></li>
</ul>
<section id="converting-a-yolov4-model-to-ir">
<span id="yolov4-to-ir"></span><h2>Converting a YOLOv4 Model to IR<a class="headerlink" href="#converting-a-yolov4-model-to-ir" title="Permalink to this headline">Â¶</a></h2>
<p>This section explains how to convert the YOLOv4 Keras model from the <a class="reference external" href="https://github.com/david8862/keras-YOLOv3-model-set">repository</a> to an IR. To convert the YOLOv4 model, follow the instructions below:</p>
<ol class="arabic simple">
<li><p>Download YOLOv4 weights and associated with it cfg file:</p></li>
</ol>
<ul class="simple">
<li><p>for YOLOv4 (<a class="reference external" href="https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights">weights</a> / <a class="reference external" href="https://github.com/david8862/keras-YOLOv3-model-set/raw/6c9aff7bb0c1660704ad07c85739e95885676e5b/cfg/yolov4.cfg">config file</a>)</p></li>
<li><p>for YOLOv4-tiny (<a class="reference external" href="https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.weights">weights</a> / <a class="reference external" href="https://raw.githubusercontent.com/david8862/keras-YOLOv3-model-set/6b4a0ee63771262363e8224b0ee915cad6c5e93e/cfg/yolov4-tiny.cfg">config file</a>)</p></li>
</ul>
<ol class="arabic">
<li><p>Clone the repository with the YOLOv4 model:</p>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">clone</span> <span class="nl">https</span><span class="p">:</span><span class="c1">//github.com/david8862/keras-YOLOv3-model-set</span></pre></div></div></li>
<li><p>Convert the model to the TensorFlow 2 format:</p></li>
</ol>
<ul>
<li><p>for YOLOv4:</p>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">keras</span><span class="o">-</span><span class="n">YOLOv3</span><span class="o">-</span><span class="n">model</span><span class="o">-</span><span class="n">set</span><span class="o">/</span><span class="n">tools</span><span class="o">/</span><span class="n">model_converter</span><span class="o">/</span><span class="n">convert</span><span class="p">.</span><span class="n">py</span> <span class="o">&lt;</span><span class="n">path_to_cfg_file</span><span class="o">&gt;/</span><span class="n">yolov4</span><span class="p">.</span><span class="n">cfg</span> <span class="o">&lt;</span><span class="n">path_to_weights</span><span class="o">&gt;/</span><span class="n">yolov4</span><span class="p">.</span><span class="n">weights</span> <span class="o">&lt;</span><span class="n">saved_model_dir</span><span class="o">&gt;</span></pre></div></div></li>
<li><p>for YOLOv4-tiny:</p>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="n">keras</span><span class="o">-</span><span class="n">YOLOv3</span><span class="o">-</span><span class="n">model</span><span class="o">-</span><span class="n">set</span><span class="o">/</span><span class="n">tools</span><span class="o">/</span><span class="n">model_converter</span><span class="o">/</span><span class="n">convert</span><span class="p">.</span><span class="n">py</span> <span class="o">&lt;</span><span class="n">path_to_cfg_file</span><span class="o">&gt;/</span><span class="n">yolov4</span><span class="o">-</span><span class="n">tiny</span><span class="p">.</span><span class="n">cfg</span> <span class="o">&lt;</span><span class="n">path_to_weights</span><span class="o">&gt;/</span><span class="n">yolov4</span><span class="o">-</span><span class="n">tiny</span><span class="p">.</span><span class="n">weights</span> <span class="o">&lt;</span><span class="n">saved_model_dir</span><span class="o">&gt;</span></pre></div></div></li>
</ul>
<ol class="arabic simple">
<li><p>Run Model Optimizer to converter the model from the TensorFlow 2 format to an IR:</p></li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Before you run the conversion, make sure you have installed all the Model Optimizer dependencies for TensorFlow 2.</p>
</div>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">mo</span> <span class="o">--</span><span class="n">saved_model_dir</span> <span class="n">yolov4</span> <span class="o">--</span><span class="n">output_dir</span> <span class="n">models</span><span class="o">/</span><span class="n">IRs</span> <span class="o">--</span><span class="n">input_shape</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">608</span><span class="p">,</span><span class="mi">608</span><span class="p">,</span><span class="mi">3</span><span class="p">]</span> <span class="o">--</span><span class="n">model_name</span> <span class="n">yolov4</span></pre></div></div></section>
<section id="converting-yolov3-model-to-the-openvino-format">
<span id="yolov3-to-ir"></span><h2>Converting YOLOv3 Model to the OpenVINO format<a class="headerlink" href="#converting-yolov3-model-to-the-openvino-format" title="Permalink to this headline">Â¶</a></h2>
<p>There are several public versions of TensorFlow YOLOv3 model implementation available on GitHub. This section explains how to convert YOLOv3 model from the <a class="reference external" href="https://github.com/mystic123/tensorflow-yolo-v3">repository</a> (commit ed60b90) to an IR , but the process is similar for other versions of TensorFlow YOLOv3 model.</p>
<section id="overview-of-yolov3-model-architecture">
<span id="yolov3-overview"></span><h3>Overview of YOLOv3 Model Architecture<a class="headerlink" href="#overview-of-yolov3-model-architecture" title="Permalink to this headline">Â¶</a></h3>
<p>Originally, YOLOv3 model includes feature extractor called <code class="docutils literal notranslate"><span class="pre">Darknet-53</span></code> with three branches at the end that make detections at three different scales. These branches must end with the YOLO <code class="docutils literal notranslate"><span class="pre">Region</span></code> layer.</p>
<p><code class="docutils literal notranslate"><span class="pre">Region</span></code> layer was first introduced in the DarkNet framework. Other frameworks, including TensorFlow, do not have the <code class="docutils literal notranslate"><span class="pre">Region</span></code> implemented as a single layer, so every author of public YOLOv3 model creates it using simple layers. This badly affects performance. For this reason, the main idea of YOLOv3 model conversion to IR is to cut off these custom <code class="docutils literal notranslate"><span class="pre">Region</span></code> -like parts of the model and complete the model with the <code class="docutils literal notranslate"><span class="pre">Region</span></code> layers where required.</p>
</section>
<section id="dumping-a-yolov3-tensorflow-model">
<h3>Dumping a YOLOv3 TensorFlow Model<a class="headerlink" href="#dumping-a-yolov3-tensorflow-model" title="Permalink to this headline">Â¶</a></h3>
<p>To dump TensorFlow model out of <a class="reference external" href="https://github.com/mystic123/tensorflow-yolo-v3">https://github.com/mystic123/tensorflow-yolo-v3</a> GitHub repository (commit ed60b90), follow the instructions below:</p>
<ol class="arabic">
<li><p>Clone the repository:</p>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">clone</span> <span class="nl">https</span><span class="p">:</span><span class="c1">//github.com/mystic123/tensorflow-yolo-v3.git</span>
<span class="n">cd</span> <span class="n">tensorflow</span><span class="o">-</span><span class="n">yolo</span><span class="o">-</span><span class="n">v3</span></pre></div></div></li>
<li><p>(Optional) Checkout to the commit that the conversion was tested on:</p>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">checkout</span> <span class="n">ed60b90</span></pre></div></div></li>
<li><p>Download <a class="reference external" href="https://github.com/AlexeyAB/darknet/blob/master/data/coco.names">coco.names</a> file from the DarkNet website <strong>OR</strong> use labels that fit your task.</p></li>
<li><p>Download the <a class="reference external" href="https://pjreddie.com/media/files/yolov3.weights">yolov3.weights</a> (for the YOLOv3 model) or <a class="reference external" href="https://pjreddie.com/media/files/yolov3-tiny.weights">yolov3-tiny.weights</a> (for the YOLOv3-tiny model) file <strong>OR</strong> use your pre-trained weights with the same structure.</p></li>
<li><p>Install PIL, which is used by the conversion script in the repo:</p>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">pillow</span></pre></div></div></li>
<li><p>Run a converter:</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This converter works with TensorFlow 1.x and numpy 1.19 or lower.</p>
</div>
<ul class="simple">
<li><p>For YOLO-v3:</p></li>
</ul>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">python3</span> <span class="n">convert_weights_pb</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">class_names</span> <span class="n">coco</span><span class="p">.</span><span class="n">names</span> <span class="o">--</span><span class="n">data_format</span> <span class="n">NHWC</span> <span class="o">--</span><span class="n">weights_file</span> <span class="n">yolov3</span><span class="p">.</span><span class="n">weights</span></pre></div></div></li>
</ol>
<ul>
<li><p>For YOLOv3-tiny:</p>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">python3</span> <span class="n">convert_weights_pb</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">class_names</span> <span class="n">coco</span><span class="p">.</span><span class="n">names</span> <span class="o">--</span><span class="n">data_format</span> <span class="n">NHWC</span> <span class="o">--</span><span class="n">weights_file</span> <span class="n">yolov3</span><span class="o">-</span><span class="n">tiny</span><span class="p">.</span><span class="n">weights</span> <span class="o">--</span><span class="n">tiny</span></pre></div></div><p>At this step, you may receive a warning like <code class="docutils literal notranslate"><span class="pre">WARNING:tensorflow:Entity</span> <span class="pre">&lt;...&gt;</span> <span class="pre">could</span> <span class="pre">not</span> <span class="pre">be</span> <span class="pre">transformed</span> <span class="pre">and</span> <span class="pre">will</span> <span class="pre">be</span> <span class="pre">executed</span> <span class="pre">as-is.</span></code>. To work around this issue, switch to gast 0.2.2 with the following command:</p>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">pip3</span> <span class="n">install</span> <span class="o">--</span><span class="n">user</span> <span class="n">gast</span><span class="o">==</span><span class="mf">0.2.2</span></pre></div></div></li>
</ul>
<p>If you have YOLOv3 weights trained for an input image with the size different from 416 (320, 608 or your own), provide the <code class="docutils literal notranslate"><span class="pre">--size</span></code> key with the size of your image specified while running the converter. For example, run the following command for an image with size 608:</p>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">python3</span> <span class="n">convert_weights_pb</span><span class="p">.</span><span class="n">py</span> <span class="o">--</span><span class="n">class_names</span> <span class="n">coco</span><span class="p">.</span><span class="n">names</span> <span class="o">--</span><span class="n">data_format</span> <span class="n">NHWC</span> <span class="o">--</span><span class="n">weights_file</span> <span class="n">yolov3_608</span><span class="p">.</span><span class="n">weights</span> <span class="o">--</span><span class="n">size</span> <span class="mi">608</span></pre></div></div></section>
<section id="converting-a-yolov3-tensorflow-model-to-the-openvino-format">
<h3>Converting a YOLOv3 TensorFlow Model to the OpenVINO format<a class="headerlink" href="#converting-a-yolov3-tensorflow-model-to-the-openvino-format" title="Permalink to this headline">Â¶</a></h3>
<p>To solve the problems explained in the <a class="reference external" href="#yolov3-overview">YOLOv3 architecture overview</a> section, use the <code class="docutils literal notranslate"><span class="pre">yolo_v3.json</span></code> or <code class="docutils literal notranslate"><span class="pre">yolo_v3_tiny.json</span></code> (depending on a model) configuration file with custom operations located in the <code class="docutils literal notranslate"><span class="pre">&lt;OPENVINO_INSTALL_DIR&gt;/tools/model_optimizer/extensions/front/tf</span></code> repository.</p>
<p>It consists of several attributes:</p>
<div class="highlight"><div class="highlight"><pre><span></span><span class="p">[</span>
  <span class="p">{</span>
    <span class="s">&quot;id&quot;</span><span class="o">:</span> <span class="s">&quot;TFYOLOV3&quot;</span><span class="p">,</span>
    <span class="s">&quot;match_kind&quot;</span><span class="o">:</span> <span class="s">&quot;general&quot;</span><span class="p">,</span>
    <span class="s">&quot;custom_attributes&quot;</span><span class="o">:</span> <span class="p">{</span>
      <span class="s">&quot;classes&quot;</span><span class="o">:</span> <span class="mi">80</span><span class="p">,</span>
      <span class="s">&quot;anchors&quot;</span><span class="o">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">23</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">61</span><span class="p">,</span> <span class="mi">62</span><span class="p">,</span> <span class="mi">45</span><span class="p">,</span> <span class="mi">59</span><span class="p">,</span> <span class="mi">119</span><span class="p">,</span> <span class="mi">116</span><span class="p">,</span> <span class="mi">90</span><span class="p">,</span> <span class="mi">156</span><span class="p">,</span> <span class="mi">198</span><span class="p">,</span> <span class="mi">373</span><span class="p">,</span> <span class="mi">326</span><span class="p">],</span>
      <span class="s">&quot;coords&quot;</span><span class="o">:</span> <span class="mi">4</span><span class="p">,</span>
      <span class="s">&quot;num&quot;</span><span class="o">:</span> <span class="mi">9</span><span class="p">,</span>
      <span class="s">&quot;masks&quot;</span><span class="o">:</span><span class="p">[[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span>
      <span class="s">&quot;entry_points&quot;</span><span class="o">:</span> <span class="p">[</span><span class="s">&quot;detector/yolo-v3/Reshape&quot;</span><span class="p">,</span> <span class="s">&quot;detector/yolo-v3/Reshape_4&quot;</span><span class="p">,</span> <span class="s">&quot;detector/yolo-v3/Reshape_8&quot;</span><span class="p">]</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">]</span></pre></div></div><p>where:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">id</span></code> and <code class="docutils literal notranslate"><span class="pre">match_kind</span></code> are parameters that you cannot change.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">custom_attributes</span></code> is a parameter that stores all the YOLOv3 specific attributes:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">classes</span></code>, <code class="docutils literal notranslate"><span class="pre">coords</span></code>, <code class="docutils literal notranslate"><span class="pre">num</span></code>, and <code class="docutils literal notranslate"><span class="pre">masks</span></code> are attributes that you should copy from the configuration file that was used for model training. If you used DarkNet officially shared weights, you can use <code class="docutils literal notranslate"><span class="pre">yolov3.cfg</span></code> or <code class="docutils literal notranslate"><span class="pre">yolov3-tiny.cfg</span></code> configuration file from <a class="reference external" href="https://github.com/david8862/keras-YOLOv3-model-set/tree/master/cfg">https://github.com/david8862/keras-YOLOv3-model-set/tree/master/cfg</a>. Replace the default values in <code class="docutils literal notranslate"><span class="pre">custom_attributes</span></code> with the parameters that follow the <code class="docutils literal notranslate"><span class="pre">[yolo]</span></code> titles in the configuration file.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">anchors</span></code> is an optional parameter that is not used while inference of the model, but it used in a demo to parse <code class="docutils literal notranslate"><span class="pre">Region</span></code> layer output</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">entry_points</span></code> is a node name list to cut off the model and append the <code class="docutils literal notranslate"><span class="pre">Region</span></code> layer with custom attributes specified above.</p></li>
</ul>
</li>
</ul>
<p>To generate an IR of the YOLOv3 TensorFlow model, run:</p>
<div class="highlight"><div class="highlight"><pre><span></span> <span class="n">mo</span>                                                   \
<span class="o">--</span><span class="n">input_model</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">yolo_v3</span><span class="p">.</span><span class="n">pb</span>                                  \
<span class="o">--</span><span class="n">transformations_config</span> <span class="n">front</span><span class="o">/</span><span class="n">tf</span><span class="o">/</span><span class="n">yolo_v3</span><span class="p">.</span><span class="n">json</span> \
<span class="o">--</span><span class="n">batch</span> <span class="mi">1</span>                                                          \
<span class="o">--</span><span class="n">output_dir</span> <span class="o">&lt;</span><span class="n">OUTPUT_MODEL_DIR</span><span class="o">&gt;</span></pre></div></div><p>To generate an IR of the YOLOv3-tiny TensorFlow model, run:</p>
<div class="highlight"><div class="highlight"><pre><span></span> <span class="n">mo</span>                                                        \
<span class="o">--</span><span class="n">input_model</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">yolo_v3_tiny</span><span class="p">.</span><span class="n">pb</span>                                  \
<span class="o">--</span><span class="n">transformations_config</span> <span class="n">front</span><span class="o">/</span><span class="n">tf</span><span class="o">/</span><span class="n">yolo_v3_tiny</span><span class="p">.</span><span class="n">json</span> \
<span class="o">--</span><span class="n">batch</span> <span class="mi">1</span>                                                               \
<span class="o">--</span><span class="n">output_dir</span> <span class="o">&lt;</span><span class="n">OUTPUT_MODEL_DIR</span><span class="o">&gt;</span></pre></div></div><p>where:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--batch</span></code> defines shape of model input. In the example, <code class="docutils literal notranslate"><span class="pre">--batch</span></code> is equal to 1, but you can also specify other integers larger than 1.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--transformations_config</span></code> adds missing <code class="docutils literal notranslate"><span class="pre">Region</span></code> layers to the model. In the IR, the <code class="docutils literal notranslate"><span class="pre">Region</span></code> layer has name <code class="docutils literal notranslate"><span class="pre">RegionYolo</span></code>.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The color channel order (RGB or BGR) of an input data should match the channel order of the model training dataset. If they are different, perform the <code class="docutils literal notranslate"><span class="pre">RGB&lt;-&gt;BGR</span></code> conversion specifying the command-line parameter: <code class="docutils literal notranslate"><span class="pre">--reverse_input_channels</span></code>. Otherwise, inference results may be incorrect. For more information about the parameter, refer to the <strong>When to Reverse Input Channels</strong> section of the <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Converting_Model.html#doxid-openvino-docs-m-o-d-g-prepare-model-convert-model-converting-model"><span class="std std-ref">Converting a Model to Intermediate Representation (IR)</span></a> guide.</p>
</div>
<p>OpenVINO toolkit provides a demo that uses YOLOv3 model. Refer to the Object Detection C++ Demo for more information.</p>
</section>
</section>
<section id="converting-yolov1-and-yolov2-models-to-the-ir">
<h2>Converting YOLOv1 and YOLOv2 Models to the IR<a class="headerlink" href="#converting-yolov1-and-yolov2-models-to-the-ir" title="Permalink to this headline">Â¶</a></h2>
<p>Before converting, choose a YOLOv1 or YOLOv2 model version that best suits your task. Download model configuration file and corresponding weight file:</p>
<ul class="simple">
<li><p>From <a class="reference external" href="https://github.com/thtrieu/darkflow">DarkFlow repository</a> : configuration files are stored in the <code class="docutils literal notranslate"><span class="pre">cfg</span></code> directory, links to weight files are given in the <code class="docutils literal notranslate"><span class="pre">README.md</span></code> file. The files from this repository are adapted for conversion to TensorFlow using DarkFlow.</p></li>
<li><p>From DarkNet website and repository: configuration files are stored in the <code class="docutils literal notranslate"><span class="pre">cfg</span></code> directory of the <a class="reference external" href="https://github.com/pjreddie/darknet">repository</a>, links to weight files are given on the <a class="reference external" href="https://pjreddie.com/darknet/yolov1/">YOLOv1</a> and <a class="reference external" href="https://pjreddie.com/darknet/yolov2/">YOLOv2</a> websites.</p></li>
</ul>
<p>To convert DarkNet YOLOv1 and YOLOv2 models to the OpenVINO format, follow these steps:</p>
<ol class="arabic simple">
<li><p><a class="reference external" href="#install-darkflow">Install DarkFlow</a></p></li>
<li><p><a class="reference external" href="#yolov1-v2-to-tf">Convert DarkNet YOLOv1 or YOLOv2 model to TensorFlow</a> using DarkFlow</p></li>
<li><p><a class="reference external" href="#yolov1-v2-to-ir">Convert TensorFlow YOLOv1 or YOLOv2 model to IR</a></p></li>
</ol>
<p>You need DarkFlow to convert YOLOv1 and YOLOv2 models to TensorFlow. To install DarkFlow:</p>
<ol class="arabic">
<li><p>Install DarkFlow <a class="reference external" href="https://github.com/thtrieu/darkflow#dependencies">required dependencies</a>.</p></li>
<li><p>Clone DarkFlow git repository:</p>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">clone</span> <span class="nl">https</span><span class="p">:</span><span class="c1">//github.com/thtrieu/darkflow.git</span></pre></div></div></li>
<li><p>Go to the root directory of the cloned repository:</p>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">cd</span> <span class="n">darkflow</span></pre></div></div></li>
<li><p>Install DarkFlow, using the instructions from the <code class="docutils literal notranslate"><span class="pre">README.md</span></code> file in the <a class="reference external" href="https://github.com/thtrieu/darkflow/blob/master/README.md#getting-started">DarkFlow repository</a>.</p></li>
</ol>
<p>To convert YOLOv1 or YOLOv2 model to TensorFlow, go to the root directory of the cloned DarkFlow repository, place the previously downloaded *.cfg and *.weights files in the current directory and run the following command:</p>
<ul>
<li><p>For YOLOv1:</p>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">python3</span> <span class="n">flow</span> <span class="o">--</span><span class="n">model</span> <span class="n">yolov1</span><span class="p">.</span><span class="n">cfg</span> <span class="o">--</span><span class="n">load</span> <span class="n">yolov1</span><span class="p">.</span><span class="n">weights</span> <span class="o">--</span><span class="n">savepb</span></pre></div></div></li>
<li><p>For YOLOv2 with VOC dataset <code class="docutils literal notranslate"><span class="pre">--labels</span></code> argument should be specified and additional changes in the original exporting script are required. In the file <a class="reference external" href="https://github.com/thtrieu/darkflow/blob/b187c65630f9aa1bb8b809c33ec67c8cc5d60124/darkflow/utils/loader.py#L121">https://github.com/thtrieu/darkflow/blob/b187c65/darkflow/utils/loader.py#L121</a> change line 121 from <code class="docutils literal notranslate"><span class="pre">self.offset</span> <span class="pre">=</span> <span class="pre">16</span></code> to <code class="docutils literal notranslate"><span class="pre">self.offset</span> <span class="pre">=</span> <span class="pre">20</span></code>. Then run:</p>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">python3</span> <span class="n">flow</span> <span class="o">--</span><span class="n">model</span> <span class="n">yolov2</span><span class="o">-</span><span class="n">voc</span><span class="p">.</span><span class="n">cfg</span> <span class="o">--</span><span class="n">load</span> <span class="n">yolov2</span><span class="o">-</span><span class="n">voc</span><span class="p">.</span><span class="n">weights</span> <span class="o">--</span><span class="n">labels</span> <span class="n">voc</span><span class="o">-</span><span class="n">labels</span><span class="p">.</span><span class="n">txt</span> <span class="o">--</span><span class="n">savepb</span></pre></div></div><p>VOC labels can be found on the following link <a class="reference external" href="https://raw.githubusercontent.com/szaza/android-yolo-v2/master/assets/tiny-yolo-voc-labels.txt">https://raw.githubusercontent.com/szaza/android-yolo-v2/master/assets/tiny-yolo-voc-labels.txt</a></p>
</li>
</ul>
<p>General conversion command is:</p>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">python3</span> <span class="n">flow</span> <span class="o">--</span><span class="n">model</span> <span class="o">&lt;</span><span class="n">path_to_model</span><span class="o">&gt;/&lt;</span><span class="n">model_name</span><span class="o">&gt;</span><span class="p">.</span><span class="n">cfg</span> <span class="o">--</span><span class="n">load</span> <span class="o">&lt;</span><span class="n">path_to_model</span><span class="o">&gt;/&lt;</span><span class="n">model_name</span><span class="o">&gt;</span><span class="p">.</span><span class="n">weights</span> <span class="o">--</span><span class="n">labels</span> <span class="o">&lt;</span><span class="n">path_to_dataset_labels_file</span><span class="o">&gt;</span> <span class="o">--</span><span class="n">savepb</span></pre></div></div><p>For YOLOv1, the <code class="docutils literal notranslate"><span class="pre">--labels</span></code> argument can be skipped. If the model was successfully converted, you can find the <code class="docutils literal notranslate"><span class="pre">&lt;model_name&gt;.meta</span></code> and <code class="docutils literal notranslate"><span class="pre">&lt;model_name&gt;.pb</span></code> files. in <code class="docutils literal notranslate"><span class="pre">built_graph</span></code> subdirectory of the cloned DarkFlow repository.</p>
<p>File <code class="docutils literal notranslate"><span class="pre">&lt;model_name&gt;.pb</span></code> is a TensorFlow representation of the YOLO model.</p>
<p>Converted TensorFlow YOLO model is missing <code class="docutils literal notranslate"><span class="pre">Region</span></code> layer and its parameters. Original YOLO <code class="docutils literal notranslate"><span class="pre">Region</span></code> layer parameters are stored in the configuration <code class="docutils literal notranslate"><span class="pre">&lt;path_to_model&gt;/&lt;model_name&gt;.cfg</span></code> file under the <code class="docutils literal notranslate"><span class="pre">[region]</span></code> title.</p>
<p>To recreate the original model structure, use the corresponding yolo <code class="docutils literal notranslate"><span class="pre">.json</span></code> configuration file with custom operations and <code class="docutils literal notranslate"><span class="pre">Region</span></code> layer parameters when converting the model to the IR. This file is located in the <code class="docutils literal notranslate"><span class="pre">&lt;OPENVINO_INSTALL_DIR&gt;/tools/model_optimizer/extensions/front/tf</span></code> directory.</p>
<p>If chosen model has specific values of these parameters, create another configuration file with custom operations and use it for conversion.</p>
<p>To generate the IR of the YOLOv1 model, provide TensorFlow YOLOv1 or YOLOv2 model to Model Optimizer with the following parameters:</p>
<div class="highlight"><div class="highlight"><pre><span></span> <span class="n">mo</span>
<span class="o">--</span><span class="n">input_model</span> <span class="o">&lt;</span><span class="n">path_to_model</span><span class="o">&gt;/&lt;</span><span class="n">model_name</span><span class="o">&gt;</span><span class="p">.</span><span class="n">pb</span>       \
<span class="o">--</span><span class="n">batch</span> <span class="mi">1</span>                                       \
<span class="o">--</span><span class="n">scale</span> <span class="mi">255</span> \
<span class="o">--</span><span class="n">transformations_config</span> <span class="n">front</span><span class="o">/</span><span class="n">tf</span><span class="o">/&lt;</span><span class="n">yolo_config</span><span class="o">&gt;</span><span class="p">.</span><span class="n">json</span></pre></div></div><p>where:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--batch</span></code> defines shape of model input. In the example, <code class="docutils literal notranslate"><span class="pre">--batch</span></code> is equal to 1, but you can also specify other integers larger than 1.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--scale</span></code> specifies scale factor that input values will be divided by. The model was trained with input values in the range <code class="docutils literal notranslate"><span class="pre">[0,1]</span></code>. OpenVINO toolkit samples read input images as values in <code class="docutils literal notranslate"><span class="pre">[0,255]</span></code> range, so the scale 255 must be applied.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--transformations_config</span></code> adds missing <code class="docutils literal notranslate"><span class="pre">Region</span></code> layers to the model. In the IR, the <code class="docutils literal notranslate"><span class="pre">Region</span></code> layer has name <code class="docutils literal notranslate"><span class="pre">RegionYolo</span></code>. For other applicable parameters, refer to the <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_TensorFlow.html#doxid-openvino-docs-m-o-d-g-prepare-model-convert-model-convert-model-from-tensor-flow"><span class="std std-ref">Convert Model from TensorFlow</span></a> guide.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The color channel order (RGB or BGR) of an input data should match the channel order of the model training dataset. If they are different, perform the <code class="docutils literal notranslate"><span class="pre">RGB&lt;-&gt;BGR</span></code> conversion specifying the command-line parameter: <code class="docutils literal notranslate"><span class="pre">--reverse_input_channels</span></code>. Otherwise, inference results may be incorrect. For more information about the parameter, refer to the <strong>When to Reverse Input Channels</strong> section of the <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Converting_Model.html#doxid-openvino-docs-m-o-d-g-prepare-model-convert-model-converting-model"><span class="std std-ref">Converting a Model to Intermediate Representation (IR)</span></a> guide.</p>
</div>
</section>
</section>


                </div>
            
            
                <div class='prev-next-bottom'>
                  
    <a class='button bttn-sec button-size-l' id="prev-link" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_XLNet_From_Tensorflow.html" title="previous page">Prev</a>
    <a class='button bttn-sec button-size-l' id="next-link" href="openvino_docs_MO_DG_prepare_model_convert_model_onnx_specific_Convert_Faster_RCNN.html" title="next page">Next</a>

                </div>
            
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, IntelÂ®.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.2.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>