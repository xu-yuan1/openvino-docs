.. index:: pair: page; Model Creation C++ Sample
.. _doxid-openvino_inference_engine_samples_model_creation_sample__r_e_a_d_m_e:


Model Creation C++ Sample
=========================

:target:`doxid-openvino_inference_engine_samples_model_creation_sample__r_e_a_d_m_e_1md_openvino_samples_cpp_model_creation_sample_readme` This sample demonstrates how to execute an synchronous inference using :ref:`model <doxid-openvino_docs__o_v__u_g__model__representation>` built on the fly which uses weights from LeNet classification model, which is known to work well on digit classification tasks.

You do not need an XML file to create a model. The API of :ref:`ov::Model <doxid-classov_1_1_model>` allows creating a model on the fly from the source code.

The following C++ API is used in the application:

.. list-table::
    :header-rows: 1

    * - Feature
      - API
      - Description
    * - OpenVINO Runtime Info
      - ``:ref:`ov::Core::get_versions <doxid-classov_1_1_core_1ad1a54997808ba8bf005ea549dfd5a20b>```
      - Get device plugins versions
    * - Shape Operations
      - ``ov::Output::get_shape`` , ``ov::Shape::size`` , ``:ref:`ov::shape_size <doxid-group__ov__model__cpp__api_1gafe8cdd6477ae9810c2bf368602d35883>```
      - Operate with shape
    * - Tensor Operations
      - ``:ref:`ov::Tensor::get_byte_size <doxid-classov_1_1_tensor_1ae540fcafc1e9dc9181e86a1ec2682935>``` , ``:ref:`ov::Tensor <doxid-classov_1_1_tensor>`:data``
      - Get tensor byte size and its data
    * - Model Operations
      - ``:ref:`ov::set_batch <doxid-namespaceov_1a3314e2ff91fcc9ffec05b1a77c37862b>```
      - Operate with model batch size
    * - Infer Request Operations
      - ``:ref:`ov::InferRequest::get_input_tensor <doxid-classov_1_1_infer_request_1a5f0bc1ab40de6a7a12136b4a4e6a8b54>```
      - Get a input tensor
    * - Model creation objects
      - ``ov::opset8::Parameter`` , ``:ref:`ov::Node::output <doxid-classov_1_1_node_1ac99614dc0669915105d5681cf3873251>``` , ``ov::opset8::Constant`` , ``ov::opset8::Convolution`` , ``ov::opset8::Add`` , ``ov::opset1::MaxPool`` , ``ov::opset8::Reshape`` , ``ov::opset8::MatMul`` , ``ov::opset8::Relu`` , ``ov::opset8::Softmax`` , ``:ref:`ov::descriptor::Tensor::set_names <doxid-classov_1_1descriptor_1_1_tensor_1a5f21c3cb845cbee0b7350163644776a0>``` , ``ov::opset8::Result`` , ``:ref:`ov::Model <doxid-classov_1_1_model>``` , ``ov::ParameterVector::vector``
      - Used to construct an OpenVINO model

Basic OpenVINO™ Runtime API is covered by :ref:`Hello Classification C++ sample <doxid-openvino_inference_engine_samples_hello_classification__r_e_a_d_m_e>`.

.. list-table::
    :header-rows: 1

    * - Options
      - Values
    * - Validated Models
      - LeNet
    * - Model Format
      - model weights file (\*.bin)
    * - Validated images
      - single-channel ``MNIST ubyte`` images
    * - Supported devices
      - :ref:`All <doxid-openvino_docs__o_v__u_g_supported_plugins__supported__devices>`
    * - Other language realization
      - :ref:`Python <doxid-openvino_inference_engine_ie_bridges_python_sample_model_creation_sample__r_e_a_d_m_e>`

How It Works
~~~~~~~~~~~~

At startup, the sample application does the following:

* Reads command line parameters

* :ref:`Build a Model <doxid-openvino_docs__o_v__u_g__model__representation>` and passed weights file

* Loads the model and input data to the OpenVINO™ Runtime plugin

* Performs synchronous inference and processes output data, logging each step in a standard output stream

You can see the explicit description of each sample step at :ref:`Integration Steps <doxid-openvino_docs__o_v__u_g__integrate__o_v_with_your_application>` section of "Integrate OpenVINO™ Runtime with Your Application" guide.

Building
~~~~~~~~

To build the sample, please use instructions available at :ref:`Build the Sample Applications <doxid-openvino_docs__o_v__u_g__samples__overview>` section in OpenVINO™ Toolkit Samples guide.

Running
~~~~~~~

.. ref-code-block:: cpp

	model_creation_sample <path_to_lenet_weights> <device>

**NOTES** :

* you can use LeNet model weights in the sample folder: ``lenet.bin`` with FP32 weights file

* The ``lenet.bin`` with FP32 weights file was generated by the :ref:`Model Optimizer <doxid-openvino_docs__m_o__d_g__deep__learning__model__optimizer__dev_guide>` tool from the public LeNet model with the ``--input_shape [64,1,28,28]`` parameter specified.

The original model is available in the `Caffe repository <https://github.com/BVLC/caffe/tree/master/examples/mnist>`__ on GitHub.

You can do inference of an image using a pre-trained model on a GPU using the following command:

.. ref-code-block:: cpp

	model_creation_sample lenet.bin GPU

Sample Output
~~~~~~~~~~~~~

The sample application logs each step in a standard output stream and outputs top-10 inference results.

.. ref-code-block:: cpp

	[ INFO ] OpenVINO Runtime version ......... <version>
	[ INFO ] Build ........... <build>
	[ INFO ]
	[ INFO ] Device info:
	[ INFO ] GPU
	[ INFO ] Intel GPU plugin version ......... <version>
	[ INFO ] Build ........... <build>
	[ INFO ]
	[ INFO ]
	[ INFO ] Create model from weights: lenet.bin
	[ INFO ] model name: lenet
	[ INFO ]     inputs
	[ INFO ]         input name: NONE
	[ INFO ]         input type: f32
	[ INFO ]         input shape: {64, 1, 28, 28}
	[ INFO ]     outputs
	[ INFO ]         output name: output_tensor
	[ INFO ]         output type: f32
	[ INFO ]         output shape: {64, 10}
	[ INFO ] Batch size is 10
	[ INFO ] model name: lenet
	[ INFO ]     inputs
	[ INFO ]         input name: NONE
	[ INFO ]         input type: u8
	[ INFO ]         input shape: {10, 28, 28, 1}
	[ INFO ]     outputs
	[ INFO ]         output name: output_tensor
	[ INFO ]         output type: f32
	[ INFO ]         output shape: {10, 10}
	[ INFO ] Compiling a model for the GPU device
	[ INFO ] Create infer request
	[ INFO ] Combine images in batch and set to input tensor
	[ INFO ] Start sync inference
	[ INFO ] Processing output tensor
	
	Top 1 results:
	
	Image 0
	
	classid probability label
	------- ----------- -----
	0       1.0000000   0
	
	Image 1
	
	classid probability label
	------- ----------- -----
	1       1.0000000   1
	
	Image 2
	
	classid probability label
	------- ----------- -----
	2       1.0000000   2
	
	Image 3
	
	classid probability label
	------- ----------- -----
	3       1.0000000   3
	
	Image 4
	
	classid probability label
	------- ----------- -----
	4       1.0000000   4
	
	Image 5
	
	classid probability label
	------- ----------- -----
	5       1.0000000   5
	
	Image 6
	
	classid probability label
	------- ----------- -----
	6       1.0000000   6
	
	Image 7
	
	classid probability label
	------- ----------- -----
	7       1.0000000   7
	
	Image 8
	
	classid probability label
	------- ----------- -----
	8       1.0000000   8
	
	Image 9
	
	classid probability label
	------- ----------- -----
	9       1.0000000   9

Deprecation Notice
~~~~~~~~~~~~~~~~~~

.. list-table::
    :header-rows: 1

    * - **Deprecation Begins**
      - June 1, 2020
    * - **Removal Date**
      - December 1, 2020

See Also
~~~~~~~~

* :ref:`Integrate the OpenVINO™ Runtime with Your Application <doxid-openvino_docs__o_v__u_g__integrate__o_v_with_your_application>`

* :ref:`Using OpenVINO™ Toolkit Samples <doxid-openvino_docs__o_v__u_g__samples__overview>`

* :ref:`Model Optimizer <doxid-openvino_docs__m_o__d_g__deep__learning__model__optimizer__dev_guide>`

