
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Tutorial Darknet* YOLOv4 Model &#8212; OpenVINO™  documentation</title>
    
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <link rel="stylesheet" type="text/css" href="../_static/doxyrest-pygments.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <link href="../_static/css/media/favicon.ico" rel="shortcut icon">
    <link rel="stylesheet" href="../_static/css/openvino_sphinx_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/button.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/input.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/textfield.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/tabs.css" type="text/css" />
    <script src="../_static/js/openvino_sphinx_theme.js"></script>
    <link rel="stylesheet" href="../_static/css/viewer.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />

    <script src="https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-datalabels"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/chartjs-plugin-annotation/0.5.7/chartjs-plugin-annotation.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-barchart-background@1.3.0/build/Plugin.Barchart.Background.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-deferred@1"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/PapaParse/5.3.1/papaparse.min.js"></script>
    <script src="../_static/js/viewer.min.js"></script>
    <script src="/assets/versions_raw.js"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/tabs.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/js/custom.js"></script>
    <script src="../_static/js/graphs.js"></script>
    <script src="../_static/js/graphs_ov_tf.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/target-highlight.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <link rel="canonical" href="https://docs.openvino.ai/latest/pages/workbench_docs_Workbench_DG_Tutorial_Import_YOLO.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Object Detection Model Tutorial" href="workbench_docs_Workbench_DG_Measure_Accuracy_Object_detection.html" />
    <link rel="prev" title="OpenVINO™ Deep Learning Workbench Tutorials" href="workbench_docs_Workbench_DG_Tutorials.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
      <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/logo.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="get_started.html">
  Get Started
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="documentation.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../tutorials.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/api_reference.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../model_zoo.html">
  Model Zoo
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="resources.html">
  Resources
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/openvinotoolkit/openvino" rel="noopener" target="_blank" title="GitHub">
            <span><i class="sst-github"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
</ul>
      </div>
      
      <div class="navbar-end-item">
        
<div class="dropdown sst-dropdown sst-dropdown-navbar">
  <button class="btn sst-btn dropdown-toggle" type="button" id="version-selector" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"></button>
  <div class="dropdown-menu" aria-labelledby="version-selector">
  </div>
</div>
      </div>
      
      <div class="navbar-end-item">
        

<div class="dropdown sst-dropdown sst-dropdown-navbar">
  <button class="btn sst-btn dropdown-toggle" type="button" id="language-selector" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">English</button>
  <div class="dropdown-menu" aria-labelledby="language-selector">
    
      
        <a class="dropdown-item font-weight-bold" href="/latest/pages/workbench_docs_Workbench_DG_Tutorial_Import_YOLO.html">English</a>
      
    
      
        <a  class="dropdown-item" href="/cn/latest/pages/workbench_docs_Workbench_DG_Tutorial_Import_YOLO.html">Chinese</a>
      
    
  </div>
</div>

      </div>
      
    </div>
  </div>
</div>
        <div id="collapse-nav-wrapper" class="container-xl">
          <button id="collapse-nav" class="button bttn-prm button-size-m" type="button" data-toggle="collapse" data-target="#nav-tree" aria-expanded="false" aria-controls="nav-tree">
            Documentation navigation <i class="fas fa-chevron-down"></i>
          </button>
        </div>
      </nav>
      <div class="transition-banner container-fluid alert alert-info alert-dismissible fade show" role="alert">
        <p>OpenVINO 2022.1 introduces a new version of OpenVINO API (API 2.0). For more information on the changes and transition steps, see the <a href="https://docs.openvino.ai/latest/openvino_2_0_transition_guide.html">transition guide</a></p>
        <button type="button" class="close" data-dismiss="alert" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
    </div>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar" id="nav-tree"><form class="searchForm bd-search d-flex align-items-center" action="../search.html" method="get">
    <i class="icon fas fa-search"></i>
    <input type="search" class="form-control" name="query" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Converting and Preparing Models
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html">
   Convert model with Model Optimizer
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Converting_Model.html">
     Setting Input Shapes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Cutting_Model.html">
     Cutting Off Parts of a Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_Additional_Optimization_Use_Cases.html">
     Embedding Preprocessing Computation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_FP16_Compression.html">
     Compression of a Model to FP16
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_TensorFlow.html">
     Converting a TensorFlow Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_ONNX.html">
     Converting an ONNX Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_PyTorch.html">
     Converting a PyTorch* Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_Paddle.html">
     Converting a PaddlePaddle* Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_MxNet.html">
     Converting an MXNet* Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_Caffe.html">
     Converting a Caffe* Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_Kaldi.html">
     Converting a Kaldi* Model
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tutorials.html">
     Model Conversion Tutorials
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_AttentionOCR_From_Tensorflow.html">
       Convert TensorFlow Attention OCR Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_BERT_From_Tensorflow.html">
       Convert TensorFlow BERT Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_CRNN_From_Tensorflow.html">
       Convert TensorFlow CRNN Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_DeepSpeech_From_Tensorflow.html">
       Convert TensorFlow DeepSpeech Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_EfficientDet_Models.html">
       Convert TensorFlow EfficientDet Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_FaceNet_From_Tensorflow.html">
       Convert TensorFlow FaceNet Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_GNMT_From_Tensorflow.html">
       Convert TensorFlow GNMT Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_lm_1b_From_Tensorflow.html">
       Convert TensorFlow Language Model on One Billion Word Benchmark
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_NCF_From_Tensorflow.html">
       Convert TensorFlow Neural Collaborative Filtering Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_Object_Detection_API_Models.html">
       Convert TensorFlow Object Detection API Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_RetinaNet_From_Tensorflow.html">
       Converting TensorFlow RetinaNet Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_Slim_Library_Models.html">
       Convert TensorFlow Slim Image Classification Model Library Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_WideAndDeep_Family_Models.html">
       Convert TensorFlow Wide and Deep Family Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_XLNet_From_Tensorflow.html">
       Convert TensorFlow XLNet Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_YOLO_From_Tensorflow.html">
       Convert TensorFlow YOLO Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_onnx_specific_Convert_Faster_RCNN.html">
       Convert ONNX* Faster R-CNN Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_onnx_specific_Convert_GPT2.html">
       Convert ONNX* GPT-2 Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_onnx_specific_Convert_Mask_RCNN.html">
       Convert ONNX* Mask R-CNN Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_Bert_ner.html">
       Convert PyTorch* BERT-NER Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_Cascade_RCNN_res101.html">
       Convert PyTorch Cascade RCNN R-101 Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_F3Net.html">
       Convert PyTorch* F3Net Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_QuartzNet.html">
       Convert PyTorch* QuartzNet Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_RCAN.html">
       Convert PyTorch* RCAN Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_RNNT.html">
       Convert PyTorch* RNN-T Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_YOLACT.html">
       Convert PyTorch* YOLACT Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_mxnet_specific_Convert_GluonCV_Models.html">
       Convert MXNet GluonCV* Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_mxnet_specific_Convert_Style_Transfer_From_MXNet.html">
       Convert MXNet Style Transfer Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_kaldi_specific_Aspire_Tdnn_Model.html">
       Convert Kaldi* ASpIRE Chain Time Delay Neural Network (TDNN) Model
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_Model_Optimizer_FAQ.html">
     Model Optimizer Frequently Asked Questions
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Deploying Inference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_OV_UG_OV_Runtime_User_Guide.html">
   Performing inference with OpenVINO Runtime
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_OV_UG_Integrate_OV_with_your_application.html">
     Integrate OpenVINO™ with Your Application
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Model_Representation.html">
       Model Representation in OpenVINO™ Runtime
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Infer_request.html">
       OpenVINO™ Inference Request
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Python_API_exclusives.html">
       OpenVINO™ Python API exclusives
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_OV_UG_ShapeInference.html">
     Changing input shapes
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_OV_UG_Working_with_devices.html">
     Working with devices
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_query_api.html">
       Query device properties, configuration
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_CPU.html">
       CPU device
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_GPU.html">
       GPU device
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
      <label for="toctree-checkbox-6">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_GPU_RemoteTensor_API.html">
         Remote Tensor API of GPU Plugin
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_VPU.html">
       VPU devices
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
      <label for="toctree-checkbox-7">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_MYRIAD.html">
         MYRIAD device
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_HDDL.html">
         HDDL device
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_GNA.html">
       GNA device
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_ARM_CPU.html">
       Arm® CPU device
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_OV_UG_Preprocessing_Overview.html">
     Optimize Preprocessing
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
    <label for="toctree-checkbox-8">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Preprocessing_Details.html">
       Preprocessing API - details
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Layout_Overview.html">
       Layout API overview
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Preprocess_Usecase_save.html">
       Use Case - Integrate and Save Preprocessing Steps Into IR
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_OV_UG_DynamicShapes.html">
     Dynamic Shapes
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
    <label for="toctree-checkbox-9">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_NoDynamicShapes.html">
       When Dynamic Shapes API is Not Applicable
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_AUTO.html">
     Automatic device selection
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
    <label for="toctree-checkbox-10">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_AUTO_debugging.html">
       Debugging Auto-Device Plugin
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_OV_UG_Running_on_multiple_devices.html">
     Running on multiple devices simultaneously
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_OV_UG_Hetero_execution.html">
     Heterogeneous execution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_OV_UG_Performance_Hints.html">
     High-level Performance Hints
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_OV_UG_Automatic_Batching.html">
     Automatic Batching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_OV_UG_network_state_intro.html">
     Stateful models
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_2_0_transition_guide.html">
   Transition to OpenVINO™ API 2.0
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_2_0_deployment.html">
     Installation &amp; Deployment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_2_0_inference_pipeline.html">
     Inference Pipeline
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_2_0_configure_devices.html">
     Configuring Devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_2_0_preprocessing.html">
     Preprocessing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_2_0_model_creation.html">
     Model Creation in Runtime
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_deployment_guide.html">
   Deploy with OpenVINO
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_install_guides_deployment_manager_tool.html">
     Deployment Manager
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_deploy_local_distribution.html">
     Local distribution
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_inference_engine_tools_compile_tool_README.html">
   Compile Tool
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tuning for Performance
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_optimization_guide_dldt_optimization_guide.html">
   Introduction to Performance Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_MO_DG_Getting_Performance_Numbers.html">
   Getting Performance Numbers
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_model_optimization_guide.html">
   Model Optimization Guide
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="pot_introduction.html">
     Optimizing models post-training
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
    <label for="toctree-checkbox-14">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="pot_default_quantization_usage.html">
       Quantizing Model
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
      <label for="toctree-checkbox-15">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="pot_compression_algorithms_quantization_default_README.html">
         DefaultQuantization Method
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="pot_accuracyaware_usage.html">
       Quantizing Model with Accuracy Control
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
      <label for="toctree-checkbox-16">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="accuracy_aware_README.html">
         AccuracyAwareQuantization Method
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="pot_docs_BestPractices.html">
       Quantization Best Practices
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
      <label for="toctree-checkbox-17">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="pot_saturation_issue.html">
         Saturation Issue
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="pot_compression_api_README.html">
       API Reference
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="pot_compression_cli_README.html">
       Command-line Interface
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
      <label for="toctree-checkbox-18">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="pot_docs_simplified_mode.html">
         Simplified Mode
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="pot_configs_README.html">
         Configuration File Description
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="pot_examples_description.html">
       Examples
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
      <label for="toctree-checkbox-19">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4 has-children">
        <a class="reference internal" href="pot_example_README.html">
         API Examples
        </a>
        <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
        <label for="toctree-checkbox-20">
         <i class="fas fa-chevron-down">
         </i>
        </label>
        <ul>
         <li class="toctree-l5">
          <a class="reference internal" href="pot_example_classification_README.html">
           Quantizatiing Image Classification Model
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="pot_example_object_detection_README.html">
           Quantizatiing Object Detection Model with Accuracy Control
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="pot_example_face_detection_README.html">
           Quantizatiing Cascaded Model
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="pot_example_segmentation_README.html">
           Quantizatiing Semantic Segmentation Model
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="pot_example_3d_segmentation_README.html">
           Quantizatiing 3D Segmentation Model
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="pot_example_speech_README.html">
           Quantizatiing for GNA Device
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="pot_configs_examples_README.html">
         Command-line Example
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="pot_docs_FrequentlyAskedQuestions.html">
       Post-training Optimization Tool Frequently Asked Questions
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="docs_nncf_introduction.html">
     Neural Network Compression Framework
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="pot_ranger_README.html">
     (Experimental) Protecting Model
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_deployment_optimization_guide_dldt_optimization_guide.html">
   Runtime Inference Optimizations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
  <label for="toctree-checkbox-21">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_deployment_optimization_guide_common.html">
     General Optimizations
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_deployment_optimization_guide_latency.html">
     Optimizing for the Latency
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
    <label for="toctree-checkbox-22">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Model_caching_overview.html">
       Model Caching Overview
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_deployment_optimization_guide_tput.html">
     Optimizing for Throughput
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_deployment_optimization_guide_tput_advanced.html">
     Using Advanced Throughput Options: Streams and Batching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_deployment_optimization_guide_internals.html">
     Further Low-Level Implementation Details
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_tuning_utilities.html">
   Tuning Utilities
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
  <label for="toctree-checkbox-23">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_inference_engine_tools_cross_check_tool_README.html">
     Cross Check Tool
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_performance_benchmarks.html">
   Performance Benchmarks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
  <label for="toctree-checkbox-24">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_performance_benchmarks_openvino.html">
     Intel® Distribution of OpenVINO™ toolkit Benchmark Results
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
    <label for="toctree-checkbox-25">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_performance_benchmarks_faq.html">
       Performance Information Frequently Asked Questions
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference external" href="https://docs.openvino.ai/downloads/benchmark_files/OV-2022.1-Download-Excel.xlsx">
       Download Performance Data Spreadsheet in MS Excel* Format
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_performance_int8_vs_fp32.html">
       Model Accuracy for INT8 and FP32 Precision
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_performance_benchmarks_ovms.html">
     OpenVINO™ Model Server Benchmark Results
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Graphical Web Interface for OpenVINO™ toolkit
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="workbench_docs_Workbench_DG_Introduction.html">
   OpenVINO™ Deep Learning Workbench Overview
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="workbench_docs_Workbench_DG_Install.html">
   Installation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/>
  <label for="toctree-checkbox-26">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Prerequisites.html">
     Prerequisites
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Run_Locally.html">
     Run the DL Workbench Locally
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/>
    <label for="toctree-checkbox-27">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Advanced_Configurations.html">
       Advanced DL Workbench Configurations
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Docker_Container.html">
       Work with Docker Container
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Start_DL_Workbench_in_DevCloud.html">
     Run the DL Workbench in the Intel® DevCloud for the Edge
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="workbench_docs_Workbench_DG_Work_with_Models_and_Sample_Datasets.html">
   Get Started
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/>
  <label for="toctree-checkbox-28">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Select_Model.html">
     Import Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_Create_Project.html">
     Create Project
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Additional_Resources.html">
     Educational Resources about DL Workbench
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/>
    <label for="toctree-checkbox-29">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Key_Concepts.html">
       DL Workbench Key Concepts
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorials.html">
   Tutorials
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/>
  <label for="toctree-checkbox-30">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Object Detection Model (YOLOv4)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Measure_Accuracy_Object_detection.html">
     Object Detection Model (SSD_mobilenet)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_Classification.html">
     Classification Model (mobilenet)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Measure_Accuracy_Classification.html">
     Classification Model (squeezenet)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_Instance_Segmentation.html">
     Instance Segmentation Model (mask R-cnn)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_Semantic_Segmentation.html">
     Semantic Segmentation Model (deeplab)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_Style_Transfer.html">
     Style Transfer Model (fast-nst-onnx)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_NLP.html">
     NLP Model (BERT)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="workbench_docs_Workbench_DG_User_Guide.html">
   User Guide
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/>
  <label for="toctree-checkbox-31">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Select_Models.html">
     Obtain Models
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" type="checkbox"/>
    <label for="toctree-checkbox-32">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_OMZ_Models.html">
       Import Open Model Zoo Models
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Original_Model_Import.html">
       Import Original Model
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-33" name="toctree-checkbox-33" type="checkbox"/>
      <label for="toctree-checkbox-33">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_Import_Original.html">
         Import Original Model Recommendations
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Generate_Datasets.html">
     Obtain Datasets
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-34" name="toctree-checkbox-34" type="checkbox"/>
    <label for="toctree-checkbox-34">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Dataset_Types.html">
       Dataset Types
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-35" name="toctree-checkbox-35" type="checkbox"/>
      <label for="toctree-checkbox-35">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Download_and_Cut_Datasets.html">
         Cut Datasets
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Select_Environment.html">
     Select Environment
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-36" name="toctree-checkbox-36" type="checkbox"/>
    <label for="toctree-checkbox-36">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Remote_Profiling.html">
       Work with Remote Targets
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-37" name="toctree-checkbox-37" type="checkbox"/>
      <label for="toctree-checkbox-37">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Profile_on_Remote_Machine.html">
         Profile on Remote Machine
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Setup_Remote_Target.html">
         Set Up Remote Target
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Add_Remote_Target.html">
         Register Remote Target in DL Workbench
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Remote_Machines.html">
         Manipulate Remote Machines
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Int_8_Quantization.html">
     Optimize Model Performance
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Run_Inference.html">
     Explore Inference Configurations
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-38" name="toctree-checkbox-38" type="checkbox"/>
    <label for="toctree-checkbox-38">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Run_Single_Inference.html">
       Run Inference
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_View_Inference_Results.html">
       View Inference Results
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Compare_Performance_between_Two_Versions_of_Models.html">
       Compare Performance between Two Versions of a Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Visualize_Model.html">
       Visualize Model
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Visualize_Accuracy.html">
     Visualize Model Output
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Measure_Accuracy.html">
     Create Accuracy Report
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-39" name="toctree-checkbox-39" type="checkbox"/>
    <label for="toctree-checkbox-39">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Accuracy_Configuration.html">
       Accuracy Configuration
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Configure_Accuracy_Settings.html">
       Set Accuracy Configuration
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Accuracy_Report_Results.html">
       Interpret Accuracy Report Results
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Deployment_Package.html">
     Create Deployment Package
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-40" name="toctree-checkbox-40" type="checkbox"/>
    <label for="toctree-checkbox-40">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Deploy_and_Integrate_Performance_Criteria_into_Application.html">
       Deploy and Integrate Performance Criteria into Application
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Export_Project.html">
     Export Project
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Jupyter_Notebooks_CLI.html">
     Learn OpenVINO in DL Workbench
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-41" name="toctree-checkbox-41" type="checkbox"/>
    <label for="toctree-checkbox-41">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Jupyter_Notebooks.html">
       Learn Model Inference with OpenVINO™ API in JupyterLab* Environment
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Persist_Database.html">
     Restore DL Workbench State
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_security_Workbench.html">
     Run DL Workbench Securely
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-42" name="toctree-checkbox-42" type="checkbox"/>
    <label for="toctree-checkbox-42">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Authentication.html">
       Enable Authentication in DL Workbench
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Configure_TLS.html">
       Configure Transport Layer Security (TLS)
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="workbench_docs_Workbench_DG_Troubleshooting.html">
   Troubleshooting
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-43" name="toctree-checkbox-43" type="checkbox"/>
  <label for="toctree-checkbox-43">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_DC_Troubleshooting.html">
     Troubleshooting for DL Workbench in the Intel® DevCloud for the Edge
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Media Processing and Computer Vision Libraries
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_dlstreamer.html">
   Intel® Deep Learning Streamer
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_gapi_gapi_intro.html">
   Introduction to OpenCV Graph API (G-API)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-44" name="toctree-checkbox-44" type="checkbox"/>
  <label for="toctree-checkbox-44">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_gapi_kernel_api.html">
     Graph API Kernel API
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_gapi_face_beautification.html">
     Implementing a Face Beautification Algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_gapi_gapi_face_analytics_pipeline.html">
     Building a Face Analytics Pipeline
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://docs.opencv.org/master/">
   OpenCV* Developer Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://software.intel.com/en-us/openclsdk-devguide">
   OpenCL™ Developer Guide
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Add-Ons
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="ovsa_get_started.html">
   OpenVINO™ Security Add-on
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  OpenVINO Extensibility
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_Extensibility_UG_Intro.html">
   OpenVINO Extensibility Mechanism
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-45" name="toctree-checkbox-45" type="checkbox"/>
  <label for="toctree-checkbox-45">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_Extensibility_UG_add_openvino_ops.html">
     Custom OpenVINO™ Operations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_Extensibility_UG_Frontend_Extensions.html">
     Frontend Extensions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_Extensibility_UG_GPU.html">
     How to Implement Custom GPU Operations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_IE_DG_Extensibility_DG_VPU_Kernel.html">
     How to Implement Custom Layers for VPU (Intel® Neural Compute Stick 2)
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_customize_model_optimizer_Customize_Model_Optimizer.html">
     Model Optimizer Extensibility
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-46" name="toctree-checkbox-46" type="checkbox"/>
    <label for="toctree-checkbox-46">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_customize_model_optimizer_Extending_Model_Optimizer_With_Caffe_Python_Layers.html">
       Extending Model Optimizer with Caffe* Python Layers
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_transformations.html">
   Overview of Transformations API
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-47" name="toctree-checkbox-47" type="checkbox"/>
  <label for="toctree-checkbox-47">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_Extensibility_UG_model_pass.html">
     OpenVINO Model Pass
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_Extensibility_UG_matcher_pass.html">
     OpenVINO Matcher Pass
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_Extensibility_UG_graph_rewrite_pass.html">
     OpenVINO Graph Rewrite Pass
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_ie_plugin_dg_overview.html">
   OpenVINO Plugin Developer Guide
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-48" name="toctree-checkbox-48" type="checkbox"/>
  <label for="toctree-checkbox-48">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_ie_plugin_dg_plugin.html">
     Implement Plugin Functionality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_ie_plugin_dg_executable_network.html">
     Implement Executable Network Functionality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_ie_plugin_dg_infer_request.html">
     Implement Synchronous Inference Request
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_ie_plugin_dg_async_infer_request.html">
     Implement Asynchronous Inference Request
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_ie_plugin_dg_plugin_build.html">
     Build Plugin Using CMake*
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_ie_plugin_dg_plugin_testing.html">
     Plugin Testing
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_ie_plugin_detailed_guides.html">
     Advanced Topics
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-49" name="toctree-checkbox-49" type="checkbox"/>
    <label for="toctree-checkbox-49">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_ie_plugin_dg_quantized_networks.html">
       Quantized networks compute and restrictions
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="openvino_docs_OV_UG_lpt.html">
       OpenVINO™ Low Precision Transformations
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-50" name="toctree-checkbox-50" type="checkbox"/>
      <label for="toctree-checkbox-50">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4 has-children">
        <a class="reference internal" href="openvino_docs_OV_UG_lpt_attributes.html">
         Attributes
        </a>
        <input class="toctree-checkbox" id="toctree-checkbox-51" name="toctree-checkbox-51" type="checkbox"/>
        <label for="toctree-checkbox-51">
         <i class="fas fa-chevron-down">
         </i>
        </label>
        <ul>
         <li class="toctree-l5">
          <a class="reference internal" href="openvino_docs_OV_UG_lpt_AvgPoolPrecisionPreserved.html">
           AvgPoolPrecisionPreserved
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="openvino_docs_OV_UG_lpt_IntervalsAlignment.html">
           IntervalsAlignment
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="openvino_docs_OV_UG_lpt_PrecisionPreserved.html">
           PrecisionPreserved
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="openvino_docs_OV_UG_lpt_Precisions.html">
           Precisions
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="openvino_docs_OV_UG_lpt_QuantizationAlignment.html">
           QuantizationAlignment
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="openvino_docs_OV_UG_lpt_QuantizationGranularity.html">
           QuantizationGranularity
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_lpt_step1_prerequisites.html">
         Step 1. Prerequisites transformations
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_lpt_step2_markup.html">
         Step 2. Markup transformations
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_lpt_step3_main.html">
         Step 3. Main transformations
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_lpt_step4_cleanup.html">
         Step 4. Cleanup transformations
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_ie_plugin_api_references.html">
     Plugin API Reference
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-52" name="toctree-checkbox-52" type="checkbox"/>
    <label for="toctree-checkbox-52">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="simple">
    </ul>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Use OpenVINO™ Toolkit Securely
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_security_guide_introduction.html">
   Introduction to OpenVINO™ Security
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_security_guide_workbench.html">
   Deep Learning Workbench Security
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_OV_UG_protecting_model_guide.html">
   Using Encrypted Models with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ovsa_get_started.html">
   OpenVINO™ Security Add-on
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#import-the-model">
   Import the model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#create-a-dataset">
   Create a dataset
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#analyze-the-model-inferencing-performance">
   Analyze the model inferencing performance
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#optimize-the-model">
   Optimize the model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#measure-accuracy">
   Measure Accuracy
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#create-deployment-package-with-the-model">
   Create deployment package with the model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#see-also">
   See Also
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                <div class="tocsection download-docs">
  <div class="dropdown sst-dropdown">
    <button class="button bttn-prm button-size-m" data-display="static" type="button" id="download-options"
      data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
      Download Docs
    </button>
    <div class="dropdown-menu" aria-labelledby="download-options">
      <a class="dropdown-item" href="#" onclick="window.print()">.pdf</a>
      <a id="download-zip-btn" class="dropdown-item" href="#">.zip</a>
    </div>
  </div>
</div>
              </div>
              
            
          </div>
          

          
          
              
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">

<div class="tocsection editthispage">
    <a href="None">
        <i class="fas fa-pencil-alt"></i> Edit this page
    </a>
</div>

            
                <div>
                  
  <section id="tutorial-darknet-yolov4-model">
<span id="doxid-workbench-docs-workbench-d-g-tutorial-import-y-o-l-o"></span><span id="index-0"></span><h1>Tutorial Darknet* YOLOv4 Model<a class="headerlink" href="#tutorial-darknet-yolov4-model" title="Permalink to this headline">¶</a></h1>
<p><span class="target" id="doxid-workbench-docs-workbench-d-g-tutorial-import-y-o-l-o-1md-openvino-workbench-docs-workbench-dg-import-yolo"></span> The tutorial follows the <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_Import_Original.html#doxid-workbench-docs-workbench-d-g-tutorial-import-original"><span class="std std-ref">recommendations on importing an original model</span></a> and shows how to import an original <a class="reference external" href="https://github.com/AlexeyAB/darknet/releases/tag/yolov4">Darknet* YOLOv4 model</a> of <a class="reference external" href="https://machinelearningmastery.com/object-recognition-with-deep-learning/">object detection</a> use case, and <a class="reference external" href="https://pjreddie.com/darknet/">Darknet*</a> framework.</p>
<table class="table">
<colgroup>
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 20%" />
<col style="width: 20%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Model</p></th>
<th class="head"><p>Use Case</p></th>
<th class="head"><p>Framework</p></th>
<th class="head"><p>Source</p></th>
<th class="head"><p>Dataset</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference external" href="https://github.com/AlexeyAB/darknet/releases/tag/yolov4">yolo-v4</a></p></td>
<td><p><a class="reference external" href="https://machinelearningmastery.com/object-recognition-with-deep-learning/">Object Detection</a></p></td>
<td><p><a class="reference external" href="https://pjreddie.com/darknet/">Darknet</a></p></td>
<td><p><a class="reference external" href="https://github.com/AlexeyAB/darknet/releases/tag/yolov4">Github repository</a></p></td>
<td><p><a class="reference external" href="http://openvino-docs.inn.intel.com/latest/workbench_docs_Workbench_DG_Generate_Datasets.html">Not Annotated</a></p></td>
</tr>
</tbody>
</table>
<p>In this tutorial, you will learn how to:</p>
<ol class="arabic simple">
<li><p>Import the model.</p></li>
<li><p>Create a dataset.</p></li>
<li><p>Analyze the model inferencing performance.</p></li>
<li><p>Optimize the model.</p></li>
<li><p>Analyze the model accuracy performance.</p></li>
<li><p>Create deployment package with the model.</p></li>
</ol>
<section id="import-the-model">
<h2>Import the model<a class="headerlink" href="#import-the-model" title="Permalink to this headline">¶</a></h2>
<details class="sphinx-bs dropdown card mb-3">
<summary class="summary-title card-header">
Import YOLOv4<div class="summary-down docutils">
<svg version="1.1" width="24" height="24" class="octicon octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="summary-up docutils">
<svg version="1.1" width="24" height="24" class="octicon octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="summary-content card-body docutils">
<ol class="arabic simple">
<li><p class="card-text">Obtain Model</p></li>
</ol>
<p class="card-text">Darknet model is represented as <cite>.weights</cite> and <cite>.cfg</cite> files. <a class="reference external" href="https://github.com/AlexeyAB/darknet/releases/tag/yolov4">Download</a> a pretrained model file <cite>yolov4.weights</cite> from <a class="reference external" href="https://github.com/AlexeyAB/darknet/releases/tag/yolov4">the following GitHub repository</a>.</p>
<ol class="arabic simple" start="2">
<li><p class="card-text">Convert Model to Supported Format</p></li>
</ol>
<p class="card-text">Convert the model to one of the input formats supported in the DL Workbench, for example, TensorFlow*, ONNX*, OpenVINO™ Intermediate Representation (IR), and <cite>other formats_</cite>.</p>
<p class="card-text">2.1 Find Similar Model Topology in the Open Model Zoo</p>
<p class="card-text">Since the model is not supported directly in the OpenVINO and the DL Workbench, according to the <span class="xref std std-ref">model import recommendations</span>, you need to convert it to a supported format. To do that, look for a similar topology in the <a class="reference external" href="https://github.com/openvinotoolkit/open_model_zoo">Open Model Zoo repository</a>.</p>
<p class="card-text">Go to the <a class="reference external" href="https://docs.openvino.ai/latest/omz_models_group_public.html">Open Model Zoo (OMZ) documentation</a> , find <a class="reference external" href="https://docs.openvino.ai/latest/omz_models_model_yolo_v4_tf.html">YOLOv4</a> model, and use the information to get the required model description:</p>
<ul class="simple">
<li><p class="card-text">which input format should be used ​for the model of your framework</p></li>
<li><p class="card-text">how to convert the model to this format</p></li>
<li><p class="card-text">how to configure accuracy of the model</p></li>
</ul>
<p class="card-text">2.2  Find Converter Parameters</p>
<p class="card-text">Open <cite>model.yml</cite> file in the <a class="reference external" href="https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/public/yolo-v4-tf/model.yml">OMZ repository</a>, and find the information on the model input format. Here you can see that the required format for the YOLOv4 model is SavedModel:</p>
<img alt="pages/_static/images/yml_file_info.png" src="pages/_static/images/yml_file_info.png" />
<p class="card-text">Open the <cite>pre-convert.py</cite> <a class="reference external" href="https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/public/yolo-v4-tf/pre-convert.py">file</a>, and find the parameters required to use the converter: the configuration file, the weights file, and the path to the converted model.</p>
<img alt="pages/_static/images/required_params.png" src="pages/_static/images/required_params.png" />
<p class="card-text">2.3 Download Darknet-to-TensorFlow Converter</p>
<p class="card-text">Go to the <a class="reference external" href="https://github.com/david8862/keras-YOLOv3-model-set">converter repository</a> and clone it:</p>
<div class="tab-set docutils">
<input checked="True" class="tab-input" id="tab-set--0-input--1" name="tab-set--0" type="radio"><label class="tab-label" for="tab-set--0-input--1">macOS, Linux</label><div class="tab-content docutils">
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>git clone https://github.com/david8862/keras-YOLOv3-model-set.git
</pre></div>
</div>
</div>
<input class="tab-input" id="tab-set--0-input--2" name="tab-set--0" type="radio"><label class="tab-label" for="tab-set--0-input--2">Windows</label><div class="tab-content docutils">
<div class="highlight-bat notranslate"><div class="highlight"><pre><span></span>git clone https://github.com/david8862/keras-YOLOv3-model-set.git
</pre></div>
</div>
</div>
</div>
<p class="card-text">2.4 Optional. Prepare Virtual Environment</p>
<p class="card-text">Install Virtual Environment</p>
<div class="tab-set docutils">
<input checked="True" class="tab-input" id="tab-set--1-input--1" name="tab-set--1" type="radio"><label class="tab-label" for="tab-set--1-input--1">macOS, Linux</label><div class="tab-content docutils">
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>python3 -m pip install virtualenv
</pre></div>
</div>
</div>
<input class="tab-input" id="tab-set--1-input--2" name="tab-set--1" type="radio"><label class="tab-label" for="tab-set--1-input--2">Windows</label><div class="tab-content docutils">
<div class="highlight-bat notranslate"><div class="highlight"><pre><span></span>python -m pip install virtualenv
</pre></div>
</div>
</div>
</div>
<p class="card-text">Create Virtual Environment</p>
<div class="tab-set docutils">
<input checked="True" class="tab-input" id="tab-set--2-input--1" name="tab-set--2" type="radio"><label class="tab-label" for="tab-set--2-input--1">macOS, Linux</label><div class="tab-content docutils">
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>python3 -m virtualenv venv
</pre></div>
</div>
</div>
<input class="tab-input" id="tab-set--2-input--2" name="tab-set--2" type="radio"><label class="tab-label" for="tab-set--2-input--2">Windows</label><div class="tab-content docutils">
<div class="highlight-bat notranslate"><div class="highlight"><pre><span></span>python -m virtualenv venv
</pre></div>
</div>
</div>
</div>
<p class="card-text">Activate Virtual Environment</p>
<div class="tab-set docutils">
<input checked="True" class="tab-input" id="tab-set--3-input--1" name="tab-set--3" type="radio"><label class="tab-label" for="tab-set--3-input--1">macOS, Linux</label><div class="tab-content docutils">
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="nb">source</span> venv/bin/activate
</pre></div>
</div>
</div>
<input class="tab-input" id="tab-set--3-input--2" name="tab-set--3" type="radio"><label class="tab-label" for="tab-set--3-input--2">Windows</label><div class="tab-content docutils">
<div class="highlight-bat notranslate"><div class="highlight"><pre><span></span>venv\Scripts\activate
</pre></div>
</div>
</div>
</div>
<p class="card-text">2.5 Install Requirements</p>
<p class="card-text">Go to the <cite>requirements.txt</cite> file to find the converter dependencies. Adjust it for your system, if necessary. For example, if you do not have a GPU device, change <cite>tensorflow-gpu</cite> dependency to <cite>tensorflow</cite>. Install the requirements:</p>
<div class="tab-set docutils">
<input checked="True" class="tab-input" id="tab-set--4-input--1" name="tab-set--4" type="radio"><label class="tab-label" for="tab-set--4-input--1">macOS, Linux</label><div class="tab-content docutils">
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>python3 -m pip install -r ./keras-YOLOv3-model-set/requirements.txt
</pre></div>
</div>
</div>
<input class="tab-input" id="tab-set--4-input--2" name="tab-set--4" type="radio"><label class="tab-label" for="tab-set--4-input--2">Windows</label><div class="tab-content docutils">
<div class="highlight-bat notranslate"><div class="highlight"><pre><span></span>python -m pip install -r .\keras-YOLOv3-model-set\requirements.txt
</pre></div>
</div>
</div>
</div>
<p class="card-text">2.6 Convert Darknet Model to TensorFlow</p>
<p class="card-text">Run the converter by providing the paths to the configuration file, the pretrained model file, and the converted model.</p>
<p class="card-text">In case you fine-tuned your model based on the publicly available configuration file of the Yolov4, you also need to use <cite>–yolo4_reorder</cite> flag. If you did not, open the configuration file <cite>yolov4.cfg</cite> and check the order of  <cite>yolo</cite> layers. If the <cite>yolo</cite> layers are described in ascending order, then you can proceed without this flag. Otherwise, you need to use it.</p>
<div class="tab-set docutils">
<input checked="True" class="tab-input" id="tab-set--5-input--1" name="tab-set--5" type="radio"><label class="tab-label" for="tab-set--5-input--1">Does not require reordering:</label><div class="tab-content docutils">
<img alt="pages/_static/images/layers_yolov3.png" src="pages/_static/images/layers_yolov3.png" />
</div>
<input class="tab-input" id="tab-set--5-input--2" name="tab-set--5" type="radio"><label class="tab-label" for="tab-set--5-input--2">Requires reordering:</label><div class="tab-content docutils">
<img alt="pages/_static/images/layers_yolov4.png" src="pages/_static/images/layers_yolov4.png" />
</div>
</div>
<p class="card-text">Organize the folders and files as follows and execute the code in the terminal or PowerShell:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span><span class="p">|</span>-- keras-YOLOv3-model-set
   <span class="p">|</span>-- tools
         <span class="p">|</span>-- model_converter
            <span class="p">|</span>-- convert.py
   <span class="p">|</span>-- cfg
   <span class="p">|</span>-- yolov4.cfg
  <span class="p">|</span>-- yolov4.weights
<span class="p">|</span>-- saved_model
</pre></div>
</div>
<p class="card-text">Run the converter:</p>
<div class="tab-set docutils">
<input checked="True" class="tab-input" id="tab-set--6-input--1" name="tab-set--6" type="radio"><label class="tab-label" for="tab-set--6-input--1">macOS, Linux</label><div class="tab-content docutils">
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>python keras-YOLOv3-model-set/tools/model_converter/convert.py keras-YOLOv3-model-set/cfg/yolov4.cfg yolov4.weights yolov4.savedmodel --yolo4_reorder
</pre></div>
</div>
</div>
<input class="tab-input" id="tab-set--6-input--2" name="tab-set--6" type="radio"><label class="tab-label" for="tab-set--6-input--2">Windows</label><div class="tab-content docutils">
<div class="highlight-bat notranslate"><div class="highlight"><pre><span></span>python keras-YOLOv3-model-set\tools\model_converter\convert.py keras-YOLOv3-model-set\cfg\yolov4.cfg yolov4.weights yolov4.savedmodel --yolo4_reorder
</pre></div>
</div>
</div>
</div>
<ol class="arabic simple" start="3">
<li><p class="card-text">Upload Model</p></li>
</ol>
<p class="card-text">Open the DL Workbench in your browser and click <strong>Create Project</strong> on the Start Page.</p>
<img alt="pages/_static/images/start_page_dl_wb.png" src="pages/_static/images/start_page_dl_wb.png" />
<p class="card-text">On the Create Project page, select <strong>Import Model</strong>.</p>
<img alt="pages/_static/images/import_model.png" src="pages/_static/images/import_model.png" />
<p class="card-text">Open <strong>Original Model</strong> tab:</p>
<ul class="simple">
<li><p class="card-text">Select <strong>TensorFlow</strong> framework and <strong>2.X TensorFlow</strong> version.</p></li>
<li><p class="card-text">Click <strong>Select Folder</strong> and provide the folder with the model in SavedModel format. Make sure you selected the folder, <strong>not</strong> the files it contains, and click <strong>Import</strong>.</p></li>
</ul>
<img alt="pages/_static/images/import_yolov4.png" src="pages/_static/images/import_yolov4.png" />
<div class="admonition note">
<p class="admonition-title">Note</p>
<p class="card-text">To work with OpenVINO tools, you need to obtain a model in Intermediate Representation (IR) format.  IR is the OpenVINO format of pre-trained model representation with two files: XML file describing the network topology and BIN file containing weights.</p>
</div>
<p class="card-text">Specify model parameters:</p>
<ul class="simple">
<li><p class="card-text">Select <strong>RGB</strong> color space in <em>General Parameters</em> since it was used during model training</p></li>
</ul>
<img alt="pages/_static/images/rgb.png" src="pages/_static/images/rgb.png" />
<ul class="simple">
<li><p class="card-text">Specify Inputs:</p></li>
</ul>
<img alt="pages/_static/images/inputs_defined.png" src="pages/_static/images/inputs_defined.png" />
<ul class="simple">
<li><p class="card-text">Check Specify Inputs (Optional)</p></li>
<li><p class="card-text">Select NHWC layout as the Original Layout</p></li>
<li><p class="card-text">Set the following parameters:</p></li>
<li><p class="card-text">N = 1: number of images in the batch</p></li>
<li><p class="card-text">H = 608: image height</p></li>
<li><p class="card-text">W = 608: image width</p></li>
<li><p class="card-text">C = 3: number of channels, RGB</p></li>
<li><p class="card-text">Set scales to <strong>255</strong> as specified in the Darknet <a class="reference external" href="https://github.com/AlexeyAB/darknet/blob/ca43bbdaaede5c9cbf82a8a0aa5e2d0a4bdcabc0/src/image.c#L957">sources</a>:</p></li>
</ul>
<img alt="pages/_static/images/scales.png" src="pages/_static/images/scales.png" />
<ul class="simple">
<li><p class="card-text">Click <strong>Convert and Import</strong></p></li>
</ul>
<p class="card-text">You will be redirected to the <em>Create Project</em> page where you can see the status of the model import.</p>
<p class="card-text"><strong>Optional. Visualize Model</strong></p>
<p class="card-text">To check how your model works and explore its properties, click <em>Open</em> under the <em>Actions</em> column.</p>
<img alt="pages/_static/images/open_yolo_model.png" src="pages/_static/images/open_yolo_model.png" />
<p class="card-text">Upload your image and check the prediction boxes to evaluate the model:</p>
<img alt="pages/_static/images/check_yolo_model.png" src="pages/_static/images/check_yolo_model.png" />
<div class="admonition note">
<p class="admonition-title">Note</p>
<p class="card-text">If the imported model predicts the right classes, but the boxes are not aligned with the objects in the image, you might have missed scales and means parameters during import. Refer to the <a class="reference external" href="https://github.com/openvinotoolkit/open_model_zoo">OMZ documentation</a> and try to import the model again.</p>
</div>
<p class="card-text">Go back to the <strong>Create Project</strong> page, click on the model to select it and proceed to the <strong>Next Step</strong>.</p>
<img alt="pages/_static/images/yolov4_imported.png" src="pages/_static/images/yolov4_imported.png" />
<p class="card-text">On the Select Environment stage you can choose a hardware accelerator on which the model will be executed.</p>
<img alt="pages/_static/images/select_environment.png" src="pages/_static/images/select_environment.png" />
</div>
</details></section>
<section id="create-a-dataset">
<h2>Create a dataset<a class="headerlink" href="#create-a-dataset" title="Permalink to this headline">¶</a></h2>
<details class="sphinx-bs dropdown card mb-3">
<summary class="summary-title card-header">
Upload Not Annotated Dataset<div class="summary-down docutils">
<svg version="1.1" width="24" height="24" class="octicon octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="summary-up docutils">
<svg version="1.1" width="24" height="24" class="octicon octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="summary-content card-body docutils">
<p class="card-text">Validation of the model is always performed against specific data combined into datasets. The data can be in different formats, depending on the task for which the model has been trained. Learn more in the Dataset Types documentation.</p>
<p class="card-text">On the third step, click <strong>Import Image Dataset</strong>.</p>
<img alt="pages/_static/images/import_image_dataset.png" src="pages/_static/images/import_image_dataset.png" />
<p class="card-text">For this tutorial, we will create a Not Annotated dataset with default images from the DL Workbench. Add images representing your specific use case and use augmentation, if necessary. Click <strong>Import</strong>.</p>
<img alt="pages/_static/images/dataset.png" src="pages/_static/images/dataset.png" />
<p class="card-text">Select the dataset by clicking on it, and click <strong>Create Project</strong>.</p>
<img alt="pages/_static/images/create_project_yolo.png" src="pages/_static/images/create_project_yolo.png" />
</div>
</details></section>
<section id="analyze-the-model-inferencing-performance">
<h2>Analyze the model inferencing performance<a class="headerlink" href="#analyze-the-model-inferencing-performance" title="Permalink to this headline">¶</a></h2>
<details class="sphinx-bs dropdown card mb-3" open="open">
<summary class="summary-title card-header">
Measure inferencing performance and learn about streams and batches<div class="summary-down docutils">
<svg version="1.1" width="24" height="24" class="octicon octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="summary-up docutils">
<svg version="1.1" width="24" height="24" class="octicon octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="summary-content card-body docutils">
<p class="card-text">When the baseline inference stage is finished, we can see the results of running our model on the CPU. We are interested in two metrics: <strong>latency</strong> and <strong>throughput</strong>.</p>
<ul class="simple">
<li><p class="card-text">Latency is the time required to process one image. The lower the value, the better.</p></li>
<li><p class="card-text">Throughput is the number of images (frames) processed per second. Higher throughput value means better performance.</p></li>
</ul>
<img alt="pages/_static/images/performance.png" src="pages/_static/images/performance.png" />
<p class="card-text"><strong>Streams</strong> are the number of instances of your model running simultaneously, and <strong>batches</strong> are the number of input data instances fed to the model.</p>
<p class="card-text">DL Workbench automatically selects the parameters to achieve a near-optimal model performance. You can further accelerate your model by <span class="xref std std-ref">configuring the optimal parameters specific to each accelerator</span>.</p>
</div>
</details></section>
<section id="optimize-the-model">
<h2>Optimize the model<a class="headerlink" href="#optimize-the-model" title="Permalink to this headline">¶</a></h2>
<details class="sphinx-bs dropdown card mb-3" open="open">
<summary class="summary-title card-header">
Optimize performance using INT8 Calibration<div class="summary-down docutils">
<svg version="1.1" width="24" height="24" class="octicon octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="summary-up docutils">
<svg version="1.1" width="24" height="24" class="octicon octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="summary-content card-body docutils">
<p class="card-text">One of the common ways to accelerate your model performance is to use <strong>8-bit integer (INT8) calibration</strong>. Calibration is the process of lowering the model precision by converting floating-point operations (for example, 32-bit or 16-bit operations) to the nearest 8-bit integer operations. INT8 Calibration accelerates Deep Learning inference while reducing the model size at the cost of accuracy drop.</p>
<p class="card-text">To calibrate a model and then execute it in the INT8 precision, open <strong>Optimize Performance</strong> tab and click <strong>Configure Optimization</strong> button.</p>
<img alt="pages/_static/images/optimize_face_detection.png" src="pages/_static/images/optimize_face_detection.png" />
<p class="card-text">The <strong>Default Method</strong> and <strong>Performance Preset</strong> are already selected to achieve better performance results. Click <strong>Optimize</strong>:</p>
<img alt="pages/_static/images/optimization_settings.png" src="pages/_static/images/optimization_settings.png" />
<p class="card-text">The project with the <strong>optimized yolov4 model</strong> page opens automatically. To check the performance boost after optimization, go to <strong>Perform</strong> tab and open <strong>Optimize Performance</strong> subtab.</p>
<img alt="pages/_static/images/performance_change.jpeg" src="pages/_static/images/performance_change.jpeg" />
<p class="card-text">From the optimization results, we see that our model has become <strong>2.51x</strong> time faster and takes up <strong>1.47x</strong> times less memory. Let’s proceed to the next step and check the optimized model accuracy.</p>
</div>
</details></section>
<section id="measure-accuracy">
<h2>Measure Accuracy<a class="headerlink" href="#measure-accuracy" title="Permalink to this headline">¶</a></h2>
<details class="sphinx-bs dropdown card mb-3" open="open">
<summary class="summary-title card-header">
Compare optimized and original model accuracy performance<div class="summary-down docutils">
<svg version="1.1" width="24" height="24" class="octicon octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="summary-up docutils">
<svg version="1.1" width="24" height="24" class="octicon octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="summary-content card-body docutils">
<p class="card-text">Go to the <strong>Perform</strong> tab and select <strong>Create Accuracy Report</strong>:</p>
<img alt="pages/_static/images/accuracy_yolov4.png" src="pages/_static/images/accuracy_yolov4.png" />
<p class="card-text">Comparison of Optimized and Parent Model Predictions Report allows you to find out on which validation dataset images the predictions of the model have become different after optimization.</p>
<p class="card-text">To enable the creation of this report type, change your model use case in the accuracy configuration. DL Workbench automatically detects Object Detection use case and other parameters for your model. Click <strong>Save</strong>:</p>
<img alt="pages/_static/images/config_filled.png" src="pages/_static/images/config_filled.png" />
<p class="card-text">You will be redirected back to the <strong>Create Accuracy Report</strong> page. Select <strong>Comparison of Optimized and Parent Model Predictions</strong> and click <strong>Create Accuracy Report</strong>:</p>
<img alt="pages/_static/images/create_report_yolo.png" src="pages/_static/images/create_report_yolo.png" />
<p class="card-text">Accuracy measurements are performed on each dataset image. Creating an Accuracy Report may take some time if the dataset is considerably big.</p>
<p class="card-text"><strong>Interpret Report Results</strong></p>
<p class="card-text">The report has two display options: Basic and Advanced mode. To learn more about each column of the Accuracy Report, refer to Interpreting Accuracy Report page.</p>
<p class="card-text">Each line of the report table in basic mode contains a number of detected objects in the image: <strong>A. Optimized Model Detections</strong>. The number of objects in Parent model predictions for the image is indicated in <strong>B. Parent Model Detections</strong>. If the numbers do not match, the model must be incorrect.</p>
<p class="card-text">To assess the difference between Optimized and Parent model predictions, check <strong>Matches between A and B</strong>. Matches show the number of times the Optimized model detected the same location of an object as the Parent Model.</p>
<img alt="pages/_static/images/accuracy_table_yolo_basic.png" src="pages/_static/images/accuracy_table_yolo_basic.png" />
<div class="admonition note">
<p class="admonition-title">Note</p>
<p class="card-text">To sort the numbers from lowest to highest, click on the parameter name in the table.</p>
</div>
<p class="card-text">Click <strong>Visualize</strong> button under the <strong>Actions</strong> column to compare the predictions and annotations for a particular image.</p>
<img alt="pages/_static/images/detections_yolo_true.png" src="pages/_static/images/detections_yolo_true.png" />
<p class="card-text">In our case, the <cite>YOLOv4</cite> model detected 2 objects of class 18 (sheep). These detections coincide with the dataset annotations: 2 objects of the same class as predicted by the model. The number of matches also equals 2. In the image, it is shown by almost identical bounding boxes for each object.</p>
<img alt="pages/_static/images/yolo_detection_false.png" src="pages/_static/images/yolo_detection_false.png" />
<p class="card-text">Let’s consider another example image. The model detected 1 objects of class 4 (airplane). But in the image, you can see that the bounding  is noticeably different from the parent model prediction.</p>
<p class="card-text">After evaluating the accuracy, you can decide whether the difference between imported and optimized models predictions is critical or not:</p>
<ul class="simple">
<li><p class="card-text">If the tradeoff between accuracy and performance is too big, import an annotated dataset  and use AccuracyAware optimization method, then repeat the steps from this tutorial.</p></li>
<li><p class="card-text">If the tradeoff is acceptable, explore inference configurations to further enhance the performance. Then create a deployment package with your ready-to-deploy model.</p></li>
</ul>
</div>
</details></section>
<section id="create-deployment-package-with-the-model">
<h2>Create deployment package with the model<a class="headerlink" href="#create-deployment-package-with-the-model" title="Permalink to this headline">¶</a></h2>
<details class="sphinx-bs dropdown card mb-3">
<summary class="summary-title card-header">
Prepare a runtime for your application<div class="summary-down docutils">
<svg version="1.1" width="24" height="24" class="octicon octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="summary-up docutils">
<svg version="1.1" width="24" height="24" class="octicon octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="summary-content card-body docutils">
<p class="card-text">OpenVINO allows to obtain a customized runtime to prepare an application for production. Open <strong>Create Deployment Package</strong> tab and include the necessary components to get a snapshot of OpenVINO runtime ready for deployment into a business application.</p>
<img alt="pages/_static/images/pack.png" src="pages/_static/images/pack.png" />
</div>
</details></section>
<section id="see-also">
<h2>See Also<a class="headerlink" href="#see-also" title="Permalink to this headline">¶</a></h2>
<p>Congratulations! You have completed the DL Workbench workflow for yolov4 model. Additionally, you can try the following capabilities:</p>
<ul class="simple">
<li><p><a class="reference internal" href="workbench_docs_Workbench_DG_Jupyter_Notebooks_CLI.html#doxid-workbench-docs-workbench-d-g-jupyter-notebooks-c-l-i"><span class="std std-ref">Learn OpenVINO CLI and API in Jupyter Notebooks</span></a></p></li>
<li><p><a class="reference internal" href="workbench_docs_Workbench_DG_Run_Single_Inference.html#doxid-workbench-docs-workbench-d-g-run-single-inference"><span class="std std-ref">Explore inference configurations</span></a></p></li>
<li><p><a class="reference internal" href="workbench_docs_Workbench_DG_Deploy_and_Integrate_Performance_Criteria_into_Application.html#doxid-workbench-docs-workbench-d-g-deploy-and-integrate-performance-criteria-into-application"><span class="std std-ref">Write sample application with your model using OpenVINO Python or C++ API</span></a></p></li>
<li><p><a class="reference internal" href="workbench_docs_Workbench_DG_Visualize_Model.html#doxid-workbench-docs-workbench-d-g-visualize-model"><span class="std std-ref">Analyze and visualize model structure</span></a></p></li>
</ul>
</section>
</section>


                </div>
            
            
                <div class='prev-next-bottom'>
                  
    <a class='button bttn-sec button-size-l' id="prev-link" href="workbench_docs_Workbench_DG_Tutorials.html" title="previous page">Prev</a>
    <a class='button bttn-sec button-size-l' id="next-link" href="workbench_docs_Workbench_DG_Measure_Accuracy_Object_detection.html" title="next page">Next</a>

                </div>
            
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, Intel®.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.2.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>