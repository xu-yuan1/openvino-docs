
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Converting TensorFlow Object Detection API Models &#8212; OpenVINO™  documentation</title>
    
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <link rel="stylesheet" type="text/css" href="../_static/doxyrest-pygments.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <link href="../_static/css/media/favicon.ico" rel="shortcut icon">
    <link rel="stylesheet" href="../_static/css/openvino_sphinx_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/button.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/input.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/textfield.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/tabs.css" type="text/css" />
    <script src="../_static/js/openvino_sphinx_theme.js"></script>
    <link rel="stylesheet" href="../_static/css/viewer.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />

    <script src="https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-datalabels"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/chartjs-plugin-annotation/0.5.7/chartjs-plugin-annotation.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-barchart-background@1.3.0/build/Plugin.Barchart.Background.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-deferred@1"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/PapaParse/5.3.1/papaparse.min.js"></script>
    <script src="../_static/js/viewer.min.js"></script>
    <script src="/assets/versions_raw.js"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/tabs.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/js/custom.js"></script>
    <script src="../_static/js/graphs.js"></script>
    <script src="../_static/js/graphs_ov_tf.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/target-highlight.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <link rel="canonical" href="https://docs.openvino.ai/latest/pages/openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_Object_Detection_API_Models.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Converting a TensorFlow RetinaNet Model" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_RetinaNet_From_Tensorflow.html" />
    <link rel="prev" title="Converting a TensorFlow Neural Collaborative Filtering Model" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_NCF_From_Tensorflow.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
      <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/logo.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="documentation.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../tutorials.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/api_reference.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../model_zoo.html">
  Model Zoo
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="resources.html">
  Resources
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/openvinotoolkit/openvino" rel="noopener" target="_blank" title="GitHub">
            <span><i class="sst-github"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
</ul>
      </div>
      
      <div class="navbar-end-item">
        
<div class="dropdown sst-dropdown sst-dropdown-navbar">
  <button class="btn sst-btn dropdown-toggle" type="button" id="version-selector" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"></button>
  <div class="dropdown-menu" aria-labelledby="version-selector">
  </div>
</div>
      </div>
      
      <div class="navbar-end-item">
        

<div class="dropdown sst-dropdown sst-dropdown-navbar">
  <button class="btn sst-btn dropdown-toggle" type="button" id="language-selector" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">English</button>
  <div class="dropdown-menu" aria-labelledby="language-selector">
    
      
        <a class="dropdown-item font-weight-bold" href="/latest/pages/openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_Object_Detection_API_Models.html">English</a>
      
    
      
        <a  class="dropdown-item" href="/cn/latest/pages/openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_Object_Detection_API_Models.html">Chinese</a>
      
    
  </div>
</div>

      </div>
      
    </div>
  </div>
</div>
        <div id="collapse-nav-wrapper" class="container-xl">
          <button id="collapse-nav" class="button bttn-prm button-size-m" type="button" data-toggle="collapse" data-target="#nav-tree" aria-expanded="false" aria-controls="nav-tree">
            Documentation navigation <i class="fas fa-chevron-down"></i>
          </button>
        </div>
      </nav>
      <div class="transition-banner container-fluid alert alert-info alert-dismissible fade show" role="alert">
        <p>OpenVINO 2022.1 introduces a new version of OpenVINO API (API 2.0). For more information on the changes and transition steps, see the <a href="https://docs.openvino.ai/latest/openvino_2_0_transition_guide.html">transition guide</a></p>
        <button type="button" class="close" data-dismiss="alert" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
    </div>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar" id="nav-tree"><form class="searchForm bd-search d-flex align-items-center" action="../search.html" method="get">
    <i class="icon fas fa-search"></i>
    <input type="search" class="form-control" name="query" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  API 2.0
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_2_0_transition_guide.html">
   OpenVINO™ API 2.0 Transition Guide
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_2_0_deployment.html">
     Installation &amp; Deployment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_2_0_inference_pipeline.html">
     Inference Pipeline
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_2_0_configure_devices.html">
     Configuring Devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_2_0_preprocessing.html">
     Preprocessing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_2_0_model_creation.html">
     Model Creation in OpenVINO™ Runtime
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Converting and Preparing Models
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_model_processing_introduction.html">
   Introduction to Model Processing
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html">
   Converting Models with Model Optimizer
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Converting_Model.html">
     Setting Input Shapes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_Model_Optimization_Techniques.html">
     Model Optimization Techniques
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Cutting_Model.html">
     Cutting Off Parts of a Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_Additional_Optimization_Use_Cases.html">
     Embedding Preprocessing Computation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_FP16_Compression.html">
     Compressing a Model to FP16
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_TensorFlow.html">
     Converting a TensorFlow Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_ONNX.html">
     Converting an ONNX Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_PyTorch.html">
     Converting a PyTorch Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_Paddle.html">
     Converting a PaddlePaddle Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_MxNet.html">
     Converting an MXNet Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_Caffe.html">
     Converting a Caffe Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_Kaldi.html">
     Converting a Kaldi Model
    </a>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tutorials.html">
     Model Conversion Tutorials
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_AttentionOCR_From_Tensorflow.html">
       Converting a TensorFlow Attention OCR Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_BERT_From_Tensorflow.html">
       Converting a TensorFlow BERT Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_CRNN_From_Tensorflow.html">
       Converting a TensorFlow CRNN Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_DeepSpeech_From_Tensorflow.html">
       Converting a TensorFlow DeepSpeech Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_EfficientDet_Models.html">
       Converting TensorFlow EfficientDet Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_FaceNet_From_Tensorflow.html">
       Converting TensorFlow FaceNet Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_GNMT_From_Tensorflow.html">
       Converting a TensorFlow GNMT Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_lm_1b_From_Tensorflow.html">
       Converting a TensorFlow Language Model on One Billion Word Benchmark
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_NCF_From_Tensorflow.html">
       Converting a TensorFlow Neural Collaborative Filtering Model
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       Converting TensorFlow Object Detection API Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_RetinaNet_From_Tensorflow.html">
       Converting a TensorFlow RetinaNet Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_Slim_Library_Models.html">
       Converting TensorFlow Slim Image Classification Model Library Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_WideAndDeep_Family_Models.html">
       Converting TensorFlow Wide and Deep Family Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_XLNet_From_Tensorflow.html">
       Converting a TensorFlow XLNet Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_YOLO_From_Tensorflow.html">
       Converting TensorFlow YOLO Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_onnx_specific_Convert_Faster_RCNN.html">
       Converting an ONNX Faster R-CNN Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_onnx_specific_Convert_GPT2.html">
       Converting an ONNX GPT-2 Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_onnx_specific_Convert_Mask_RCNN.html">
       Converting an ONNX Mask R-CNN Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_Bert_ner.html">
       Converting a PyTorch BERT-NER Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_Cascade_RCNN_res101.html">
       Converting a PyTorch Cascade RCNN R-101 Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_F3Net.html">
       Converting a PyTorch F3Net Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_QuartzNet.html">
       Converting a PyTorch QuartzNet Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_RCAN.html">
       Converting a PyTorch RCAN Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_RNNT.html">
       Converting a PyTorch RNN-T Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_YOLACT.html">
       Converting a PyTorch YOLACT Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_mxnet_specific_Convert_GluonCV_Models.html">
       Converting MXNet GluonCV Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_mxnet_specific_Convert_Style_Transfer_From_MXNet.html">
       Converting an MXNet Style Transfer Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_kaldi_specific_Aspire_Tdnn_Model.html">
       Converting a Kaldi ASpIRE Chain Time Delay Neural Network (TDNN) Model
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_Model_Optimizer_FAQ.html">
     Model Optimizer Frequently Asked Questions
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Optimization and Performance
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_optimization_guide_dldt_optimization_guide.html">
   Introduction to Performance Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_MO_DG_Getting_Performance_Numbers.html">
   Getting Performance Numbers
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_model_optimization_guide.html">
   Model Optimization Guide
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="pot_introduction.html">
     Optimizing models post-training
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="pot_default_quantization_usage.html">
       Quantizing Model
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
      <label for="toctree-checkbox-6">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="pot_compression_algorithms_quantization_default_README.html">
         DefaultQuantization Method
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="pot_accuracyaware_usage.html">
       Quantizing Model with Accuracy Control
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
      <label for="toctree-checkbox-7">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="accuracy_aware_README.html">
         AccuracyAwareQuantization Method
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="pot_docs_BestPractices.html">
       Quantization Best Practices
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
      <label for="toctree-checkbox-8">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="pot_saturation_issue.html">
         Saturation Issue
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="pot_compression_api_README.html">
       API Reference
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="pot_compression_cli_README.html">
       Command-line Interface
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
      <label for="toctree-checkbox-9">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="pot_docs_simplified_mode.html">
         Simplified Mode
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="pot_configs_README.html">
         Configuration File Description
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="pot_examples_description.html">
       Examples
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
      <label for="toctree-checkbox-10">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4 has-children">
        <a class="reference internal" href="pot_example_README.html">
         API Examples
        </a>
        <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
        <label for="toctree-checkbox-11">
         <i class="fas fa-chevron-down">
         </i>
        </label>
        <ul>
         <li class="toctree-l5">
          <a class="reference internal" href="pot_example_classification_README.html">
           Quantizatiing Image Classification Model
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="pot_example_object_detection_README.html">
           Quantizatiing Object Detection Model with Accuracy Control
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="pot_example_face_detection_README.html">
           Quantizatiing Cascaded Model
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="pot_example_segmentation_README.html">
           Quantizatiing Semantic Segmentation Model
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="pot_example_3d_segmentation_README.html">
           Quantizatiing 3D Segmentation Model
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="pot_example_speech_README.html">
           Quantizatiing for GNA Device
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="pot_configs_examples_README.html">
         Command-line Example
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="pot_docs_FrequentlyAskedQuestions.html">
       Post-training Optimization Tool Frequently Asked Questions
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="docs_nncf_introduction.html">
     Neural Network Compression Framework
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="pot_range_supervision_README.html">
     (Experimental) Protecting Model
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_deployment_optimization_guide_dldt_optimization_guide.html">
   Runtime Inference Optimizations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_deployment_optimization_guide_common.html">
     General Optimizations
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_deployment_optimization_guide_latency.html">
     Optimizing for the Latency
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
    <label for="toctree-checkbox-13">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Model_caching_overview.html">
       Model Caching Overview
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_deployment_optimization_guide_tput.html">
     Optimizing for Throughput
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_deployment_optimization_guide_tput_advanced.html">
     Using Advanced Throughput Options: Streams and Batching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_deployment_optimization_guide_internals.html">
     Further Low-Level Implementation Details
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_tuning_utilities.html">
   Tuning Utilities
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
  <label for="toctree-checkbox-14">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_inference_engine_tools_cross_check_tool_README.html">
     Cross Check Tool
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_performance_benchmarks.html">
   Performance Benchmarks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_performance_benchmarks_openvino.html">
     Intel® Distribution of OpenVINO™ toolkit Benchmark Results
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
    <label for="toctree-checkbox-16">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_performance_benchmarks_faq.html">
       Performance Information Frequently Asked Questions
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference external" href="https://docs.openvino.ai/downloads/benchmark_files/OV-2022.1-Download-Excel.xlsx">
       Download Performance Data Spreadsheet in MS Excel Format
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_performance_int8_vs_fp32.html">
       Model Accuracy for INT8 and FP32 Precision
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_performance_benchmarks_ovms.html">
     OpenVINO™ Model Server Benchmark Results
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Deploying Inference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_deployment_guide_introduction.html">
   Introduction to OpenVINO™ Deployment
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_OV_UG_OV_Runtime_User_Guide.html">
   Performing Inference with OpenVINO Runtime
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_OV_UG_Integrate_OV_with_your_application.html">
     Integrate OpenVINO™ with Your Application
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
    <label for="toctree-checkbox-18">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Model_Representation.html">
       Model Representation in OpenVINO™ Runtime
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Infer_request.html">
       OpenVINO™ Inference Request
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Python_API_exclusives.html">
       OpenVINO™ Python API Exclusives
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_OV_UG_ShapeInference.html">
     Changing Input Shapes
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_OV_UG_Working_with_devices.html">
     Working with devices
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
    <label for="toctree-checkbox-19">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_query_api.html">
       Query Device Properties - Configuration
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_CPU.html">
       CPU Device
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_GPU.html">
       GPU Device
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
      <label for="toctree-checkbox-20">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_GPU_RemoteTensor_API.html">
         Remote Tensor API of GPU Plugin
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_VPU.html">
       VPU Devices
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
      <label for="toctree-checkbox-21">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_MYRIAD.html">
         MYRIAD Device
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_HDDL.html">
         HDDL Device
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_GNA.html">
       GNA Device
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_ARM_CPU.html">
       Arm® CPU Device
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_OV_UG_Preprocessing_Overview.html">
     Optimize Preprocessing
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
    <label for="toctree-checkbox-22">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Preprocessing_Details.html">
       Preprocessing API - details
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Layout_Overview.html">
       Layout API Overview
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Preprocess_Usecase_save.html">
       Use Case - Integrate and Save Preprocessing Steps Into IR
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_OV_UG_DynamicShapes.html">
     Dynamic Shapes
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
    <label for="toctree-checkbox-23">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_NoDynamicShapes.html">
       When Dynamic Shapes API is Not Applicable
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_AUTO.html">
     Automatic Device Selection
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
    <label for="toctree-checkbox-24">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_AUTO_debugging.html">
       Debugging Auto-Device Plugin
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_OV_UG_Running_on_multiple_devices.html">
     Running on Multiple Devices Simultaneously
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_OV_UG_Hetero_execution.html">
     Heterogeneous execution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_OV_UG_Performance_Hints.html">
     High-level Performance Hints
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_OV_UG_Automatic_Batching.html">
     Automatic Batching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_OV_UG_network_state_intro.html">
     Stateful models
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_deployment_guide.html">
   Deploying Your Applications with OpenVINO™
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
  <label for="toctree-checkbox-25">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_install_guides_deployment_manager_tool.html">
     Deploying Your Application with Deployment Manager
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_deploy_local_distribution.html">
     Libraries for Local Distribution
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_inference_engine_tools_compile_tool_README.html">
   Compile Tool
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  THE Ecosystem
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="ovsa_get_started.html">
   OpenVINO™ Security Add-on
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="workbench_docs_Workbench_DG_Introduction.html">
   OpenVINO™ Deep Learning Workbench Overview
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/>
  <label for="toctree-checkbox-26">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Install.html">
     Installation
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/>
    <label for="toctree-checkbox-27">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Prerequisites.html">
       Prerequisites
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Run_Locally.html">
       Run the DL Workbench Locally
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/>
      <label for="toctree-checkbox-28">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Advanced_Configurations.html">
         Advanced DL Workbench Configurations
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Docker_Container.html">
         Work with Docker Container
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Start_DL_Workbench_in_DevCloud.html">
       Run the DL Workbench in the Intel® DevCloud for the Edge
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Work_with_Models_and_Sample_Datasets.html">
     Get Started
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/>
    <label for="toctree-checkbox-29">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Select_Model.html">
       Import Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_Create_Project.html">
       Create Project
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Additional_Resources.html">
       Educational Resources about DL Workbench
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/>
      <label for="toctree-checkbox-30">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Key_Concepts.html">
         DL Workbench Key Concepts
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorials.html">
     Tutorials
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/>
    <label for="toctree-checkbox-31">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_Import_YOLO.html">
       Object Detection Model (YOLOv4)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Measure_Accuracy_Object_detection.html">
       Object Detection Model (SSD_mobilenet)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_Classification.html">
       Classification Model (mobilenet)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Measure_Accuracy_Classification.html">
       Classification Model (squeezenet)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_Instance_Segmentation.html">
       Instance Segmentation Model (mask R-cnn)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_Semantic_Segmentation.html">
       Semantic Segmentation Model (deeplab)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_Style_Transfer.html">
       Style Transfer Model (fast-nst-onnx)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_NLP.html">
       NLP Model (BERT)
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_User_Guide.html">
     User Guide
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" type="checkbox"/>
    <label for="toctree-checkbox-32">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Select_Models.html">
       Obtain Models
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-33" name="toctree-checkbox-33" type="checkbox"/>
      <label for="toctree-checkbox-33">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_OMZ_Models.html">
         Import Open Model Zoo Models
        </a>
       </li>
       <li class="toctree-l4 has-children">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Original_Model_Import.html">
         Import Original Model
        </a>
        <input class="toctree-checkbox" id="toctree-checkbox-34" name="toctree-checkbox-34" type="checkbox"/>
        <label for="toctree-checkbox-34">
         <i class="fas fa-chevron-down">
         </i>
        </label>
        <ul>
         <li class="toctree-l5">
          <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_Import_Original.html">
           Import Original Model Recommendations
          </a>
         </li>
        </ul>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Generate_Datasets.html">
       Obtain Datasets
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-35" name="toctree-checkbox-35" type="checkbox"/>
      <label for="toctree-checkbox-35">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4 has-children">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Dataset_Types.html">
         Dataset Types
        </a>
        <input class="toctree-checkbox" id="toctree-checkbox-36" name="toctree-checkbox-36" type="checkbox"/>
        <label for="toctree-checkbox-36">
         <i class="fas fa-chevron-down">
         </i>
        </label>
        <ul>
         <li class="toctree-l5">
          <a class="reference internal" href="workbench_docs_Workbench_DG_Download_and_Cut_Datasets.html">
           Cut Datasets
          </a>
         </li>
        </ul>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Select_Environment.html">
       Select Environment
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-37" name="toctree-checkbox-37" type="checkbox"/>
      <label for="toctree-checkbox-37">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4 has-children">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Remote_Profiling.html">
         Work with Remote Targets
        </a>
        <input class="toctree-checkbox" id="toctree-checkbox-38" name="toctree-checkbox-38" type="checkbox"/>
        <label for="toctree-checkbox-38">
         <i class="fas fa-chevron-down">
         </i>
        </label>
        <ul>
         <li class="toctree-l5">
          <a class="reference internal" href="workbench_docs_Workbench_DG_Profile_on_Remote_Machine.html">
           Profile on Remote Machine
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="workbench_docs_Workbench_DG_Setup_Remote_Target.html">
           Set Up Remote Target
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="workbench_docs_Workbench_DG_Add_Remote_Target.html">
           Register Remote Target in DL Workbench
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="workbench_docs_Workbench_DG_Remote_Machines.html">
           Manipulate Remote Machines
          </a>
         </li>
        </ul>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Int_8_Quantization.html">
       Optimize Model Performance
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Run_Inference.html">
       Explore Inference Configurations
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-39" name="toctree-checkbox-39" type="checkbox"/>
      <label for="toctree-checkbox-39">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Run_Single_Inference.html">
         Run Inference
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_View_Inference_Results.html">
         View Inference Results
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Compare_Performance_between_Two_Versions_of_Models.html">
         Compare Performance between Two Versions of a Model
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Visualize_Model.html">
         Visualize Model
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Visualize_Accuracy.html">
       Visualize Model Output
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Measure_Accuracy.html">
       Create Accuracy Report
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-40" name="toctree-checkbox-40" type="checkbox"/>
      <label for="toctree-checkbox-40">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Accuracy_Configuration.html">
         Accuracy Configuration
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Configure_Accuracy_Settings.html">
         Set Accuracy Configuration
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Accuracy_Report_Results.html">
         Interpret Accuracy Report Results
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Deployment_Package.html">
       Create Deployment Package
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-41" name="toctree-checkbox-41" type="checkbox"/>
      <label for="toctree-checkbox-41">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Deploy_and_Integrate_Performance_Criteria_into_Application.html">
         Deploy and Integrate Performance Criteria into Application
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Export_Project.html">
       Export Project
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Jupyter_Notebooks_CLI.html">
       Learn OpenVINO in DL Workbench
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-42" name="toctree-checkbox-42" type="checkbox"/>
      <label for="toctree-checkbox-42">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Jupyter_Notebooks.html">
         Learn Model Inference with OpenVINO™ API in JupyterLab* Environment
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Persist_Database.html">
       Restore DL Workbench State
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="workbench_docs_security_Workbench.html">
       Run DL Workbench Securely
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-43" name="toctree-checkbox-43" type="checkbox"/>
      <label for="toctree-checkbox-43">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Authentication.html">
         Enable Authentication in DL Workbench
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Configure_TLS.html">
         Configure Transport Layer Security (TLS)
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Troubleshooting.html">
     Troubleshooting
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-44" name="toctree-checkbox-44" type="checkbox"/>
    <label for="toctree-checkbox-44">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_DC_Troubleshooting.html">
       Troubleshooting for DL Workbench in the Intel® DevCloud for the Edge
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Media Processing and Computer Vision Libraries
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_dlstreamer.html">
   Intel® Deep Learning Streamer
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_gapi_gapi_intro.html">
   Introduction to OpenCV Graph API (G-API)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-45" name="toctree-checkbox-45" type="checkbox"/>
  <label for="toctree-checkbox-45">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_gapi_kernel_api.html">
     Graph API Kernel API
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_gapi_face_beautification.html">
     Implementing a Face Beautification Algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_gapi_gapi_face_analytics_pipeline.html">
     Building a Face Analytics Pipeline
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://docs.opencv.org/master/">
   OpenCV* Developer Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://software.intel.com/en-us/openclsdk-devguide">
   OpenCL™ Developer Guide
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  OpenVINO Extensibility
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_Extensibility_UG_Intro.html">
   OpenVINO Extensibility Mechanism
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-46" name="toctree-checkbox-46" type="checkbox"/>
  <label for="toctree-checkbox-46">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_Extensibility_UG_add_openvino_ops.html">
     Custom OpenVINO™ Operations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_Extensibility_UG_Frontend_Extensions.html">
     Frontend Extensions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_Extensibility_UG_GPU.html">
     How to Implement Custom GPU Operations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_Extensibility_UG_VPU_Kernel.html">
     How to Implement Custom Layers for VPU (Intel® Neural Compute Stick 2)
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_customize_model_optimizer_Customize_Model_Optimizer.html">
     Model Optimizer Extensibility
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-47" name="toctree-checkbox-47" type="checkbox"/>
    <label for="toctree-checkbox-47">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_customize_model_optimizer_Extending_Model_Optimizer_With_Caffe_Python_Layers.html">
       Extending Model Optimizer with Caffe Python Layers
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_transformations.html">
   Overview of Transformations API
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-48" name="toctree-checkbox-48" type="checkbox"/>
  <label for="toctree-checkbox-48">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_Extensibility_UG_model_pass.html">
     OpenVINO Model Pass
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_Extensibility_UG_matcher_pass.html">
     OpenVINO Matcher Pass
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_Extensibility_UG_graph_rewrite_pass.html">
     OpenVINO Graph Rewrite Pass
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_ie_plugin_dg_overview.html">
   OpenVINO Plugin Developer Guide
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-49" name="toctree-checkbox-49" type="checkbox"/>
  <label for="toctree-checkbox-49">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_ie_plugin_dg_plugin.html">
     Implement Plugin Functionality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_ie_plugin_dg_executable_network.html">
     Implement Executable Network Functionality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_ie_plugin_dg_infer_request.html">
     Implement Synchronous Inference Request
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_ie_plugin_dg_async_infer_request.html">
     Implement Asynchronous Inference Request
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_ie_plugin_dg_plugin_build.html">
     Build Plugin Using CMake*
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_ie_plugin_dg_plugin_testing.html">
     Plugin Testing
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_ie_plugin_detailed_guides.html">
     Advanced Topics
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-50" name="toctree-checkbox-50" type="checkbox"/>
    <label for="toctree-checkbox-50">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_ie_plugin_dg_quantized_networks.html">
       Quantized networks compute and restrictions
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="openvino_docs_OV_UG_lpt.html">
       OpenVINO™ Low Precision Transformations
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-51" name="toctree-checkbox-51" type="checkbox"/>
      <label for="toctree-checkbox-51">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4 has-children">
        <a class="reference internal" href="openvino_docs_OV_UG_lpt_attributes.html">
         Attributes
        </a>
        <input class="toctree-checkbox" id="toctree-checkbox-52" name="toctree-checkbox-52" type="checkbox"/>
        <label for="toctree-checkbox-52">
         <i class="fas fa-chevron-down">
         </i>
        </label>
        <ul>
         <li class="toctree-l5">
          <a class="reference internal" href="openvino_docs_OV_UG_lpt_AvgPoolPrecisionPreserved.html">
           AvgPoolPrecisionPreserved
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="openvino_docs_OV_UG_lpt_IntervalsAlignment.html">
           IntervalsAlignment
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="openvino_docs_OV_UG_lpt_PrecisionPreserved.html">
           PrecisionPreserved
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="openvino_docs_OV_UG_lpt_Precisions.html">
           Precisions
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="openvino_docs_OV_UG_lpt_QuantizationAlignment.html">
           QuantizationAlignment
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="openvino_docs_OV_UG_lpt_QuantizationGranularity.html">
           QuantizationGranularity
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_lpt_step1_prerequisites.html">
         Step 1. Prerequisites transformations
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_lpt_step2_markup.html">
         Step 2. Markup transformations
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_lpt_step3_main.html">
         Step 3. Main transformations
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_lpt_step4_cleanup.html">
         Step 4. Cleanup transformations
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_ie_plugin_api_references.html">
     Plugin API Reference
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-53" name="toctree-checkbox-53" type="checkbox"/>
    <label for="toctree-checkbox-53">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="simple">
    </ul>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Use OpenVINO™ Toolkit Securely
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_security_guide_introduction.html">
   Introduction to OpenVINO™ Security
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_security_guide_workbench.html">
   Deep Learning Workbench Security
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_OV_UG_protecting_model_guide.html">
   Using Encrypted Models with OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ovsa_get_started.html">
   OpenVINO™ Security Add-on
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#converting-a-model">
   Converting a Model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#openvino-toolkit-samples-and-open-model-zoo-demos">
   OpenVINO™ Toolkit Samples and Open Model Zoo Demos
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feeding-input-images-to-the-samples">
   Feeding Input Images to the Samples
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#custom-input-shape">
   Custom Input Shape
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fixed-shape-resizer-replacement">
     Fixed Shape Resizer Replacement
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#keeping-aspect-ratio-resizer-replacement">
     Keeping Aspect Ratio Resizer Replacement
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-conversion-process-in-detail">
   Model Conversion Process in Detail
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                <div class="tocsection download-docs">
  <div class="dropdown sst-dropdown">
    <button class="button bttn-prm button-size-m" data-display="static" type="button" id="download-options"
      data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
      Download Docs
    </button>
    <div class="dropdown-menu" aria-labelledby="download-options">
      <a class="dropdown-item" href="#" onclick="window.print()">.pdf</a>
      <a id="download-zip-btn" class="dropdown-item" href="#">.zip</a>
    </div>
  </div>
</div>
              </div>
              
            
          </div>
          

          
          
              
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">

<div class="tocsection editthispage">
    <a href="None">
        <i class="fas fa-pencil-alt"></i> Edit this page
    </a>
</div>

            
                <div>
                  
  <section id="converting-tensorflow-object-detection-api-models">
<span id="doxid-openvino-docs-m-o-d-g-prepare-model-convert-model-tf-specific-convert-object-detection-a-p-i-models"></span><span id="index-0"></span><h1>Converting TensorFlow Object Detection API Models<a class="headerlink" href="#converting-tensorflow-object-detection-api-models" title="Permalink to this headline">¶</a></h1>
<p><span class="target" id="doxid-openvino-docs-m-o-d-g-prepare-model-convert-model-tf-specific-convert-object-detection-a-p-i-models-1md-openvino-docs-mo-dg-prepare-model-convert-model-tf-specific-convert-object-detection-api-models"></span>  <strong>NOTES</strong> :</p>
<ul class="simple">
<li><p>Starting with the 2022.1 release, Model Optimizer can convert the TensorFlow Object Detection API Faster and Mask RCNNs topologies differently. By default, Model Optimizer adds operation “Proposal” to the generated IR. This operation needs an additional input to the model with name “image_info” which should be fed with several values describing the preprocessing applied to the input image (refer to the <a class="reference internal" href="openvino_docs_ops_detection_Proposal_4.html#doxid-openvino-docs-ops-detection-proposal-4"><span class="std std-ref">Proposal</span></a> operation specification for more information). However, this input is redundant for the models trained and inferred with equal size images. Model Optimizer can generate IR for such models and insert operation <a class="reference internal" href="openvino_docs_ops_detection_DetectionOutput_1.html#doxid-openvino-docs-ops-detection-detection-output-1"><span class="std std-ref">DetectionOutput</span></a> instead of <code class="docutils literal notranslate"><span class="pre">Proposal</span></code>. The <code class="docutils literal notranslate"><span class="pre">DetectionOutput</span></code> operation does not require additional model input “image_info”. Moreover, for some models the produced inference results are closer to the original TensorFlow model. In order to trigger new behavior, the attribute “operation_to_add” in the corresponding JSON transformation configuration file should be set to value “DetectionOutput” instead of default one “Proposal”.</p></li>
<li><p>Starting with the 2021.1 release, Model Optimizer converts the TensorFlow Object Detection API SSDs, Faster and Mask RCNNs topologies keeping shape-calculating sub-graphs by default, so topologies can be re-shaped in the OpenVINO Runtime using dedicated reshape API. Refer to the <a class="reference internal" href="openvino_docs_OV_UG_ShapeInference.html#doxid-openvino-docs-o-v-u-g-shape-inference"><span class="std std-ref">Using Shape Inference</span></a> guide for more information on how to use this feature. It is possible to change the both spatial dimensions of the input image and batch size.</p></li>
<li><p>To generate IRs for TF 1 SSD topologies, Model Optimizer creates a number of <code class="docutils literal notranslate"><span class="pre">PriorBoxClustered</span></code> operations instead of a constant node with prior boxes calculated for the particular input image size. This change allows you to reshape the topology in the OpenVINO Runtime using dedicated API. The reshaping is supported for all SSD topologies except FPNs, which contain hardcoded shapes for some operations preventing from changing topology input shape.</p></li>
</ul>
<section id="converting-a-model">
<h2>Converting a Model<a class="headerlink" href="#converting-a-model" title="Permalink to this headline">¶</a></h2>
<p>You can download TensorFlow Object Detection API models from the <a class="reference external" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md">TensorFlow 1 Detection Model Zoo</a> or <a class="reference external" href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md">TensorFlow 2 Detection Model Zoo</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Before converting, make sure you have configured Model Optimizer. For configuration steps, refer to the <a class="reference internal" href="openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html#doxid-openvino-docs-m-o-d-g-deep-learning-model-optimizer-dev-guide"><span class="std std-ref">Configuring Model Optimizer</span></a>.</p>
</div>
<p>To convert a TensorFlow Object Detection API model, run the <code class="docutils literal notranslate"><span class="pre">mo</span></code> command with the following required parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--input_model</span> <span class="pre">&lt;path_to_frozen.pb&gt;</span></code> File with a pretrained model (binary or text .pb file after freezing) OR <code class="docutils literal notranslate"><span class="pre">--saved_model_dir</span> <span class="pre">&lt;path_to_saved_model&gt;</span></code> for the TensorFlow 2 models</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--transformations_config</span> <span class="pre">&lt;path_to_subgraph_replacement_configuration_file.json&gt;</span></code> A subgraph replacement configuration file with transformations description. For the models downloaded from the TensorFlow Object Detection API zoo, you can find the configuration files in the <code class="docutils literal notranslate"><span class="pre">&lt;PYTHON_SITE_PACKAGES&gt;/openvino/tools/mo/front/tf</span></code> directory. Use:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">ssd_v2_support.json</span></code> for frozen SSD topologies from the models zoo version up to 1.13.X inclusively</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ssd_support_api_v.1.14.json</span></code> for SSD topologies trained using the TensorFlow Object Detection API version 1.14 up to 1.14.X inclusively</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ssd_support_api_v.1.15.json</span></code> for SSD topologies trained using the TensorFlow Object Detection API version 1.15 up to 2.0</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ssd_support_api_v.2.0.json</span></code> for SSD topologies trained using the TensorFlow Object Detection API version 2.0 up to 2.3.X inclusively</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ssd_support_api_v.2.4.json</span></code> for SSD topologies trained using the TensorFlow Object Detection API version 2.4 or higher</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">efficient_det_support_api_v.2.0.json</span></code> for EfficientDet topologies trained using the TensorFlow Object Detection API version 2.0 up to 2.3.X inclusively</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">efficient_det_support_api_v.2.4.json</span></code> for EfficientDet topologies trained using the TensorFlow Object Detection API version 2.4 or higher</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">faster_rcnn_support.json</span></code> for Faster R-CNN topologies from the TF 1.X models zoo trained with TensorFlow version up to 1.6.X inclusively</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">faster_rcnn_support_api_v1.7.json</span></code> for Faster R-CNN topologies trained using the TensorFlow Object Detection API version 1.7.0 up to 1.9.X inclusively</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">faster_rcnn_support_api_v1.10.json</span></code> for Faster R-CNN topologies trained using the TensorFlow Object Detection API version 1.10.0 up to 1.12.X inclusively</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">faster_rcnn_support_api_v1.13.json</span></code> for Faster R-CNN topologies trained using the TensorFlow Object Detection API version 1.13.X</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">faster_rcnn_support_api_v1.14.json</span></code> for Faster R-CNN topologies trained using the TensorFlow Object Detection API version 1.14.0 up to 1.14.X inclusively</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">faster_rcnn_support_api_v1.15.json</span></code> for Faster R-CNN topologies trained using the TensorFlow Object Detection API version 1.15.0 up to 2.0</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">faster_rcnn_support_api_v2.0.json</span></code> for Faster R-CNN topologies trained using the TensorFlow Object Detection API version 2.0 up to 2.3.X inclusively</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">faster_rcnn_support_api_v2.4.json</span></code> for Faster R-CNN topologies trained using the TensorFlow Object Detection API version 2.4 or higher</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mask_rcnn_support.json</span></code> for Mask R-CNN topologies from the TF 1.X models zoo trained with TensorFlow version 1.9.0 or lower.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mask_rcnn_support_api_v1.7.json</span></code> for Mask R-CNN topologies trained using the TensorFlow Object Detection API version 1.7.0 up to 1.9.X inclusively</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mask_rcnn_support_api_v1.11.json</span></code> for Mask R-CNN topologies trained using the TensorFlow Object Detection API version 1.11.0 up to 1.12.X inclusively</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mask_rcnn_support_api_v1.13.json</span></code> for Mask R-CNN topologies trained using the TensorFlow Object Detection API version 1.13.0 up to 1.13.X inclusively</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mask_rcnn_support_api_v1.14.json</span></code> for Mask R-CNN topologies trained using the TensorFlow Object Detection API version 1.14.0 up to 1.14.X inclusively</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mask_rcnn_support_api_v1.15.json</span></code> for Mask R-CNN topologies trained using the TensorFlow Object Detection API version 1.15.0 up to 2.0</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mask_rcnn_support_api_v2.0.json</span></code> for Mask R-CNN topologies trained using the TensorFlow Object Detection API version 2.0 up to 2.3.X inclusively</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mask_rcnn_support_api_v2.4.json</span></code> for Mask R-CNN topologies trained using the TensorFlow Object Detection API version 2.4 or higher</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rfcn_support.json</span></code> for RFCN topology from the models zoo trained with TensorFlow version up to 1.9.X inclusively</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rfcn_support_api_v1.10.json</span></code> for RFCN topology from the models zoo frozen with TensorFlow version 1.10.0 up to 1.12.X inclusively</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rfcn_support_api_v1.13.json</span></code> for RFCN topology from the models zoo frozen with TensorFlow version 1.13.X</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rfcn_support_api_v1.14.json</span></code> for RFCN topology from the models zoo frozen with TensorFlow version 1.14.0 or higher</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">--tensorflow_object_detection_api_pipeline_config</span> <span class="pre">&lt;path_to_pipeline.config&gt;</span></code> A special configuration file that describes the topology hyper-parameters and structure of the TensorFlow Object Detection API model. For the models downloaded from the TensorFlow Object Detection API zoo, the configuration file is named <code class="docutils literal notranslate"><span class="pre">pipeline.config</span></code>. If you plan to train a model yourself, you can find templates for these files in the <a class="reference external" href="https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs">models repository</a>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--input_shape</span></code> (optional) A custom input image shape. For more information how the <code class="docutils literal notranslate"><span class="pre">--input_shape</span></code> parameter is handled for the TensorFlow Object Detection API models, refer to the <a class="reference external" href="#custom-input-shape">Custom Input Shape</a> guide.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The color channel order (RGB or BGR) of an input data should match the channel order of the model training dataset. If they are different, perform the <code class="docutils literal notranslate"><span class="pre">RGB&lt;-&gt;BGR</span></code> conversion specifying the command-line parameter: <code class="docutils literal notranslate"><span class="pre">--reverse_input_channels</span></code>. Otherwise, inference results may be incorrect. If you convert a TensorFlow Object Detection API model to use with the OpenVINO sample applications, you must specify the <code class="docutils literal notranslate"><span class="pre">--reverse_input_channels</span></code> parameter. For more information about the parameter, refer to the <strong>When to Reverse Input Channels</strong> section of the <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Converting_Model.html#doxid-openvino-docs-m-o-d-g-prepare-model-convert-model-converting-model"><span class="std std-ref">Converting a Model to Intermediate Representation (IR)</span></a> guide.</p>
</div>
<p>Additionally to the mandatory parameters listed above you can use optional conversion parameters if needed. A full list of parameters is available in the <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_TensorFlow.html#doxid-openvino-docs-m-o-d-g-prepare-model-convert-model-convert-model-from-tensor-flow"><span class="std std-ref">Converting a TensorFlow Model</span></a> guide.</p>
<p>For example, if you downloaded the pre-trained <a class="reference external" href="http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2018_01_28.tar.gz">SSD InceptionV2 topology</a> and extracted archive to the directory <code class="docutils literal notranslate"><span class="pre">/tmp/ssd_inception_v2_coco_2018_01_28</span></code>, the sample command line to convert the model looks as follows:</p>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">mo</span> <span class="o">--</span><span class="n">input_model</span><span class="o">=/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ssd_inception_v2_coco_2018_01_28</span><span class="o">/</span><span class="n">frozen_inference_graph</span><span class="p">.</span><span class="n">pb</span> <span class="o">--</span><span class="n">transformations_config</span> <span class="n">front</span><span class="o">/</span><span class="n">tf</span><span class="o">/</span><span class="n">ssd_v2_support</span><span class="p">.</span><span class="n">json</span> <span class="o">--</span><span class="n">tensorflow_object_detection_api_pipeline_config</span> <span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ssd_inception_v2_coco_2018_01_28</span><span class="o">/</span><span class="n">pipeline</span><span class="p">.</span><span class="n">config</span> <span class="o">--</span><span class="n">reverse_input_channels</span></pre></div></div></section>
<section id="openvino-toolkit-samples-and-open-model-zoo-demos">
<h2>OpenVINO™ Toolkit Samples and Open Model Zoo Demos<a class="headerlink" href="#openvino-toolkit-samples-and-open-model-zoo-demos" title="Permalink to this headline">¶</a></h2>
<p>OpenVINO comes with a number of samples to demonstrate use of OpenVINO Runtime API. Additionally, Open Model Zoo provides set of demo applications to show implementation of close to real life applications, based on deep learning in various tasks, including Image Classification, Visual Object Detection, Text Recognition, Speech Recognition, Natural Language Processing and others. Refer to the links below for more details.</p>
<ul class="simple">
<li><p><a class="reference internal" href="openvino_docs_OV_UG_Samples_Overview.html#doxid-openvino-docs-o-v-u-g-samples-overview"><span class="std std-ref">OpenVINO Samples</span></a></p></li>
<li><p>Open Model Zoo Demos</p></li>
</ul>
</section>
<section id="feeding-input-images-to-the-samples">
<h2>Feeding Input Images to the Samples<a class="headerlink" href="#feeding-input-images-to-the-samples" title="Permalink to this headline">¶</a></h2>
<p>There are several important notes about feeding input images to the samples:</p>
<ol class="arabic simple">
<li><p>OpenVINO samples stretch input image to the size of the input operation without preserving aspect ratio. This behavior is usually correct for most topologies (including SSDs), but incorrect for other models like Faster R-CNN, Mask R-CNN and R-FCN. These models usually use keeps aspect ratio resizer. The type of preprocessing is defined in the pipeline configuration file in the section <code class="docutils literal notranslate"><span class="pre">image_resizer</span></code>. If keeping aspect ratio is used, then it is necessary to resize image before passing it to the sample and optionally pad the resized image with 0s (if the attribute “pad_to_max_dimension” in the pipeline.config is equal to “true”).</p></li>
<li><p>TensorFlow implementation of image resize may be different from the one implemented in the sample. Even reading input image from compressed format (like <code class="docutils literal notranslate"><span class="pre">.jpg</span></code>) could give different results in the sample and TensorFlow. If it is necessary to compare accuracy between the TensorFlow and the OpenVINO, it is recommended to pass pre-resized input image in a non-compressed format (like <code class="docutils literal notranslate"><span class="pre">.bmp</span></code>).</p></li>
<li><p>If you want to infer the model with the OpenVINO samples, convert the model specifying the <code class="docutils literal notranslate"><span class="pre">--reverse_input_channels</span></code> command line parameter. The samples load images in BGR channels order, while TensorFlow models were trained with images in RGB order. When the <code class="docutils literal notranslate"><span class="pre">--reverse_input_channels</span></code> command line parameter is specified, Model Optimizer performs first convolution or other channel dependent operation weights modification so the output will be like the image is passed with RGB channels order.</p></li>
<li><p>Read carefully the messages printed by Model Optimizer during a model conversion. They contain important instructions on how to prepare input data before running the inference and how to interpret the output.</p></li>
</ol>
<p><span class="target" id="doxid-openvino-docs-m-o-d-g-prepare-model-convert-model-tf-specific-convert-object-detection-a-p-i-models-1custom-input-shape"></span></p>
</section>
<section id="custom-input-shape">
<h2>Custom Input Shape<a class="headerlink" href="#custom-input-shape" title="Permalink to this headline">¶</a></h2>
<p>Model Optimizer handles the command line parameter <code class="docutils literal notranslate"><span class="pre">--input_shape</span></code> for TensorFlow Object Detection API models in a special way depending on the image resizer type defined in the <code class="docutils literal notranslate"><span class="pre">pipeline.config</span></code> file. TensorFlow Object Detection API generates different <code class="docutils literal notranslate"><span class="pre">Preprocessor</span></code> sub-graph based on the image resizer type. Model Optimizer supports two types of image resizer:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">fixed_shape_resizer</span></code> <em>Stretches</em> input image to the specific height and width. The <code class="docutils literal notranslate"><span class="pre">pipeline.config</span></code> snippet below shows a <code class="docutils literal notranslate"><span class="pre">fixed_shape_resizer</span></code> sample definition:</p>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">image_resizer</span> <span class="p">{</span>
  <span class="n">fixed_shape_resizer</span> <span class="p">{</span>
    <span class="nl">height</span><span class="p">:</span> <span class="mi">300</span>
    <span class="nl">width</span><span class="p">:</span> <span class="mi">300</span>
  <span class="p">}</span>
<span class="p">}</span></pre></div></div></li>
<li><p><code class="docutils literal notranslate"><span class="pre">keep_aspect_ratio_resizer</span></code> Resizes the input image <em>keeping aspect ratio</em> to satisfy the minimum and maximum size constraints. The <code class="docutils literal notranslate"><span class="pre">pipeline.config</span></code> snippet below shows a <code class="docutils literal notranslate"><span class="pre">keep_aspect_ratio_resizer</span></code> sample definition:</p>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">image_resizer</span> <span class="p">{</span>
  <span class="n">keep_aspect_ratio_resizer</span> <span class="p">{</span>
    <span class="nl">min_dimension</span><span class="p">:</span> <span class="mi">600</span>
    <span class="nl">max_dimension</span><span class="p">:</span> <span class="mi">1024</span>
  <span class="p">}</span>
<span class="p">}</span></pre></div></div><p>If an additional parameter “pad_to_max_dimension” is equal to “true”, then the resized image will be padded with 0s to the square image of size “max_dimension”.</p>
</li>
</ul>
<section id="fixed-shape-resizer-replacement">
<h3>Fixed Shape Resizer Replacement<a class="headerlink" href="#fixed-shape-resizer-replacement" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>If the <code class="docutils literal notranslate"><span class="pre">--input_shape</span></code> command line parameter is not specified, Model Optimizer generates an input operation with the height and width as defined in the <code class="docutils literal notranslate"><span class="pre">pipeline.config</span></code>.</p></li>
<li><p>If the <code class="docutils literal notranslate"><span class="pre">--input_shape</span> <span class="pre">[1,</span> <span class="pre">H,</span> <span class="pre">W,</span> <span class="pre">3]</span></code> command line parameter is specified, Model Optimizer sets the input operation height to <code class="docutils literal notranslate"><span class="pre">H</span></code> and width to <code class="docutils literal notranslate"><span class="pre">W</span></code> and convert the model. However, the conversion may fail because of the following reasons:</p>
<ul>
<li><p>The model is not reshape-able, meaning that it’s not possible to change the size of the model input image. For example, SSD FPN models have <code class="docutils literal notranslate"><span class="pre">Reshape</span></code> operations with hard-coded output shapes, but the input size to these <code class="docutils literal notranslate"><span class="pre">Reshape</span></code> instances depends on the input image size. In this case, Model Optimizer shows an error during the shape inference phase. Run Model Optimizer with <code class="docutils literal notranslate"><span class="pre">--log_level</span> <span class="pre">DEBUG</span></code> to see the inferred operations output shapes to see the mismatch.</p></li>
<li><p>Custom input shape is too small. For example, if you specify <code class="docutils literal notranslate"><span class="pre">--input_shape</span> <span class="pre">[1,100,100,3]</span></code> to convert a SSD Inception V2 model, one of convolution or pooling nodes decreases input tensor spatial dimensions to non-positive values. In this case, Model Optimizer shows error message like this: ‘[ ERROR ] Shape [ 1 -1 -1 256] is not fully defined for output X of “node_name”.’</p></li>
</ul>
</li>
</ul>
</section>
<section id="keeping-aspect-ratio-resizer-replacement">
<h3>Keeping Aspect Ratio Resizer Replacement<a class="headerlink" href="#keeping-aspect-ratio-resizer-replacement" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>If the <code class="docutils literal notranslate"><span class="pre">--input_shape</span></code> command line parameter is not specified, Model Optimizer generates an input operation with both height and width equal to the value of parameter <code class="docutils literal notranslate"><span class="pre">min_dimension</span></code> in the <code class="docutils literal notranslate"><span class="pre">keep_aspect_ratio_resizer</span></code>.</p></li>
<li><p>If the <code class="docutils literal notranslate"><span class="pre">--input_shape</span> <span class="pre">[1,</span> <span class="pre">H,</span> <span class="pre">W,</span> <span class="pre">3]</span></code> command line parameter is specified, Model Optimizer scales the specified input image height <code class="docutils literal notranslate"><span class="pre">H</span></code> and width <code class="docutils literal notranslate"><span class="pre">W</span></code> to satisfy the <code class="docutils literal notranslate"><span class="pre">min_dimension</span></code> and <code class="docutils literal notranslate"><span class="pre">max_dimension</span></code> constraints defined in the <code class="docutils literal notranslate"><span class="pre">keep_aspect_ratio_resizer</span></code>. The following function calculates the input operation height and width:</p></li>
</ul>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">def</span> <span class="n">calculate_shape_keeping_aspect_ratio</span><span class="p">(</span><span class="nl">H</span><span class="p">:</span> <span class="kt">int</span><span class="p">,</span> <span class="nl">W</span><span class="p">:</span> <span class="kt">int</span><span class="p">,</span> <span class="nl">min_dimension</span><span class="p">:</span> <span class="kt">int</span><span class="p">,</span> <span class="nl">max_dimension</span><span class="p">:</span> <span class="kt">int</span><span class="p">)</span><span class="o">:</span>
    <span class="n">ratio_min</span> <span class="o">=</span> <span class="n">min_dimension</span> <span class="o">/</span> <a class="reference internal" href="../api/groups/namespacengraph_1_1runtime_1_1reference.html#doxid-namespacengraph-1-1runtime-1-1reference-1abc42885cb896b121ab5ac214cbf60935"><span class="std std-ref">min</span></a><span></span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
    <span class="n">ratio_max</span> <span class="o">=</span> <span class="n">max_dimension</span> <span class="o">/</span> <a class="reference internal" href="../api/groups/namespacengraph_1_1runtime_1_1reference.html#doxid-namespacengraph-1-1runtime-1-1reference-1a92cfabd79e866544fb35d44884e7adfd"><span class="std std-ref">max</span></a><span></span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span>
    <span class="n">ratio</span> <span class="o">=</span> <a class="reference internal" href="../api/groups/namespacengraph_1_1runtime_1_1reference.html#doxid-namespacengraph-1-1runtime-1-1reference-1abc42885cb896b121ab5ac214cbf60935"><span class="std std-ref">min</span></a><span></span><span class="p">(</span><span class="n">ratio_min</span><span class="p">,</span> <span class="n">ratio_max</span><span class="p">)</span>
    <span class="k">return</span> <span class="kt">int</span><span class="p">(</span><a class="reference internal" href="../api/groups/namespacengraph_1_1runtime_1_1reference.html#doxid-namespacengraph-1-1runtime-1-1reference-1a8ea383ca6ce01d26eabe1c27a0e1bd37"><span class="std std-ref">round</span></a><span></span><span class="p">(</span><span class="n">H</span> <span class="err">\</span><span class="o">*</span> <span class="n">ratio</span><span class="p">)),</span> <span class="kt">int</span><span class="p">(</span><a class="reference internal" href="../api/groups/namespacengraph_1_1runtime_1_1reference.html#doxid-namespacengraph-1-1runtime-1-1reference-1a8ea383ca6ce01d26eabe1c27a0e1bd37"><span class="std std-ref">round</span></a><span></span><span class="p">(</span><span class="n">W</span> <span class="err">\</span><span class="o">*</span> <span class="n">ratio</span><span class="p">))</span></pre></div></div><p>The <code class="docutils literal notranslate"><span class="pre">--input_shape</span></code> command line parameter should be specified only if the “pad_to_max_dimension” does not exist of is set to “false” in the <code class="docutils literal notranslate"><span class="pre">keep_aspect_ratio_resizer</span></code>.</p>
<p>Models with <code class="docutils literal notranslate"><span class="pre">keep_aspect_ratio_resizer</span></code> were trained to recognize object in real aspect ratio, in contrast with most of the classification topologies trained to recognize objects stretched vertically and horizontally as well. By default, Model Optimizer converts topologies with <code class="docutils literal notranslate"><span class="pre">keep_aspect_ratio_resizer</span></code> to consume a square input image. If the non-square image is provided as input, it is stretched without keeping aspect ratio that results to object detection quality decrease.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It is highly recommended to specify the <code class="docutils literal notranslate"><span class="pre">--input_shape</span></code> command line parameter for the models with <code class="docutils literal notranslate"><span class="pre">keep_aspect_ratio_resizer</span></code>, if the input image dimensions are known in advance.</p>
</div>
</section>
</section>
<section id="model-conversion-process-in-detail">
<h2>Model Conversion Process in Detail<a class="headerlink" href="#model-conversion-process-in-detail" title="Permalink to this headline">¶</a></h2>
<p>This section is intended for users who want to understand how Model Optimizer performs Object Detection API models conversion in details. The information in this section is also useful for users having complex models that are not converted with Model Optimizer out of the box. It is highly recommended to read the <strong>Graph Transformation Extensions</strong> section in the <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_customize_model_optimizer_Customize_Model_Optimizer.html#doxid-openvino-docs-m-o-d-g-prepare-model-customize-model-optimizer-customize-model-optimizer"><span class="std std-ref">Model Optimizer Extensibility</span></a> documentation first to understand sub-graph replacement concepts which are used here.</p>
<p>It is also important to open the model in the <a class="reference external" href="https://www.tensorflow.org/guide/summaries_and_tensorboard">TensorBoard</a> to see the topology structure. Model Optimizer can create an event file that can be then fed to the TensorBoard tool. Run Model Optimizer, providing two command line parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">--input_model</span> <span class="pre">&lt;path_to_frozen.pb&gt;</span></code> Path to the frozen model.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--tensorboard_logdir</span></code> Path to the directory where TensorBoard looks for the event files.</p></li>
</ul>
<p>Implementation of the transformations for Object Detection API models is located in the file <a class="reference external" href="https://github.com/openvinotoolkit/openvino/blob/releases/2022/1/tools/mo/openvino/tools/mo/front/tf/ObjectDetectionAPI.py">https://github.com/openvinotoolkit/openvino/blob/releases/2022/1/tools/mo/openvino/tools/mo/front/tf/ObjectDetectionAPI.py</a>. Refer to the code in this file to understand the details of the conversion process.</p>
</section>
</section>


                </div>
            
            
                <div class='prev-next-bottom'>
                  
    <a class='button bttn-sec button-size-l' id="prev-link" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_NCF_From_Tensorflow.html" title="previous page">Prev</a>
    <a class='button bttn-sec button-size-l' id="next-link" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_RetinaNet_From_Tensorflow.html" title="next page">Next</a>

                </div>
            
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, Intel®.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.2.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>