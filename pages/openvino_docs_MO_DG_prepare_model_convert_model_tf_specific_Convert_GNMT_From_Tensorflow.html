
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Convert TensorFlow GNMT Model &#8212; OpenVINO™  documentation</title>
    
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <link rel="stylesheet" type="text/css" href="../_static/doxyrest-pygments.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <link href="../_static/css/media/favicon.ico" rel="shortcut icon">
    <link rel="stylesheet" href="../_static/css/openvino_sphinx_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/button.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/input.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/textfield.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/tabs.css" type="text/css" />
    <script src="../_static/js/openvino_sphinx_theme.js"></script>
    <link rel="stylesheet" href="../_static/css/viewer.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />

    <script src="https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-datalabels"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/chartjs-plugin-annotation/0.5.7/chartjs-plugin-annotation.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-barchart-background@1.3.0/build/Plugin.Barchart.Background.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-deferred@1"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/PapaParse/5.3.1/papaparse.min.js"></script>
    <script src="../_static/js/viewer.min.js"></script>
    <script src="/assets/versions_raw.js"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/tabs.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/js/custom.js"></script>
    <script src="../_static/js/graphs.js"></script>
    <script src="../_static/js/graphs_ov_tf.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/target-highlight.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <link rel="canonical" href="https://docs.openvino.ai/latest/pages/openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_GNMT_From_Tensorflow.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Convert TensorFlow Language Model on One Billion Word Benchmark" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_lm_1b_From_Tensorflow.html" />
    <link rel="prev" title="Convert TensorFlow FaceNet Models" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_FaceNet_From_Tensorflow.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
      <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/logo.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="get_started.html">
  Get Started
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="documentation.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../tutorials.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/api_reference.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../model_zoo.html">
  Model Zoo
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="resources.html">
  Resources
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/openvinotoolkit/openvino" rel="noopener" target="_blank" title="GitHub">
            <span><i class="sst-github"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
</ul>
      </div>
      
      <div class="navbar-end-item">
        
<div class="dropdown sst-dropdown sst-dropdown-navbar">
  <button class="btn sst-btn dropdown-toggle" type="button" id="version-selector" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"></button>
  <div class="dropdown-menu" aria-labelledby="version-selector">
  </div>
</div>
      </div>
      
      <div class="navbar-end-item">
        

<div class="dropdown sst-dropdown sst-dropdown-navbar">
  <button class="btn sst-btn dropdown-toggle" type="button" id="language-selector" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">English</button>
  <div class="dropdown-menu" aria-labelledby="language-selector">
    
      
        <a class="dropdown-item font-weight-bold" href="/latest/pages/openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_GNMT_From_Tensorflow.html">English</a>
      
    
      
        <a  class="dropdown-item" href="/cn/latest/pages/openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_GNMT_From_Tensorflow.html">Chinese</a>
      
    
  </div>
</div>

      </div>
      
    </div>
  </div>
</div>
        <div id="collapse-nav-wrapper" class="container-xl">
          <button id="collapse-nav" class="button bttn-prm button-size-m" type="button" data-toggle="collapse" data-target="#nav-tree" aria-expanded="false" aria-controls="nav-tree">
            Documentation navigation <i class="fas fa-chevron-down"></i>
          </button>
        </div>
      </nav>
      <div class="transition-banner container-fluid alert alert-info alert-dismissible fade show" role="alert">
        <p>OpenVINO 2022.1 introduces a new version of OpenVINO API (API 2.0). For more information on the changes and transition steps, see the <a href="https://docs.openvino.ai/latest/openvino_2_0_transition_guide.html">transition guide</a></p>
        <button type="button" class="close" data-dismiss="alert" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
    </div>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar" id="nav-tree"><form class="searchForm bd-search d-flex align-items-center" action="../search.html" method="get">
    <i class="icon fas fa-search"></i>
    <input type="search" class="form-control" name="query" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Converting and Preparing Models
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html">
   Convert model with Model Optimizer
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Converting_Model.html">
     Setting Input Shapes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Cutting_Model.html">
     Cutting Off Parts of a Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_Additional_Optimization_Use_Cases.html">
     Embedding Preprocessing Computation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_FP16_Compression.html">
     Compression of a Model to FP16
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_TensorFlow.html">
     Converting a TensorFlow Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_ONNX.html">
     Converting an ONNX Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_PyTorch.html">
     Converting a PyTorch* Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_Paddle.html">
     Converting a PaddlePaddle* Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_MxNet.html">
     Converting an MXNet* Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_Caffe.html">
     Converting a Caffe* Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Convert_Model_From_Kaldi.html">
     Converting a Kaldi* Model
    </a>
   </li>
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tutorials.html">
     Model Conversion Tutorials
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
    <label for="toctree-checkbox-2">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_AttentionOCR_From_Tensorflow.html">
       Convert TensorFlow Attention OCR Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_BERT_From_Tensorflow.html">
       Convert TensorFlow BERT Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_CRNN_From_Tensorflow.html">
       Convert TensorFlow CRNN Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_DeepSpeech_From_Tensorflow.html">
       Convert TensorFlow DeepSpeech Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_EfficientDet_Models.html">
       Convert TensorFlow EfficientDet Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_FaceNet_From_Tensorflow.html">
       Convert TensorFlow FaceNet Models
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       Convert TensorFlow GNMT Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_lm_1b_From_Tensorflow.html">
       Convert TensorFlow Language Model on One Billion Word Benchmark
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_NCF_From_Tensorflow.html">
       Convert TensorFlow Neural Collaborative Filtering Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_Object_Detection_API_Models.html">
       Convert TensorFlow Object Detection API Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_RetinaNet_From_Tensorflow.html">
       Converting TensorFlow RetinaNet Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_Slim_Library_Models.html">
       Convert TensorFlow Slim Image Classification Model Library Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_WideAndDeep_Family_Models.html">
       Convert TensorFlow Wide and Deep Family Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_XLNet_From_Tensorflow.html">
       Convert TensorFlow XLNet Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_YOLO_From_Tensorflow.html">
       Convert TensorFlow YOLO Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_onnx_specific_Convert_Faster_RCNN.html">
       Convert ONNX* Faster R-CNN Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_onnx_specific_Convert_GPT2.html">
       Convert ONNX* GPT-2 Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_onnx_specific_Convert_Mask_RCNN.html">
       Convert ONNX* Mask R-CNN Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_Bert_ner.html">
       Convert PyTorch* BERT-NER Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_Cascade_RCNN_res101.html">
       Convert PyTorch Cascade RCNN R-101 Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_F3Net.html">
       Convert PyTorch* F3Net Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_QuartzNet.html">
       Convert PyTorch* QuartzNet Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_RCAN.html">
       Convert PyTorch* RCAN Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_RNNT.html">
       Convert PyTorch* RNN-T Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_pytorch_specific_Convert_YOLACT.html">
       Convert PyTorch* YOLACT Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_mxnet_specific_Convert_GluonCV_Models.html">
       Convert MXNet GluonCV* Models
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_mxnet_specific_Convert_Style_Transfer_From_MXNet.html">
       Convert MXNet Style Transfer Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_kaldi_specific_Aspire_Tdnn_Model.html">
       Convert Kaldi* ASpIRE Chain Time Delay Neural Network (TDNN) Model
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_Model_Optimizer_FAQ.html">
     Model Optimizer Frequently Asked Questions
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Deploying Inference
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_OV_UG_OV_Runtime_User_Guide.html">
   Performing inference with OpenVINO Runtime
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_OV_UG_Integrate_OV_with_your_application.html">
     Integrate OpenVINO™ with Your Application
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Model_Representation.html">
       Model Representation in OpenVINO™ Runtime
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Infer_request.html">
       OpenVINO™ Inference Request
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Python_API_exclusives.html">
       OpenVINO™ Python API exclusives
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_OV_UG_ShapeInference.html">
     Changing input shapes
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_OV_UG_Working_with_devices.html">
     Working with devices
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_query_api.html">
       Query device properties, configuration
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_CPU.html">
       CPU device
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_GPU.html">
       GPU device
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
      <label for="toctree-checkbox-6">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_GPU_RemoteTensor_API.html">
         Remote Tensor API of GPU Plugin
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_VPU.html">
       VPU devices
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
      <label for="toctree-checkbox-7">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_MYRIAD.html">
         MYRIAD device
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_HDDL.html">
         HDDL device
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_GNA.html">
       GNA device
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_ARM_CPU.html">
       Arm® CPU device
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_OV_UG_Preprocessing_Overview.html">
     Optimize Preprocessing
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
    <label for="toctree-checkbox-8">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Preprocessing_Details.html">
       Preprocessing API - details
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Layout_Overview.html">
       Layout API overview
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Preprocess_Usecase_save.html">
       Use Case - Integrate and Save Preprocessing Steps Into IR
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_OV_UG_DynamicShapes.html">
     Dynamic Shapes
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
    <label for="toctree-checkbox-9">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_NoDynamicShapes.html">
       When Dynamic Shapes API is Not Applicable
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_AUTO.html">
     Automatic device selection
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
    <label for="toctree-checkbox-10">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_supported_plugins_AUTO_debugging.html">
       Debugging Auto-Device Plugin
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_OV_UG_Running_on_multiple_devices.html">
     Running on multiple devices simultaneously
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_OV_UG_Hetero_execution.html">
     Heterogeneous execution
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_OV_UG_Performance_Hints.html">
     High-level Performance Hints
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_OV_UG_Automatic_Batching.html">
     Automatic Batching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_OV_UG_network_state_intro.html">
     Stateful models
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_2_0_transition_guide.html">
   Transition to OpenVINO™ API 2.0
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_2_0_deployment.html">
     Installation &amp; Deployment
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_2_0_inference_pipeline.html">
     Inference Pipeline
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_2_0_configure_devices.html">
     Configuring Devices
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_2_0_preprocessing.html">
     Preprocessing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_2_0_model_creation.html">
     Model Creation in Runtime
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_deployment_guide.html">
   Deploy with OpenVINO
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_install_guides_deployment_manager_tool.html">
     Deployment Manager
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_deploy_local_distribution.html">
     Local distribution
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_inference_engine_tools_compile_tool_README.html">
   Compile Tool
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tuning for Performance
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_optimization_guide_dldt_optimization_guide.html">
   Introduction to Performance Optimization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_MO_DG_Getting_Performance_Numbers.html">
   Getting Performance Numbers
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_model_optimization_guide.html">
   Model Optimization Guide
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="pot_introduction.html">
     Optimizing models post-training
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
    <label for="toctree-checkbox-14">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="pot_default_quantization_usage.html">
       Quantizing Model
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
      <label for="toctree-checkbox-15">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="pot_compression_algorithms_quantization_default_README.html">
         DefaultQuantization Method
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="pot_accuracyaware_usage.html">
       Quantizing Model with Accuracy Control
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
      <label for="toctree-checkbox-16">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="accuracy_aware_README.html">
         AccuracyAwareQuantization Method
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="pot_docs_BestPractices.html">
       Quantization Best Practices
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
      <label for="toctree-checkbox-17">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="pot_saturation_issue.html">
         Saturation Issue
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="pot_compression_api_README.html">
       API Reference
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="pot_compression_cli_README.html">
       Command-line Interface
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
      <label for="toctree-checkbox-18">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="pot_docs_simplified_mode.html">
         Simplified Mode
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="pot_configs_README.html">
         Configuration File Description
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="pot_examples_description.html">
       Examples
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
      <label for="toctree-checkbox-19">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4 has-children">
        <a class="reference internal" href="pot_example_README.html">
         API Examples
        </a>
        <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
        <label for="toctree-checkbox-20">
         <i class="fas fa-chevron-down">
         </i>
        </label>
        <ul>
         <li class="toctree-l5">
          <a class="reference internal" href="pot_example_classification_README.html">
           Quantizatiing Image Classification Model
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="pot_example_object_detection_README.html">
           Quantizatiing Object Detection Model with Accuracy Control
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="pot_example_face_detection_README.html">
           Quantizatiing Cascaded Model
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="pot_example_segmentation_README.html">
           Quantizatiing Semantic Segmentation Model
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="pot_example_3d_segmentation_README.html">
           Quantizatiing 3D Segmentation Model
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="pot_example_speech_README.html">
           Quantizatiing for GNA Device
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="pot_configs_examples_README.html">
         Command-line Example
        </a>
       </li>
      </ul>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="pot_docs_FrequentlyAskedQuestions.html">
       Post-training Optimization Tool Frequently Asked Questions
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="docs_nncf_introduction.html">
     Neural Network Compression Framework
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="pot_ranger_README.html">
     (Experimental) Protecting Model
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_deployment_optimization_guide_dldt_optimization_guide.html">
   Runtime Inference Optimizations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
  <label for="toctree-checkbox-21">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_deployment_optimization_guide_common.html">
     General Optimizations
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_deployment_optimization_guide_latency.html">
     Optimizing for the Latency
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
    <label for="toctree-checkbox-22">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_OV_UG_Model_caching_overview.html">
       Model Caching Overview
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_deployment_optimization_guide_tput.html">
     Optimizing for Throughput
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_deployment_optimization_guide_tput_advanced.html">
     Using Advanced Throughput Options: Streams and Batching
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_deployment_optimization_guide_internals.html">
     Further Low-Level Implementation Details
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_tuning_utilities.html">
   Tuning Utilities
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
  <label for="toctree-checkbox-23">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_inference_engine_tools_cross_check_tool_README.html">
     Cross Check Tool
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_performance_benchmarks.html">
   Performance Benchmarks
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/>
  <label for="toctree-checkbox-24">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_performance_benchmarks_openvino.html">
     Intel® Distribution of OpenVINO™ toolkit Benchmark Results
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-25" name="toctree-checkbox-25" type="checkbox"/>
    <label for="toctree-checkbox-25">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_performance_benchmarks_faq.html">
       Performance Information Frequently Asked Questions
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference external" href="https://docs.openvino.ai/downloads/benchmark_files/OV-2022.1-Download-Excel.xlsx">
       Download Performance Data Spreadsheet in MS Excel* Format
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_performance_int8_vs_fp32.html">
       Model Accuracy for INT8 and FP32 Precision
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_performance_benchmarks_ovms.html">
     OpenVINO™ Model Server Benchmark Results
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Graphical Web Interface for OpenVINO™ toolkit
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="workbench_docs_Workbench_DG_Introduction.html">
   OpenVINO™ Deep Learning Workbench Overview
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="workbench_docs_Workbench_DG_Install.html">
   Installation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-26" name="toctree-checkbox-26" type="checkbox"/>
  <label for="toctree-checkbox-26">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Prerequisites.html">
     Prerequisites
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Run_Locally.html">
     Run the DL Workbench Locally
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-27" name="toctree-checkbox-27" type="checkbox"/>
    <label for="toctree-checkbox-27">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Advanced_Configurations.html">
       Advanced DL Workbench Configurations
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Docker_Container.html">
       Work with Docker Container
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Start_DL_Workbench_in_DevCloud.html">
     Run the DL Workbench in the Intel® DevCloud for the Edge
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="workbench_docs_Workbench_DG_Work_with_Models_and_Sample_Datasets.html">
   Get Started
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-28" name="toctree-checkbox-28" type="checkbox"/>
  <label for="toctree-checkbox-28">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Select_Model.html">
     Import Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_Create_Project.html">
     Create Project
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Additional_Resources.html">
     Educational Resources about DL Workbench
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-29" name="toctree-checkbox-29" type="checkbox"/>
    <label for="toctree-checkbox-29">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Key_Concepts.html">
       DL Workbench Key Concepts
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorials.html">
   Tutorials
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-30" name="toctree-checkbox-30" type="checkbox"/>
  <label for="toctree-checkbox-30">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_Import_YOLO.html">
     Object Detection Model (YOLOv4)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Measure_Accuracy_Object_detection.html">
     Object Detection Model (SSD_mobilenet)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_Classification.html">
     Classification Model (mobilenet)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Measure_Accuracy_Classification.html">
     Classification Model (squeezenet)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_Instance_Segmentation.html">
     Instance Segmentation Model (mask R-cnn)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_Semantic_Segmentation.html">
     Semantic Segmentation Model (deeplab)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_Style_Transfer.html">
     Style Transfer Model (fast-nst-onnx)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_NLP.html">
     NLP Model (BERT)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="workbench_docs_Workbench_DG_User_Guide.html">
   User Guide
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-31" name="toctree-checkbox-31" type="checkbox"/>
  <label for="toctree-checkbox-31">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Select_Models.html">
     Obtain Models
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-32" name="toctree-checkbox-32" type="checkbox"/>
    <label for="toctree-checkbox-32">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_OMZ_Models.html">
       Import Open Model Zoo Models
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Original_Model_Import.html">
       Import Original Model
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-33" name="toctree-checkbox-33" type="checkbox"/>
      <label for="toctree-checkbox-33">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Tutorial_Import_Original.html">
         Import Original Model Recommendations
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Generate_Datasets.html">
     Obtain Datasets
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-34" name="toctree-checkbox-34" type="checkbox"/>
    <label for="toctree-checkbox-34">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Dataset_Types.html">
       Dataset Types
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-35" name="toctree-checkbox-35" type="checkbox"/>
      <label for="toctree-checkbox-35">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Download_and_Cut_Datasets.html">
         Cut Datasets
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Select_Environment.html">
     Select Environment
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-36" name="toctree-checkbox-36" type="checkbox"/>
    <label for="toctree-checkbox-36">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Remote_Profiling.html">
       Work with Remote Targets
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-37" name="toctree-checkbox-37" type="checkbox"/>
      <label for="toctree-checkbox-37">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Profile_on_Remote_Machine.html">
         Profile on Remote Machine
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Setup_Remote_Target.html">
         Set Up Remote Target
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Add_Remote_Target.html">
         Register Remote Target in DL Workbench
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="workbench_docs_Workbench_DG_Remote_Machines.html">
         Manipulate Remote Machines
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Int_8_Quantization.html">
     Optimize Model Performance
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Run_Inference.html">
     Explore Inference Configurations
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-38" name="toctree-checkbox-38" type="checkbox"/>
    <label for="toctree-checkbox-38">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Run_Single_Inference.html">
       Run Inference
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_View_Inference_Results.html">
       View Inference Results
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Compare_Performance_between_Two_Versions_of_Models.html">
       Compare Performance between Two Versions of a Model
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Visualize_Model.html">
       Visualize Model
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Visualize_Accuracy.html">
     Visualize Model Output
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Measure_Accuracy.html">
     Create Accuracy Report
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-39" name="toctree-checkbox-39" type="checkbox"/>
    <label for="toctree-checkbox-39">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Accuracy_Configuration.html">
       Accuracy Configuration
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Configure_Accuracy_Settings.html">
       Set Accuracy Configuration
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Accuracy_Report_Results.html">
       Interpret Accuracy Report Results
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Deployment_Package.html">
     Create Deployment Package
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-40" name="toctree-checkbox-40" type="checkbox"/>
    <label for="toctree-checkbox-40">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Deploy_and_Integrate_Performance_Criteria_into_Application.html">
       Deploy and Integrate Performance Criteria into Application
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Export_Project.html">
     Export Project
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Jupyter_Notebooks_CLI.html">
     Learn OpenVINO in DL Workbench
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-41" name="toctree-checkbox-41" type="checkbox"/>
    <label for="toctree-checkbox-41">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Jupyter_Notebooks.html">
       Learn Model Inference with OpenVINO™ API in JupyterLab* Environment
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_Persist_Database.html">
     Restore DL Workbench State
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="workbench_docs_security_Workbench.html">
     Run DL Workbench Securely
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-42" name="toctree-checkbox-42" type="checkbox"/>
    <label for="toctree-checkbox-42">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Authentication.html">
       Enable Authentication in DL Workbench
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="workbench_docs_Workbench_DG_Configure_TLS.html">
       Configure Transport Layer Security (TLS)
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="workbench_docs_Workbench_DG_Troubleshooting.html">
   Troubleshooting
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-43" name="toctree-checkbox-43" type="checkbox"/>
  <label for="toctree-checkbox-43">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="workbench_docs_Workbench_DG_DC_Troubleshooting.html">
     Troubleshooting for DL Workbench in the Intel® DevCloud for the Edge
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Media Processing and Computer Vision Libraries
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_dlstreamer.html">
   Intel® Deep Learning Streamer
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_gapi_gapi_intro.html">
   Introduction to OpenCV Graph API (G-API)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-44" name="toctree-checkbox-44" type="checkbox"/>
  <label for="toctree-checkbox-44">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_gapi_kernel_api.html">
     Graph API Kernel API
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_gapi_face_beautification.html">
     Implementing a Face Beautification Algorithm
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_gapi_gapi_face_analytics_pipeline.html">
     Building a Face Analytics Pipeline
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://docs.opencv.org/master/">
   OpenCV* Developer Guide
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://software.intel.com/en-us/openclsdk-devguide">
   OpenCL™ Developer Guide
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Add-Ons
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="ovsa_get_started.html">
   OpenVINO™ Security Add-on
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  OpenVINO Extensibility
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_Extensibility_UG_Intro.html">
   OpenVINO Extensibility Mechanism
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-45" name="toctree-checkbox-45" type="checkbox"/>
  <label for="toctree-checkbox-45">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_Extensibility_UG_add_openvino_ops.html">
     Custom OpenVINO™ Operations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_Extensibility_UG_Frontend_Extensions.html">
     Frontend Extensions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_Extensibility_UG_GPU.html">
     How to Implement Custom GPU Operations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_IE_DG_Extensibility_DG_VPU_Kernel.html">
     How to Implement Custom Layers for VPU (Intel® Neural Compute Stick 2)
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_customize_model_optimizer_Customize_Model_Optimizer.html">
     Model Optimizer Extensibility
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-46" name="toctree-checkbox-46" type="checkbox"/>
    <label for="toctree-checkbox-46">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_customize_model_optimizer_Extending_Model_Optimizer_With_Caffe_Python_Layers.html">
       Extending Model Optimizer with Caffe* Python Layers
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_transformations.html">
   Overview of Transformations API
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-47" name="toctree-checkbox-47" type="checkbox"/>
  <label for="toctree-checkbox-47">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_Extensibility_UG_model_pass.html">
     OpenVINO Model Pass
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_Extensibility_UG_matcher_pass.html">
     OpenVINO Matcher Pass
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_Extensibility_UG_graph_rewrite_pass.html">
     OpenVINO Graph Rewrite Pass
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="openvino_docs_ie_plugin_dg_overview.html">
   OpenVINO Plugin Developer Guide
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-48" name="toctree-checkbox-48" type="checkbox"/>
  <label for="toctree-checkbox-48">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_ie_plugin_dg_plugin.html">
     Implement Plugin Functionality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_ie_plugin_dg_executable_network.html">
     Implement Executable Network Functionality
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_ie_plugin_dg_infer_request.html">
     Implement Synchronous Inference Request
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_ie_plugin_dg_async_infer_request.html">
     Implement Asynchronous Inference Request
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_ie_plugin_dg_plugin_build.html">
     Build Plugin Using CMake*
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="openvino_docs_ie_plugin_dg_plugin_testing.html">
     Plugin Testing
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_ie_plugin_detailed_guides.html">
     Advanced Topics
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-49" name="toctree-checkbox-49" type="checkbox"/>
    <label for="toctree-checkbox-49">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="openvino_docs_ie_plugin_dg_quantized_networks.html">
       Quantized networks compute and restrictions
      </a>
     </li>
     <li class="toctree-l3 has-children">
      <a class="reference internal" href="openvino_docs_OV_UG_lpt.html">
       OpenVINO™ Low Precision Transformations
      </a>
      <input class="toctree-checkbox" id="toctree-checkbox-50" name="toctree-checkbox-50" type="checkbox"/>
      <label for="toctree-checkbox-50">
       <i class="fas fa-chevron-down">
       </i>
      </label>
      <ul>
       <li class="toctree-l4 has-children">
        <a class="reference internal" href="openvino_docs_OV_UG_lpt_attributes.html">
         Attributes
        </a>
        <input class="toctree-checkbox" id="toctree-checkbox-51" name="toctree-checkbox-51" type="checkbox"/>
        <label for="toctree-checkbox-51">
         <i class="fas fa-chevron-down">
         </i>
        </label>
        <ul>
         <li class="toctree-l5">
          <a class="reference internal" href="openvino_docs_OV_UG_lpt_AvgPoolPrecisionPreserved.html">
           AvgPoolPrecisionPreserved
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="openvino_docs_OV_UG_lpt_IntervalsAlignment.html">
           IntervalsAlignment
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="openvino_docs_OV_UG_lpt_PrecisionPreserved.html">
           PrecisionPreserved
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="openvino_docs_OV_UG_lpt_Precisions.html">
           Precisions
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="openvino_docs_OV_UG_lpt_QuantizationAlignment.html">
           QuantizationAlignment
          </a>
         </li>
         <li class="toctree-l5">
          <a class="reference internal" href="openvino_docs_OV_UG_lpt_QuantizationGranularity.html">
           QuantizationGranularity
          </a>
         </li>
        </ul>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_lpt_step1_prerequisites.html">
         Step 1. Prerequisites transformations
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_lpt_step2_markup.html">
         Step 2. Markup transformations
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_lpt_step3_main.html">
         Step 3. Main transformations
        </a>
       </li>
       <li class="toctree-l4">
        <a class="reference internal" href="openvino_docs_OV_UG_lpt_step4_cleanup.html">
         Step 4. Cleanup transformations
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="openvino_docs_ie_plugin_api_references.html">
     Plugin API Reference
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-52" name="toctree-checkbox-52" type="checkbox"/>
    <label for="toctree-checkbox-52">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="simple">
    </ul>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Use OpenVINO™ Toolkit Securely
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_security_guide_introduction.html">
   Introduction to OpenVINO™ Security
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_security_guide_workbench.html">
   Deep Learning Workbench Security
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="openvino_docs_OV_UG_protecting_model_guide.html">
   Using Encrypted Models with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ovsa_get_started.html">
   OpenVINO™ Security Add-on
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#create-a-patch-file">
   Create a Patch File
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#convert-gnmt-model-to-ir">
   Convert GNMT Model to IR
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-to-use-gnmt-model">
   How to Use GNMT Model
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-to-run-gnmt-ir">
     How to RUN GNMT IR
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                <div class="tocsection download-docs">
  <div class="dropdown sst-dropdown">
    <button class="button bttn-prm button-size-m" data-display="static" type="button" id="download-options"
      data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
      Download Docs
    </button>
    <div class="dropdown-menu" aria-labelledby="download-options">
      <a class="dropdown-item" href="#" onclick="window.print()">.pdf</a>
      <a id="download-zip-btn" class="dropdown-item" href="#">.zip</a>
    </div>
  </div>
</div>
              </div>
              
            
          </div>
          

          
          
              
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">

<div class="tocsection editthispage">
    <a href="None">
        <i class="fas fa-pencil-alt"></i> Edit this page
    </a>
</div>

            
                <div>
                  
  <section id="convert-tensorflow-gnmt-model">
<span id="doxid-openvino-docs-m-o-d-g-prepare-model-convert-model-tf-specific-convert-g-n-m-t-from-tensorflow"></span><span id="index-0"></span><h1>Convert TensorFlow GNMT Model<a class="headerlink" href="#convert-tensorflow-gnmt-model" title="Permalink to this headline">¶</a></h1>
<p><span class="target" id="doxid-openvino-docs-m-o-d-g-prepare-model-convert-model-tf-specific-convert-g-n-m-t-from-tensorflow-1md-openvino-docs-mo-dg-prepare-model-convert-model-tf-specific-convert-gnmt-from-tensorflow"></span> This tutorial explains how to convert Google* Neural Machine Translation (GNMT) model to the Intermediate Representation (IR).</p>
<p>On GitHub*, you can find several public versions of TensorFlow* GNMT model implementation. This tutorial explains how to convert the GNMT model from the <a class="reference external" href="https://github.com/tensorflow/nmt">TensorFlow* Neural Machine Translation (NMT) repository</a> to the IR.</p>
<section id="create-a-patch-file">
<span id="patch-file"></span><h2>Create a Patch File<a class="headerlink" href="#create-a-patch-file" title="Permalink to this headline">¶</a></h2>
<p>Before converting the model, you need to create a patch file for the repository. The patch modifies the framework code by adding a special command-line argument to the framework options that enables inference graph dumping:</p>
<ol class="arabic">
<li><p>Go to a writable directory and create a <code class="docutils literal notranslate"><span class="pre">GNMT_inference.patch</span></code> file.</p></li>
<li><p>Copy the following diff code to the file:</p>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">diff</span> <span class="o">--</span><span class="n">git</span> <span class="n">a</span><span class="o">/</span><span class="n">nmt</span><span class="o">/</span><span class="n">inference</span><span class="p">.</span><span class="n">py</span> <span class="n">b</span><span class="o">/</span><span class="n">nmt</span><span class="o">/</span><span class="n">inference</span><span class="p">.</span><span class="n">py</span>
<span class="n">index</span> <span class="mi">2</span><span class="n">cbef07</span><span class="p">..</span><span class="n">e185490</span> <span class="mi">100644</span>
<span class="o">---</span> <span class="n">a</span><span class="o">/</span><span class="n">nmt</span><span class="o">/</span><span class="n">inference</span><span class="p">.</span><span class="n">py</span>
<span class="o">+++</span> <span class="n">b</span><span class="o">/</span><span class="n">nmt</span><span class="o">/</span><span class="n">inference</span><span class="p">.</span><span class="n">py</span>
<span class="err">@@</span> <span class="o">-</span><span class="mi">17</span><span class="p">,</span><span class="mi">9</span> <span class="o">+</span><span class="mi">17</span><span class="p">,</span><span class="mi">11</span> <span class="err">@@</span>
 <span class="n">from</span> <span class="n">__future__</span> <span class="n">import</span> <span class="n">print_function</span>

 <span class="n">import</span> <span class="n">codecs</span>
<span class="o">+</span><span class="n">import</span> <span class="n">os</span>
 <span class="n">import</span> <span class="n">time</span>

 <span class="n">import</span> <span class="n">tensorflow</span> <span class="n">as</span> <span class="n">tf</span>
<span class="o">+</span><span class="n">from</span> <span class="n">tensorflow</span><span class="p">.</span><span class="n">python</span><span class="p">.</span><span class="n">framework</span> <span class="n">import</span> <span class="n">graph_io</span>

 <span class="n">from</span> <span class="p">.</span> <span class="n">import</span> <span class="n">attention_model</span>
 <span class="n">from</span> <span class="p">.</span> <span class="n">import</span> <span class="n">gnmt_model</span>
<span class="err">@@</span> <span class="o">-</span><span class="mi">105</span><span class="p">,</span><span class="mi">6</span> <span class="o">+</span><span class="mi">107</span><span class="p">,</span><span class="mi">29</span> <span class="err">@@</span> <span class="n">def</span> <span class="n">start_sess_and_load_model</span><span class="p">(</span><span class="n">infer_model</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="p">)</span><span class="o">:</span>
   <span class="k">return</span> <span class="n">sess</span><span class="p">,</span> <span class="n">loaded_infer_model</span>


<span class="o">+</span><span class="n">def</span> <span class="n">inference_dump_graph</span><span class="p">(</span><span class="n">ckpt_path</span><span class="p">,</span> <span class="n">path_to_dump</span><span class="p">,</span> <span class="n">hparams</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="n">None</span><span class="p">)</span><span class="o">:</span>
<span class="o">+</span>    <span class="n">model_creator</span> <span class="o">=</span> <span class="n">get_model_creator</span><span class="p">(</span><span class="n">hparams</span><span class="p">)</span>
<span class="o">+</span>    <span class="n">infer_model</span> <span class="o">=</span> <span class="n">model_helper</span><span class="p">.</span><span class="n">create_infer_model</span><span class="p">(</span><span class="n">model_creator</span><span class="p">,</span> <span class="n">hparams</span><span class="p">,</span> <span class="n">scope</span><span class="p">)</span>
<span class="o">+</span>    <span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">Session</span><span class="p">(</span>
<span class="o">+</span>        <span class="n">graph</span><span class="o">=</span><span class="n">infer_model</span><span class="p">.</span><span class="n">graph</span><span class="p">,</span> <span class="n">config</span><span class="o">=</span><span class="n">utils</span><span class="p">.</span><span class="n">get_config_proto</span><span class="p">())</span>
<span class="o">+</span>    <span class="n">with</span> <span class="n">infer_model</span><span class="p">.</span><span class="n">graph</span><span class="p">.</span><span class="n">as_default</span><span class="p">()</span><span class="o">:</span>
<span class="o">+</span>        <span class="n">loaded_infer_model</span> <span class="o">=</span> <span class="n">model_helper</span><span class="p">.</span><span class="n">load_model</span><span class="p">(</span>
<span class="o">+</span>            <span class="n">infer_model</span><span class="p">.</span><span class="n">model</span><span class="p">,</span> <span class="n">ckpt_path</span><span class="p">,</span> <span class="n">sess</span><span class="p">,</span> <span class="s">&quot;infer&quot;</span><span class="p">)</span>
<span class="o">+</span>    <span class="n">utils</span><span class="p">.</span><span class="n">print_out</span><span class="p">(</span><span class="s">&quot;Dumping inference graph to {}&quot;</span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="n">path_to_dump</span><span class="p">))</span>
<span class="o">+</span>    <span class="n">loaded_infer_model</span><span class="p">.</span><span class="n">saver</span><span class="p">.</span><span class="n">save</span><span class="p">(</span>
<span class="o">+</span>        <span class="n">sess</span><span class="p">,</span>
<span class="o">+</span>        <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">path_to_dump</span> <span class="o">+</span> <span class="sc">&#39;inference_GNMT_graph&#39;</span><span class="p">)</span>
<span class="o">+</span>        <span class="p">)</span>
<span class="o">+</span>    <span class="n">utils</span><span class="p">.</span><span class="n">print_out</span><span class="p">(</span><span class="s">&quot;Dumping done!&quot;</span><span class="p">)</span>
<span class="o">+</span>
<span class="o">+</span>    <span class="n">output_node_name</span> <span class="o">=</span> <span class="sc">&#39;index_to_string_Lookup&#39;</span>
<span class="o">+</span>    <span class="n">utils</span><span class="p">.</span><span class="n">print_out</span><span class="p">(</span><span class="s">&quot;Freezing GNMT graph with output node {}...&quot;</span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="n">output_node_name</span><span class="p">))</span>
<span class="o">+</span>    <span class="n">frozen</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">graph_util</span><span class="p">.</span><span class="n">convert_variables_to_constants</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">sess</span><span class="p">.</span><span class="n">graph_def</span><span class="p">,</span>
<span class="o">+</span>                                                          <span class="p">[</span><span class="n">output_node_name</span><span class="p">])</span>
<span class="o">+</span>    <span class="n">graph_io</span><span class="p">.</span><span class="n">write_graph</span><span class="p">(</span><span class="n">frozen</span><span class="p">,</span> <span class="sc">&#39;.&#39;</span><span class="p">,</span> <span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">path_to_dump</span><span class="p">,</span> <span class="sc">&#39;frozen_GNMT_inference_graph.pb&#39;</span><span class="p">),</span> <span class="n">as_text</span><span class="o">=</span><span class="n">False</span><span class="p">)</span>
<span class="o">+</span>    <span class="n">utils</span><span class="p">.</span><span class="n">print_out</span><span class="p">(</span><span class="s">&quot;Freezing done. Freezed model frozen_GNMT_inference_graph.pb saved to {}&quot;</span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="n">path_to_dump</span><span class="p">))</span>
<span class="o">+</span>
<span class="o">+</span>
 <span class="n">def</span> <span class="n">inference</span><span class="p">(</span><span class="n">ckpt_path</span><span class="p">,</span>
               <span class="n">inference_input_file</span><span class="p">,</span>
               <span class="n">inference_output_file</span><span class="p">,</span>
<span class="n">diff</span> <span class="o">--</span><span class="n">git</span> <span class="n">a</span><span class="o">/</span><span class="n">nmt</span><span class="o">/</span><span class="n">nmt</span><span class="p">.</span><span class="n">py</span> <span class="n">b</span><span class="o">/</span><span class="n">nmt</span><span class="o">/</span><span class="n">nmt</span><span class="p">.</span><span class="n">py</span>
<span class="n">index</span> <span class="n">f5823d8</span><span class="p">..</span><span class="n">a733748</span> <span class="mi">100644</span>
<span class="o">---</span> <span class="n">a</span><span class="o">/</span><span class="n">nmt</span><span class="o">/</span><span class="n">nmt</span><span class="p">.</span><span class="n">py</span>
<span class="o">+++</span> <span class="n">b</span><span class="o">/</span><span class="n">nmt</span><span class="o">/</span><span class="n">nmt</span><span class="p">.</span><span class="n">py</span>
<span class="err">@@</span> <span class="o">-</span><span class="mi">310</span><span class="p">,</span><span class="mi">6</span> <span class="o">+</span><span class="mi">310</span><span class="p">,</span><span class="mi">13</span> <span class="err">@@</span> <span class="n">def</span> <span class="n">add_arguments</span><span class="p">(</span><span class="n">parser</span><span class="p">)</span><span class="o">:</span>
   <span class="n">parser</span><span class="p">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">&quot;--num_intra_threads&quot;</span><span class="p">,</span> <span class="n">type</span><span class="o">=</span><span class="kt">int</span><span class="p">,</span> <span class="k">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                       <span class="n">help</span><span class="o">=</span><span class="s">&quot;number of intra_op_parallelism_threads&quot;</span><span class="p">)</span>

<span class="o">+</span>  <span class="err">#</span> <span class="n">Special</span> <span class="n">argument</span> <span class="k">for</span> <span class="n">inference</span> <span class="n">model</span> <span class="n">dumping</span> <span class="n">without</span> <span class="n">inference</span>
<span class="o">+</span>  <span class="n">parser</span><span class="p">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">&quot;--dump_inference_model&quot;</span><span class="p">,</span> <span class="n">type</span><span class="o">=</span><span class="s">&quot;bool&quot;</span><span class="p">,</span> <span class="n">nargs</span><span class="o">=</span><span class="s">&quot;?&quot;</span><span class="p">,</span>
<span class="o">+</span>                      <span class="k">const</span><span class="o">=</span><span class="n">True</span><span class="p">,</span> <span class="k">default</span><span class="o">=</span><span class="n">False</span><span class="p">,</span>
<span class="o">+</span>                      <span class="n">help</span><span class="o">=</span><span class="s">&quot;Argument for dump inference graph for specified trained ckpt&quot;</span><span class="p">)</span>
<span class="o">+</span>
<span class="o">+</span>  <span class="n">parser</span><span class="p">.</span><span class="n">add_argument</span><span class="p">(</span><span class="s">&quot;--path_to_dump&quot;</span><span class="p">,</span> <span class="n">type</span><span class="o">=</span><span class="n">str</span><span class="p">,</span> <span class="k">default</span><span class="o">=</span><span class="s">&quot;&quot;</span><span class="p">,</span>
<span class="o">+</span>                      <span class="n">help</span><span class="o">=</span><span class="s">&quot;Path to dump inference graph.&quot;</span><span class="p">)</span>

 <span class="n">def</span> <span class="n">create_hparams</span><span class="p">(</span><span class="n">flags</span><span class="p">)</span><span class="o">:</span>
   <span class="s">&quot;&quot;&quot;Create training hparams.&quot;&quot;&quot;</span>
<span class="err">@@</span> <span class="o">-</span><span class="mi">396</span><span class="p">,</span><span class="mi">6</span> <span class="o">+</span><span class="mi">403</span><span class="p">,</span><span class="mi">9</span> <span class="err">@@</span> <span class="n">def</span> <span class="n">create_hparams</span><span class="p">(</span><span class="n">flags</span><span class="p">)</span><span class="o">:</span>
       <span class="n">language_model</span><span class="o">=</span><span class="n">flags</span><span class="p">.</span><span class="n">language_model</span><span class="p">,</span>
       <span class="n">num_intra_threads</span><span class="o">=</span><span class="n">flags</span><span class="p">.</span><span class="n">num_intra_threads</span><span class="p">,</span>
       <span class="n">num_inter_threads</span><span class="o">=</span><span class="n">flags</span><span class="p">.</span><span class="n">num_inter_threads</span><span class="p">,</span>
<span class="o">+</span>
<span class="o">+</span>      <span class="n">dump_inference_model</span><span class="o">=</span><span class="n">flags</span><span class="p">.</span><span class="n">dump_inference_model</span><span class="p">,</span>
<span class="o">+</span>      <span class="n">path_to_dump</span><span class="o">=</span><span class="n">flags</span><span class="p">.</span><span class="n">path_to_dump</span><span class="p">,</span>
   <span class="p">)</span>


<span class="err">@@</span> <span class="o">-</span><span class="mi">613</span><span class="p">,</span><span class="mi">7</span> <span class="o">+</span><span class="mi">623</span><span class="p">,</span><span class="mi">7</span> <span class="err">@@</span> <span class="n">def</span> <span class="n">create_or_load_hparams</span><span class="p">(</span>
   <span class="k">return</span> <span class="n">hparams</span>


<span class="o">-</span><span class="n">def</span> <span class="n">run_main</span><span class="p">(</span><span class="n">flags</span><span class="p">,</span> <span class="n">default_hparams</span><span class="p">,</span> <span class="n">train_fn</span><span class="p">,</span> <span class="n">inference_fn</span><span class="p">,</span> <span class="n">target_session</span><span class="o">=</span><span class="s">&quot;&quot;</span><span class="p">)</span><span class="o">:</span>
<span class="o">+</span><span class="n">def</span> <span class="n">run_main</span><span class="p">(</span><span class="n">flags</span><span class="p">,</span> <span class="n">default_hparams</span><span class="p">,</span> <span class="n">train_fn</span><span class="p">,</span> <span class="n">inference_fn</span><span class="p">,</span> <span class="n">inference_dump</span><span class="p">,</span> <span class="n">target_session</span><span class="o">=</span><span class="s">&quot;&quot;</span><span class="p">)</span><span class="o">:</span>
   <span class="s">&quot;&quot;&quot;Run main.&quot;&quot;&quot;</span>
   <span class="cp"># Job</span>
   <span class="n">jobid</span> <span class="o">=</span> <span class="n">flags</span><span class="p">.</span><span class="n">jobid</span>
<span class="err">@@</span> <span class="o">-</span><span class="mi">653</span><span class="p">,</span><span class="mi">8</span> <span class="o">+</span><span class="mi">663</span><span class="p">,</span><span class="mi">26</span> <span class="err">@@</span> <span class="n">def</span> <span class="n">run_main</span><span class="p">(</span><span class="n">flags</span><span class="p">,</span> <span class="n">default_hparams</span><span class="p">,</span> <span class="n">train_fn</span><span class="p">,</span> <span class="n">inference_fn</span><span class="p">,</span> <span class="n">target_session</span><span class="o">=</span><span class="s">&quot;&quot;</span><span class="p">)</span><span class="o">:</span>
         <span class="n">out_dir</span><span class="p">,</span> <span class="n">default_hparams</span><span class="p">,</span> <span class="n">flags</span><span class="p">.</span><span class="n">hparams_path</span><span class="p">,</span>
         <span class="n">save_hparams</span><span class="o">=</span><span class="p">(</span><span class="n">jobid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">))</span>

<span class="o">-</span>  <span class="err">##</span> <span class="n">Train</span> <span class="o">/</span> <span class="n">Decode</span>
<span class="o">-</span>  <span class="k">if</span> <span class="n">flags</span><span class="p">.</span><span class="nl">inference_input_file</span><span class="p">:</span>
<span class="o">+</span>  <span class="err">#</span>  <span class="n">Dumping</span> <span class="n">inference</span> <span class="n">model</span>
<span class="o">+</span>  <span class="k">if</span> <span class="n">flags</span><span class="p">.</span><span class="nl">dump_inference_model</span><span class="p">:</span>
<span class="o">+</span>      <span class="err">#</span> <span class="n">Inference</span> <span class="n">indices</span>
<span class="o">+</span>      <span class="n">hparams</span><span class="p">.</span><span class="n">inference_indices</span> <span class="o">=</span> <span class="n">None</span>
<span class="o">+</span>      <span class="k">if</span> <span class="n">flags</span><span class="p">.</span><span class="nl">inference_list</span><span class="p">:</span>
<span class="o">+</span>          <span class="p">(</span><span class="n">hparams</span><span class="p">.</span><span class="n">inference_indices</span><span class="p">)</span> <span class="o">=</span> <span class="p">(</span>
<span class="o">+</span>              <span class="p">[</span><span class="kt">int</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="n">in</span> <span class="n">flags</span><span class="p">.</span><span class="n">inference_list</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">&quot;,&quot;</span><span class="p">)])</span>
<span class="o">+</span>
<span class="o">+</span>      <span class="err">#</span> <span class="n">Ckpt</span>
<span class="o">+</span>      <span class="n">ckpt</span> <span class="o">=</span> <span class="n">flags</span><span class="p">.</span><span class="n">ckpt</span>
<span class="o">+</span>      <span class="k">if</span> <span class="n">not</span> <span class="nl">ckpt</span><span class="p">:</span>
<span class="o">+</span>          <span class="n">ckpt</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="n">out_dir</span><span class="p">)</span>
<span class="o">+</span>
<span class="o">+</span>      <span class="err">#</span> <span class="n">Path</span> <span class="n">to</span> <span class="n">dump</span> <span class="n">graph</span>
<span class="o">+</span>      <span class="n">assert</span> <span class="n">flags</span><span class="p">.</span><span class="n">path_to_dump</span> <span class="o">!=</span> <span class="s">&quot;&quot;</span><span class="p">,</span> <span class="s">&quot;Please, specify path_to_dump model.&quot;</span>
<span class="o">+</span>      <span class="n">path_to_dump</span> <span class="o">=</span> <span class="n">flags</span><span class="p">.</span><span class="n">path_to_dump</span>
<span class="o">+</span>      <span class="k">if</span> <span class="n">not</span> <span class="n">tf</span><span class="p">.</span><span class="n">gfile</span><span class="p">.</span><span class="n">Exists</span><span class="p">(</span><span class="n">path_to_dump</span><span class="p">)</span><span class="o">:</span> <span class="n">tf</span><span class="p">.</span><span class="n">gfile</span><span class="p">.</span><span class="n">MakeDirs</span><span class="p">(</span><span class="n">path_to_dump</span><span class="p">)</span>
<span class="o">+</span>
<span class="o">+</span>      <span class="n">inference_dump</span><span class="p">(</span><span class="n">ckpt</span><span class="p">,</span> <span class="n">path_to_dump</span><span class="p">,</span> <span class="n">hparams</span><span class="p">)</span>
<span class="o">+</span>  <span class="n">elif</span> <span class="n">flags</span><span class="p">.</span><span class="nl">inference_input_file</span><span class="p">:</span>
     <span class="cp"># Inference output directory</span>
     <span class="n">trans_file</span> <span class="o">=</span> <span class="n">flags</span><span class="p">.</span><span class="n">inference_output_file</span>
     <span class="n">assert</span> <span class="n">trans_file</span>
<span class="err">@@</span> <span class="o">-</span><span class="mi">693</span><span class="p">,</span><span class="mi">7</span> <span class="o">+</span><span class="mi">721</span><span class="p">,</span><span class="mi">8</span> <span class="err">@@</span> <span class="n">def</span> <span class="n">main</span><span class="p">(</span><span class="n">unused_argv</span><span class="p">)</span><span class="o">:</span>
   <span class="n">default_hparams</span> <span class="o">=</span> <span class="n">create_hparams</span><span class="p">(</span><span class="n">FLAGS</span><span class="p">)</span>
   <span class="n">train_fn</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="n">train</span>
   <span class="n">inference_fn</span> <span class="o">=</span> <span class="n">inference</span><span class="p">.</span><span class="n">inference</span>
<span class="o">-</span>  <span class="n">run_main</span><span class="p">(</span><span class="n">FLAGS</span><span class="p">,</span> <span class="n">default_hparams</span><span class="p">,</span> <span class="n">train_fn</span><span class="p">,</span> <span class="n">inference_fn</span><span class="p">)</span>
<span class="o">+</span>  <span class="n">inference_dump</span> <span class="o">=</span> <span class="n">inference</span><span class="p">.</span><span class="n">inference_dump_graph</span>
<span class="o">+</span>  <span class="n">run_main</span><span class="p">(</span><span class="n">FLAGS</span><span class="p">,</span> <span class="n">default_hparams</span><span class="p">,</span> <span class="n">train_fn</span><span class="p">,</span> <span class="n">inference_fn</span><span class="p">,</span> <span class="n">inference_dump</span><span class="p">)</span>


 <span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&quot;__main__&quot;</span><span class="o">:</span></pre></div></div></li>
<li><p>Save and close the file.</p></li>
</ol>
</section>
<section id="convert-gnmt-model-to-ir">
<h2>Convert GNMT Model to IR<a class="headerlink" href="#convert-gnmt-model-to-ir" title="Permalink to this headline">¶</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Please, use TensorFlow version 1.13 or lower.</p>
</div>
<p><strong>Step 1</strong>. Clone the GitHub repository and check out the commit:</p>
<ol class="arabic">
<li><p>Clone the NMT reposirory:</p>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">clone</span> <span class="nl">https</span><span class="p">:</span><span class="c1">//github.com/tensorflow/nmt.git</span></pre></div></div></li>
<li><p>Check out the necessary commit:</p>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">checkout</span> <span class="n">b278487980832417ad8ac701c672b5c3dc7fa553</span></pre></div></div></li>
</ol>
<p><strong>Step 2</strong>. Get a trained model. You have two options:</p>
<ul class="simple">
<li><p>Train the model with the GNMT <code class="docutils literal notranslate"><span class="pre">wmt16_gnmt_4_layer.json</span></code> or <code class="docutils literal notranslate"><span class="pre">wmt16_gnmt_8_layer.json</span></code> configuration file using the NMT framework.</p></li>
<li><p><em>Do not use the pre-trained checkpoints provided in the NMT repository, as they are outdated and can be incompatible with the current repository version.</em></p></li>
</ul>
<p>This tutorial assumes the use of the trained GNMT model from <code class="docutils literal notranslate"><span class="pre">wmt16_gnmt_4_layer.json</span></code> config, German to English translation.</p>
<p><strong>Step 3</strong>. Create an inference graph:</p>
<p>The OpenVINO assumes that a model is used for inference only. Hence, before converting the model into the IR, you need to transform the training graph into the inference graph. For the GNMT model, the training graph and the inference graph have different decoders: the training graph uses a greedy search decoding algorithm, while the inference graph uses a beam search decoding algorithm.</p>
<ol class="arabic">
<li><p>Apply the <code class="docutils literal notranslate"><span class="pre">GNMT_inference.patch</span></code> patch to the repository. Refer to the <a class="reference external" href="#patch-file">Create a Patch File</a> instructions if you do not have it:</p>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">git</span> <span class="n">apply</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">patch</span><span class="o">/</span><span class="n">GNMT_inference</span><span class="p">.</span><span class="n">patch</span></pre></div></div></li>
<li><p>Run the NMT framework to dump the inference model:</p></li>
</ol>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">nmt</span><span class="p">.</span><span class="n">nmt</span>
    <span class="o">--</span><span class="n">src</span><span class="o">=</span><span class="n">de</span>
    <span class="o">--</span><span class="n">tgt</span><span class="o">=</span><span class="n">en</span>
    <span class="o">--</span><span class="n">ckpt</span><span class="o">=/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">ckpt</span><span class="o">/</span><span class="n">translate</span><span class="p">.</span><span class="n">ckpt</span>
    <span class="o">--</span><span class="n">hparams_path</span><span class="o">=/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">repository</span><span class="o">/</span><span class="n">nmt</span><span class="o">/</span><span class="n">nmt</span><span class="o">/</span><span class="n">standard_hparams</span><span class="o">/</span><span class="n">wmt16_gnmt_4_layer</span><span class="p">.</span><span class="n">json</span>
    <span class="o">--</span><span class="n">vocab_prefix</span><span class="o">=/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">vocab</span><span class="o">/</span><span class="n">vocab</span><span class="p">.</span><span class="n">bpe</span><span class="mf">.32000</span>
    <span class="o">--</span><span class="n">out_dir</span><span class="o">=</span><span class="s">&quot;&quot;</span>
    <span class="o">--</span><span class="n">dump_inference_model</span>
    <span class="o">--</span><span class="n">infer_mode</span> <span class="n">beam_search</span>
    <span class="o">--</span><span class="n">path_to_dump</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">dump</span><span class="o">/</span><span class="n">model</span><span class="o">/</span></pre></div></div><p>If you use different checkpoints, use the corresponding values for the <code class="docutils literal notranslate"><span class="pre">src</span></code>, <code class="docutils literal notranslate"><span class="pre">tgt</span></code>, <code class="docutils literal notranslate"><span class="pre">ckpt</span></code>, <code class="docutils literal notranslate"><span class="pre">hparams_path</span></code>, and <code class="docutils literal notranslate"><span class="pre">vocab_prefix</span></code> parameters. Inference checkpoint <code class="docutils literal notranslate"><span class="pre">inference_GNMT_graph</span></code> and frozen inference graph <code class="docutils literal notranslate"><span class="pre">frozen_GNMT_inference_graph.pb</span></code> will appear in the <code class="docutils literal notranslate"><span class="pre">/path/to/dump/model/</span></code> folder.</p>
<p>To generate <code class="docutils literal notranslate"><span class="pre">vocab.bpe.32000</span></code>, execute the <code class="docutils literal notranslate"><span class="pre">nmt/scripts/wmt16_en_de.sh</span></code> script. If you face an issue of a size mismatch between the checkpoint graph’s embedding layer and vocabulary (both src and target), we recommend you to add the following code to the <code class="docutils literal notranslate"><span class="pre">nmt.py</span></code> file to the <code class="docutils literal notranslate"><span class="pre">extend_hparams</span></code> function after the line 508 (after initialization of the <code class="docutils literal notranslate"><span class="pre">src_vocab_size</span></code> and <code class="docutils literal notranslate"><span class="pre">tgt_vocab_size</span></code> variables):</p>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">src_vocab_size</span> <span class="o">-=</span> <span class="mi">1</span>
<span class="n">tgt_vocab_size</span> <span class="o">-=</span> <span class="mi">1</span></pre></div></div><p><strong>Step 4</strong>. Convert the model to the IR:</p>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">mo</span>
<span class="o">--</span><span class="n">input_model</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">dump</span><span class="o">/</span><span class="n">model</span><span class="o">/</span><span class="n">frozen_GNMT_inference_graph</span><span class="p">.</span><span class="n">pb</span>
<span class="o">--</span><span class="n">input</span> <span class="s">&quot;IteratorGetNext:1{i32}[1],IteratorGetNext:0{i32}[1 50],dynamic_seq2seq/hash_table_Lookup_1:0[1]-&gt;[2],dynamic_seq2seq/hash_table_Lookup:0[1]-&gt;[1]&quot;</span>
<span class="o">--</span><span class="n">output</span> <span class="n">dynamic_seq2seq</span><span class="o">/</span><span class="n">decoder</span><span class="o">/</span><span class="n">decoder</span><span class="o">/</span><span class="n">GatherTree</span>
<span class="o">--</span><span class="n">output_dir</span> <span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="n">to</span><span class="o">/</span><span class="n">output</span><span class="o">/</span><span class="n">IR</span><span class="o">/</span></pre></div></div><p>Input and output cutting with the <code class="docutils literal notranslate"><span class="pre">--input</span></code> and <code class="docutils literal notranslate"><span class="pre">--output</span></code> options is required since OpenVINO does not support <code class="docutils literal notranslate"><span class="pre">IteratorGetNext</span></code> and <code class="docutils literal notranslate"><span class="pre">LookupTableFindV2</span></code> operations.</p>
<p>Input cutting:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IteratorGetNext</span></code> operation iterates over a dataset. It is cut by output ports: port 0 contains data tensor with shape <code class="docutils literal notranslate"><span class="pre">[batch_size,</span> <span class="pre">max_sequence_length]</span></code>, port 1 contains <code class="docutils literal notranslate"><span class="pre">sequence_length</span></code> for every batch with shape <code class="docutils literal notranslate"><span class="pre">[batch_size]</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">LookupTableFindV2</span></code> operations (<code class="docutils literal notranslate"><span class="pre">dynamic_seq2seq/hash_table_Lookup_1</span></code> and <code class="docutils literal notranslate"><span class="pre">dynamic_seq2seq/hash_table_Lookup</span></code> nodes in the graph) are cut with constant values).</p></li>
</ul>
<p>Output cutting:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">LookupTableFindV2</span></code> operation is cut from the output and the <code class="docutils literal notranslate"><span class="pre">dynamic_seq2seq/decoder/decoder/GatherTree</span></code> node is treated as a new exit point.</p></li>
</ul>
<p>For more information about model cutting, refer to <a class="reference internal" href="openvino_docs_MO_DG_prepare_model_convert_model_Cutting_Model.html#doxid-openvino-docs-m-o-d-g-prepare-model-convert-model-cutting-model"><span class="std std-ref">Cutting Off Parts of a Model</span></a>.</p>
</section>
<section id="how-to-use-gnmt-model">
<span id="run-gnmt"></span><h2>How to Use GNMT Model<a class="headerlink" href="#how-to-use-gnmt-model" title="Permalink to this headline">¶</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This step assumes you have converted a model to the Intermediate Representation.</p>
</div>
<p>Inputs of the model:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IteratorGetNext/placeholder_out_port_0</span></code> input with shape <code class="docutils literal notranslate"><span class="pre">[batch_size,</span> <span class="pre">max_sequence_length]</span></code> contains <code class="docutils literal notranslate"><span class="pre">batch_size</span></code> decoded input sentences. Every sentence is decoded the same way as indices of sentence elements in vocabulary and padded with index of <code class="docutils literal notranslate"><span class="pre">eos</span></code> (end of sentence symbol). If the length of the sentence is less than <code class="docutils literal notranslate"><span class="pre">max_sequence_length</span></code>, remaining elements are filled with index of <code class="docutils literal notranslate"><span class="pre">eos</span></code> token.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IteratorGetNext/placeholder_out_port_1</span></code> input with shape <code class="docutils literal notranslate"><span class="pre">[batch_size]</span></code> contains sequence lengths for every sentence from the first input. For example, if <code class="docutils literal notranslate"><span class="pre">max_sequence_length</span> <span class="pre">=</span> <span class="pre">50</span></code>, <code class="docutils literal notranslate"><span class="pre">batch_size</span> <span class="pre">=</span> <span class="pre">1</span></code> and the sentence has only 30 elements, then the input tensor for <code class="docutils literal notranslate"><span class="pre">IteratorGetNext/placeholder_out_port_1</span></code> should be <code class="docutils literal notranslate"><span class="pre">[30]</span></code>.</p></li>
</ul>
<p>Outputs of the model:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">dynamic_seq2seq/decoder/decoder/GatherTree</span></code> tensor with shape <code class="docutils literal notranslate"><span class="pre">[max_sequence_length</span> <span class="pre">\*</span> <span class="pre">2,</span> <span class="pre">batch,</span> <span class="pre">beam_size]</span></code>, that contains <code class="docutils literal notranslate"><span class="pre">beam_size</span></code> best translations for every sentence from input (also decoded as indices of words in vocabulary). </p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Shape of this tensor in TensorFlow* can be different: instead of <code class="docutils literal notranslate"><span class="pre">max_sequence_length</span> <span class="pre">\*</span> <span class="pre">2</span></code>, it can be any value less than that, because OpenVINO does not support dynamic shapes of outputs, while TensorFlow can stop decoding iterations when <code class="docutils literal notranslate"><span class="pre">eos</span></code> symbol is generated.*</p>
</div>
</li>
</ul>
<section id="how-to-run-gnmt-ir">
<span id="id1"></span><h3>How to RUN GNMT IR<a class="headerlink" href="#how-to-run-gnmt-ir" title="Permalink to this headline">¶</a></h3>
<ol class="arabic">
<li><p>With benchmark app:</p>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">benchmark_app</span> <span class="o">-</span><span class="n">m</span> <span class="o">&lt;</span><span class="n">path</span> <span class="n">to</span> <span class="n">the</span> <span class="n">generated</span> <span class="n">GNMT</span> <span class="n">IR</span><span class="o">&gt;</span> <span class="o">-</span><span class="n">d</span> <span class="n">CPU</span></pre></div></div></li>
<li><p>With OpenVINO Runtime Python API:</p></li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Before running the example, insert a path to your GNMT <code class="docutils literal notranslate"><span class="pre">.xml</span></code> and <code class="docutils literal notranslate"><span class="pre">.bin</span></code> files into <code class="docutils literal notranslate"><span class="pre">MODEL_PATH</span></code> and <code class="docutils literal notranslate"><span class="pre">WEIGHTS_PATH</span></code>, and fill <code class="docutils literal notranslate"><span class="pre">input_data_tensor</span></code> and <code class="docutils literal notranslate"><span class="pre">seq_lengths</span></code> tensors according to your input data.</p>
</div>
<div class="highlight"><div class="highlight"><pre><span></span><span class="n">from</span> <span class="n">openvino</span><span class="p">.</span><span class="n">inference_engine</span> <span class="n">import</span> <span class="n">IENetwork</span><span class="p">,</span> <span class="n">IECore</span>

<span class="n">MODEL_PATH</span> <span class="o">=</span> <span class="sc">&#39;/path/to/IR/frozen_GNMT_inference_graph.xml&#39;</span>
<span class="n">WEIGHTS_PATH</span> <span class="o">=</span> <span class="sc">&#39;/path/to/IR/frozen_GNMT_inference_graph.bin&#39;</span>

<span class="cp"># Creating network</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">IENetwork</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">MODEL_PATH</span><span class="p">,</span>
    <span class="n">weights</span><span class="o">=</span><span class="n">WEIGHTS_PATH</span><span class="p">)</span>

<span class="cp"># Creating input data</span>
<span class="n">input_data</span> <span class="o">=</span> <span class="p">{</span><span class="sc">&#39;IteratorGetNext/placeholder_out_port_0&#39;</span><span class="o">:</span> <span class="n">input_data_tensor</span><span class="p">,</span>
              <span class="sc">&#39;IteratorGetNext/placeholder_out_port_1&#39;</span><span class="o">:</span> <span class="n">seq_lengths</span><span class="p">}</span>

<span class="cp"># Creating plugin and loading extensions</span>
<span class="n">ie</span> <span class="o">=</span> <span class="n">IECore</span><span class="p">()</span>
<span class="n">ie</span><span class="p">.</span><span class="n">add_extension</span><span class="p">(</span><span class="n">extension_path</span><span class="o">=</span><span class="s">&quot;libcpu_extension.so&quot;</span><span class="p">,</span> <span class="n">device_name</span><span class="o">=</span><span class="s">&quot;CPU&quot;</span><span class="p">)</span>

<span class="cp"># Loading network</span>
<span class="n">exec_net</span> <span class="o">=</span> <span class="n">ie</span><span class="p">.</span><span class="n">load_network</span><span class="p">(</span><span class="n">network</span><span class="o">=</span><span class="n">net</span><span class="p">,</span> <span class="n">device_name</span><span class="o">=</span><span class="s">&quot;CPU&quot;</span><span class="p">)</span>

<span class="cp"># Run inference</span>
<span class="n">result_ie</span> <span class="o">=</span> <span class="n">exec_net</span><span class="p">.</span><span class="n">infer</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span></pre></div></div><p>For more information about Python API, refer to <a class="reference external" href="ie_python_api/api.html">OpenVINO Runtime Python API</a>.</p>
</section>
</section>
</section>


                </div>
            
            
                <div class='prev-next-bottom'>
                  
    <a class='button bttn-sec button-size-l' id="prev-link" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_FaceNet_From_Tensorflow.html" title="previous page">Prev</a>
    <a class='button bttn-sec button-size-l' id="next-link" href="openvino_docs_MO_DG_prepare_model_convert_model_tf_specific_Convert_lm_1b_From_Tensorflow.html" title="next page">Next</a>

                </div>
            
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, Intel®.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.2.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>