
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Vehicle Detection And Recognition with OpenVINO &#8212; OpenVINO™  documentation</title>
    
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <link rel="stylesheet" type="text/css" href="../_static/doxyrest-pygments.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <link href="../_static/css/media/favicon.ico" rel="shortcut icon">
    <link rel="stylesheet" href="../_static/css/openvino_sphinx_theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/button.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/input.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/textfield.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/tabs.css" type="text/css" />
    <script src="../_static/js/openvino_sphinx_theme.js"></script>
    <link rel="stylesheet" href="../_static/css/viewer.min.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />

    <script src="https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-datalabels"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/chartjs-plugin-annotation/0.5.7/chartjs-plugin-annotation.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-barchart-background@1.3.0/build/Plugin.Barchart.Background.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-deferred@1"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/PapaParse/5.3.1/papaparse.min.js"></script>
    <script src="../_static/js/viewer.min.js"></script>
    <script src="/assets/versions_raw.js"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/tabs.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/js/custom.js"></script>
    <script src="../_static/js/graphs.js"></script>
    <script src="../_static/js/graphs_ov_tf.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/target-highlight.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <link rel="canonical" href="https://docs.openvino.ai/latest/notebooks/218-vehicle-detection-and-recognition-with-output.html" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="From Training to Deployment with TensorFlow and OpenVINO" href="301-tensorflow-training-openvino-with-output.html" />
    <link rel="prev" title="Deblur Photos with DeblurGAN-v2 and OpenVINO" href="217-vision-deblur-with-output.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
      <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../index.html">
  <img src="../_static/logo.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../pages/documentation.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../tutorials.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../api/api_reference.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../model_zoo.html">
  Model Zoo
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../pages/resources.html">
  Resources
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/openvinotoolkit/openvino" rel="noopener" target="_blank" title="GitHub">
            <span><i class="sst-github"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
</ul>
      </div>
      
      <div class="navbar-end-item">
        
<div class="dropdown sst-dropdown sst-dropdown-navbar">
  <button class="btn sst-btn dropdown-toggle" type="button" id="version-selector" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"></button>
  <div class="dropdown-menu" aria-labelledby="version-selector">
  </div>
</div>
      </div>
      
      <div class="navbar-end-item">
        

<div class="dropdown sst-dropdown sst-dropdown-navbar">
  <button class="btn sst-btn dropdown-toggle" type="button" id="language-selector" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">English</button>
  <div class="dropdown-menu" aria-labelledby="language-selector">
    
      
        <a class="dropdown-item font-weight-bold" href="/latest/notebooks/218-vehicle-detection-and-recognition-with-output.html">English</a>
      
    
      
        <a  class="dropdown-item" href="/cn/latest/notebooks/218-vehicle-detection-and-recognition-with-output.html">Chinese</a>
      
    
  </div>
</div>

      </div>
      
    </div>
  </div>
</div>
        <div id="collapse-nav-wrapper" class="container-xl">
          <button id="collapse-nav" class="button bttn-prm button-size-m" type="button" data-toggle="collapse" data-target="#nav-tree" aria-expanded="false" aria-controls="nav-tree">
            Documentation navigation <i class="fas fa-chevron-down"></i>
          </button>
        </div>
      </nav>
      <div class="transition-banner container-fluid alert alert-info alert-dismissible fade show" role="alert">
        <p>OpenVINO 2022.1 introduces a new version of OpenVINO API (API 2.0). For more information on the changes and transition steps, see the <a href="https://docs.openvino.ai/latest/openvino_2_0_transition_guide.html">transition guide</a></p>
        <button type="button" class="close" data-dismiss="alert" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
    </div>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar" id="nav-tree"><form class="searchForm bd-search d-flex align-items-center" action="../search.html" method="get">
    <i class="icon fas fa-search"></i>
    <input type="search" class="form-control" name="query" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="001-hello-world-with-output.html">
   Hello Image Classification
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="002-openvino-api-with-output.html">
   OpenVINO API Tutorial
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="003-hello-segmentation-with-output.html">
   Hello Image Segmentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="004-hello-detection-with-output.html">
   Hello Object Detection
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="101-tensorflow-to-openvino-with-output.html">
   Convert a TensorFlow Model to OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="102-pytorch-onnx-to-openvino-with-output.html">
   Convert a PyTorch Model to ONNX and OpenVINO IR
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="103-paddle-onnx-to-openvino-classification-with-output.html">
   Convert a PaddlePaddle Model to ONNX and OpenVINO IR
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="104-model-tools-with-output.html">
   Working with Open Model Zoo Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="105-language-quantize-bert-with-output.html">
   Quantize NLP models with OpenVINO Post-Training Optimization Tool ​
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="106-auto-device-with-output.html">
   Automatic Device Selection with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="110-ct-segmentation-quantize-with-output.html">
   Quantize a Segmentation Model and Show Live Inference
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="111-detection-quantization-with-output.html">
   Object Detection Quantization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="112-pytorch-post-training-quantization-nncf-with-output.html">
   Post-Training Quantization of PyTorch models with NNCF
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="113-image-classification-quantization-with-output.html">
   Quantization of Image Classification Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="114-quantization-simplified-mode-with-output.html">
   INT8 Quantization with Post-training Optimization Tool (POT) in Simplified Mode tutorial
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="201-vision-monodepth-with-output.html">
   Monodepth Estimation with OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="202-vision-superresolution-image-with-output.html">
   Single Image Super Resolution with OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="202-vision-superresolution-video-with-output.html">
   Video Super Resolution with OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="205-vision-background-removal-with-output.html">
   Image Background Removal with U^2-Net and OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="206-vision-paddlegan-anime-with-output.html">
   Photos to Anime with PaddleGAN and OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="207-vision-paddlegan-superresolution-with-output.html">
   Super Resolution with PaddleGAN and OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="208-optical-character-recognition-with-output.html">
   Optical Character Recognition (OCR) with OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="209-handwritten-ocr-with-output.html">
   Handwritten Chinese and Japanese OCR
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="210-ct-scan-live-inference-with-output.html">
   Live Inference and Benchmark CT-scan Data with OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="211-speech-to-text-with-output.html">
   Speech to Text with OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="212-onnx-style-transfer-with-output.html">
   Style Transfer on ONNX Models with OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="213-question-answering-with-output.html">
   Interactive question answering with OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="214-vision-paddle-classification-with-output.html">
   PaddlePaddle Image Classification with OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="215-image-inpainting-with-output.html">
   Image In-painting with OpenVINO™
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="217-vision-deblur-with-output.html">
   Deblur Photos with DeblurGAN-v2 and OpenVINO
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Vehicle Detection And Recognition with OpenVINO
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="301-tensorflow-training-openvino-with-output.html">
   From Training to Deployment with TensorFlow and OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="301-tensorflow-training-openvino-pot-with-output.html">
   Post-Training Quantization with TensorFlow Classification Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="302-pytorch-quantization-aware-training-with-output.html">
   Quantization Aware Training with NNCF, using PyTorch framework
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="305-tensorflow-quantization-aware-training-with-output.html">
   Quantization Aware Training with NNCF, using TensorFlow Framework
  </a>
 </li>
</ul>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="401-object-detection-with-output.html">
   Live Object Detection with OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="402-pose-estimation-with-output.html">
   Live Human Pose Estimation with OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="403-action-recognition-webcam-with-output.html">
   Human Action Recognition with OpenVINO
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="405-paddle-ocr-webcam-with-output.html">
   PaddleOCR with OpenVINO
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Vehicle Detection And Recognition with OpenVINO
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#imports">
   Imports
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#download-models">
   Download Models
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-models">
   Load Models
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#get-attributes-from-model">
     Get attributes from model
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#helper-function">
     Helper function
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#read-and-display-a-test-image">
     Read and display a test image
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#use-detection-model-to-detect-vehicles">
   Use detection model to detect vehicles
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#detection-processing">
     Detection Processing
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recognize-vehicle-attributes">
     Recognize vehicle attributes
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#recognition-processing">
       Recognition processing
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conbine-two-models">
     Conbine two models
    </a>
   </li>
  </ul>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                <div class="tocsection download-docs">
  <div class="dropdown sst-dropdown">
    <button class="button bttn-prm button-size-m" data-display="static" type="button" id="download-options"
      data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
      Download Docs
    </button>
    <div class="dropdown-menu" aria-labelledby="download-options">
      <a class="dropdown-item" href="#" onclick="window.print()">.pdf</a>
      <a id="download-zip-btn" class="dropdown-item" href="#">.zip</a>
    </div>
  </div>
</div>
              </div>
              
            
          </div>
          

          
          
              
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">

<div class="tocsection editthispage">
    <a href="None">
        <i class="fas fa-pencil-alt"></i> Edit this page
    </a>
</div>

            
                <div>
                  
  <section id="vehicle-detection-and-recognition-with-openvino">
<h1>Vehicle Detection And Recognition with OpenVINO<a class="headerlink" href="#vehicle-detection-and-recognition-with-openvino" title="Permalink to this headline">¶</a></h1>
<p>This tutorial demonstrates how to use two pre-trained models from <a class="reference external" href="https://github.com/openvinotoolkit/open_model_zoo">Open
Model Zoo</a>:
<a class="reference external" href="https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/intel/vehicle-detection-0200">vehicle-detection-0200</a>
for object detection and
<a class="reference external" href="https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/intel/vehicle-attributes-recognition-barrier-0039">vehicle-attributes-recognition-barrier-0039</a>
for image classification. Using these models, we will detect vehicles
from raw images and recognize attributes of detected vehicles.
<img alt="flowchart" src="https://user-images.githubusercontent.com/47499836/157867076-9e997781-f9ef-45f6-9a51-b515bbf41048.png" /></p>
<p>Finally, we will get the result:</p>
<figure class="align-default" id="id1">
<img alt="result" src="https://user-images.githubusercontent.com/47499836/157867020-99738b30-62ca-44e2-8d9e-caf13fb724ed.png" />
<figcaption>
<p><span class="caption-text">result</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
</section>
<section id="imports">
<h1>Imports<a class="headerlink" href="#imports" title="Permalink to this headline">¶</a></h1>
<p>Import the required modules.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Tuple</span>

<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">openvino.runtime</span> <span class="kn">import</span> <span class="n">Core</span>

<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;../utils&quot;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">notebook_utils</span> <span class="k">as</span> <span class="nn">utils</span>
</pre></div>
</div>
</section>
<section id="download-models">
<h1>Download Models<a class="headerlink" href="#download-models" title="Permalink to this headline">¶</a></h1>
<p>We use <code class="docutils literal notranslate"><span class="pre">omz_downloader</span></code>, which is a command-line tool from the
<code class="docutils literal notranslate"><span class="pre">openvino-dev</span></code> package. <code class="docutils literal notranslate"><span class="pre">omz_downloader</span></code> automatically creates a
directory structure and downloads the selected model. This step is
skipped if the model is already downloaded. The selected model comes
from the public directory, which means it must be converted into
Intermediate Representation (IR).</p>
<blockquote>
<div><p>Note: If you want to change the model, you need to modify the model
name, such as<code class="docutils literal notranslate"><span class="pre">&quot;vehicle-detection-0201&quot;</span></code>,
<code class="docutils literal notranslate"><span class="pre">&quot;vehicle-detection-0202&quot;</span></code>. They support different image input
sizes in detection. Besides, you can change recognition model to
<code class="docutils literal notranslate"><span class="pre">&quot;vehicle-attributes-recognition-barrier-0042&quot;</span></code>, They are trained
from different deep learning frames. If you want to change the
precision, you need to modify the precision value in <code class="docutils literal notranslate"><span class="pre">&quot;FP32&quot;</span></code>,
<code class="docutils literal notranslate"><span class="pre">&quot;FP16&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;FP16-INT8&quot;</span></code>, different type has different model size
and precision value.</p>
</div></blockquote>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Directory where model will be downloaded</span>
<span class="n">base_model_dir</span> <span class="o">=</span> <span class="s2">&quot;model&quot;</span>
<span class="c1"># Model name as named in Open Model Zoo</span>
<span class="n">detection_model_name</span> <span class="o">=</span> <span class="s2">&quot;vehicle-detection-0200&quot;</span>
<span class="n">recognition_model_name</span> <span class="o">=</span> <span class="s2">&quot;vehicle-attributes-recognition-barrier-0039&quot;</span>
<span class="c1"># Selected precision (FP32, FP16, FP16-INT8)</span>
<span class="n">precision</span> <span class="o">=</span> <span class="s2">&quot;FP32&quot;</span>

<span class="c1"># Check if the model exists</span>
<span class="n">detection_model_path</span> <span class="o">=</span> <span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;model/intel/</span><span class="si">{</span><span class="n">detection_model_name</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">precision</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">detection_model_name</span><span class="si">}</span><span class="s2">.xml&quot;</span>
<span class="p">)</span>
<span class="n">recognition_model_path</span> <span class="o">=</span> <span class="p">(</span>
    <span class="sa">f</span><span class="s2">&quot;model/intel/</span><span class="si">{</span><span class="n">recognition_model_name</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">precision</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">recognition_model_name</span><span class="si">}</span><span class="s2">.xml&quot;</span>
<span class="p">)</span>

<span class="c1"># Download the detection model</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">detection_model_path</span><span class="p">):</span>
    <span class="n">download_command</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;omz_downloader &quot;</span> \
                       <span class="sa">f</span><span class="s2">&quot;--name </span><span class="si">{</span><span class="n">detection_model_name</span><span class="si">}</span><span class="s2"> &quot;</span> \
                       <span class="sa">f</span><span class="s2">&quot;--precision </span><span class="si">{</span><span class="n">precision</span><span class="si">}</span><span class="s2"> &quot;</span> \
                       <span class="sa">f</span><span class="s2">&quot;--output_dir </span><span class="si">{</span><span class="n">base_model_dir</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="o">!</span> <span class="nv">$download_command</span>
<span class="c1"># Download the recognition model</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">recognition_model_path</span><span class="p">):</span>
    <span class="n">download_command</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;omz_downloader &quot;</span> \
                       <span class="sa">f</span><span class="s2">&quot;--name </span><span class="si">{</span><span class="n">recognition_model_name</span><span class="si">}</span><span class="s2"> &quot;</span> \
                       <span class="sa">f</span><span class="s2">&quot;--precision </span><span class="si">{</span><span class="n">precision</span><span class="si">}</span><span class="s2"> &quot;</span> \
                       <span class="sa">f</span><span class="s2">&quot;--output_dir </span><span class="si">{</span><span class="n">base_model_dir</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="o">!</span> <span class="nv">$download_command</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1">################|| Downloading vehicle-detection-0200 ||################</span>

<span class="o">==========</span> <span class="n">Downloading</span> <span class="n">model</span><span class="o">/</span><span class="n">intel</span><span class="o">/</span><span class="n">vehicle</span><span class="o">-</span><span class="n">detection</span><span class="o">-</span><span class="mi">0200</span><span class="o">/</span><span class="n">FP32</span><span class="o">/</span><span class="n">vehicle</span><span class="o">-</span><span class="n">detection</span><span class="o">-</span><span class="mf">0200.</span><span class="n">xml</span>


<span class="o">==========</span> <span class="n">Downloading</span> <span class="n">model</span><span class="o">/</span><span class="n">intel</span><span class="o">/</span><span class="n">vehicle</span><span class="o">-</span><span class="n">detection</span><span class="o">-</span><span class="mi">0200</span><span class="o">/</span><span class="n">FP32</span><span class="o">/</span><span class="n">vehicle</span><span class="o">-</span><span class="n">detection</span><span class="o">-</span><span class="mf">0200.</span><span class="n">bin</span>


<span class="c1">################|| Downloading vehicle-attributes-recognition-barrier-0039 ||################</span>

<span class="o">==========</span> <span class="n">Downloading</span> <span class="n">model</span><span class="o">/</span><span class="n">intel</span><span class="o">/</span><span class="n">vehicle</span><span class="o">-</span><span class="n">attributes</span><span class="o">-</span><span class="n">recognition</span><span class="o">-</span><span class="n">barrier</span><span class="o">-</span><span class="mi">0039</span><span class="o">/</span><span class="n">FP32</span><span class="o">/</span><span class="n">vehicle</span><span class="o">-</span><span class="n">attributes</span><span class="o">-</span><span class="n">recognition</span><span class="o">-</span><span class="n">barrier</span><span class="o">-</span><span class="mf">0039.</span><span class="n">xml</span>


<span class="o">==========</span> <span class="n">Downloading</span> <span class="n">model</span><span class="o">/</span><span class="n">intel</span><span class="o">/</span><span class="n">vehicle</span><span class="o">-</span><span class="n">attributes</span><span class="o">-</span><span class="n">recognition</span><span class="o">-</span><span class="n">barrier</span><span class="o">-</span><span class="mi">0039</span><span class="o">/</span><span class="n">FP32</span><span class="o">/</span><span class="n">vehicle</span><span class="o">-</span><span class="n">attributes</span><span class="o">-</span><span class="n">recognition</span><span class="o">-</span><span class="n">barrier</span><span class="o">-</span><span class="mf">0039.</span><span class="n">bin</span>
</pre></div>
</div>
</section>
<section id="load-models">
<h1>Load Models<a class="headerlink" href="#load-models" title="Permalink to this headline">¶</a></h1>
<p>In this notebook, we will need a detection model and a recognition
model. After downloading the models, we initialize inference engine
runtime (IECore), and use <code class="docutils literal notranslate"><span class="pre">read_network</span></code> to read network architecture
and weights from <em>.xml and</em>.bin files. Then, we compile it to the
specified device with <code class="docutils literal notranslate"><span class="pre">compile_model()</span></code>.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialize inference engine runtime</span>
<span class="n">ie_core</span> <span class="o">=</span> <span class="n">Core</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">model_init</span><span class="p">(</span><span class="n">model_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Read the network and weights from file, load the</span>
<span class="sd">    model on the CPU and get input and output names of nodes</span>

<span class="sd">    :param: model: model architecture path *.xml</span>
<span class="sd">    :retuns:</span>
<span class="sd">            input_key: Input node network</span>
<span class="sd">            output_key: Output node network</span>
<span class="sd">            exec_net: Encoder model network</span>
<span class="sd">            net: Model network</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Read the network and corresponding weights from file</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">ie_core</span><span class="o">.</span><span class="n">read_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model_path</span><span class="p">)</span>
    <span class="c1"># compile the model for the CPU (you can use GPU or MYRIAD as well)</span>
    <span class="n">compiled_model</span> <span class="o">=</span> <span class="n">ie_core</span><span class="o">.</span><span class="n">compile_model</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">device_name</span><span class="o">=</span><span class="s2">&quot;CPU&quot;</span><span class="p">)</span>
    <span class="c1"># Get input and output names of nodes</span>
    <span class="n">input_keys</span> <span class="o">=</span> <span class="n">compiled_model</span><span class="o">.</span><span class="n">input</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">output_keys</span> <span class="o">=</span> <span class="n">compiled_model</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">input_keys</span><span class="p">,</span> <span class="n">output_keys</span><span class="p">,</span> <span class="n">compiled_model</span>
</pre></div>
</div>
<section id="get-attributes-from-model">
<h2>Get attributes from model<a class="headerlink" href="#get-attributes-from-model" title="Permalink to this headline">¶</a></h2>
<p>We use <code class="docutils literal notranslate"><span class="pre">input_keys.shape</span></code> to get data shapes</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># de -&gt; detection</span>
<span class="c1"># re -&gt; recognition</span>
<span class="c1"># Detection model initialization</span>
<span class="n">input_key_de</span><span class="p">,</span> <span class="n">output_keys_de</span><span class="p">,</span> <span class="n">compiled_model_de</span> <span class="o">=</span> <span class="n">model_init</span><span class="p">(</span><span class="n">detection_model_path</span><span class="p">)</span>
<span class="c1"># Recognition model initialization</span>
<span class="n">input_key_re</span><span class="p">,</span> <span class="n">output_keys_re</span><span class="p">,</span> <span class="n">compiled_model_re</span> <span class="o">=</span> <span class="n">model_init</span><span class="p">(</span><span class="n">recognition_model_path</span><span class="p">)</span>

<span class="c1"># Get input size - Detection</span>
<span class="n">height_de</span><span class="p">,</span> <span class="n">width_de</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">input_key_de</span><span class="o">.</span><span class="n">shape</span><span class="p">)[</span><span class="mi">2</span><span class="p">:]</span>
<span class="c1"># Get input size - Recognition</span>
<span class="n">height_re</span><span class="p">,</span> <span class="n">width_re</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">input_key_re</span><span class="o">.</span><span class="n">shape</span><span class="p">)[</span><span class="mi">2</span><span class="p">:]</span>
</pre></div>
</div>
</section>
<section id="helper-function">
<h2>Helper function<a class="headerlink" href="#helper-function" title="Permalink to this headline">¶</a></h2>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">plt_show</span></code> function is used to show image</p></li>
</ol>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plt_show</span><span class="p">(</span><span class="n">raw_image</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Use matplot to show image inline</span>
<span class="sd">    raw_image: input image</span>

<span class="sd">    :param: raw_image:image array</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">raw_image</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="read-and-display-a-test-image">
<h2>Read and display a test image<a class="headerlink" href="#read-and-display-a-test-image" title="Permalink to this headline">¶</a></h2>
<p>For the detection model’s input shape is <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">3,</span> <span class="pre">256,</span> <span class="pre">256]</span></code>, so we
need to resize the image size to <code class="docutils literal notranslate"><span class="pre">256</span> <span class="pre">x</span> <span class="pre">256</span></code>, and expand batch channel
with <code class="docutils literal notranslate"><span class="pre">expand_dims</span></code> function.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load an image</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://storage.openvinotoolkit.org/data/test_data/images/person-bicycle-car-detection.bmp&quot;</span>
<span class="n">filename</span> <span class="o">=</span> <span class="s2">&quot;cars.jpg&quot;</span>
<span class="n">directory</span> <span class="o">=</span> <span class="s2">&quot;data&quot;</span>
<span class="n">image_file</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">download_file</span><span class="p">(</span>
    <span class="n">url</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="n">filename</span><span class="p">,</span> <span class="n">directory</span><span class="o">=</span><span class="n">directory</span><span class="p">,</span> <span class="n">show_progress</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">silent</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">timeout</span><span class="o">=</span><span class="mi">30</span>
<span class="p">)</span>
<span class="k">assert</span> <span class="n">Path</span><span class="p">(</span><span class="n">image_file</span><span class="p">)</span><span class="o">.</span><span class="n">exists</span><span class="p">()</span>

<span class="c1"># Read an image</span>
<span class="n">image_de</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="s2">&quot;data/cars.jpg&quot;</span><span class="p">)</span>
<span class="c1"># Resize to [3, 256, 256]</span>
<span class="n">resized_image_de</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">image_de</span><span class="p">,</span> <span class="p">(</span><span class="n">width_de</span><span class="p">,</span> <span class="n">height_de</span><span class="p">))</span>
<span class="c1"># Expand to [1, 3, 256, 256]</span>
<span class="n">input_image_de</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">resized_image_de</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
<span class="c1"># Show image</span>
<span class="n">plt_show</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">image_de</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">))</span>
</pre></div>
</div>
<img alt="../_images/218-vehicle-detection-and-recognition-with-output_12_0.png" src="../_images/218-vehicle-detection-and-recognition-with-output_12_0.png" />
</section>
</section>
<section id="use-detection-model-to-detect-vehicles">
<h1>Use detection model to detect vehicles<a class="headerlink" href="#use-detection-model-to-detect-vehicles" title="Permalink to this headline">¶</a></h1>
<figure class="align-default" id="id2">
<img alt="pipline" src="https://user-images.githubusercontent.com/47499836/157867076-9e997781-f9ef-45f6-9a51-b515bbf41048.png" />
<figcaption>
<p><span class="caption-text">pipline</span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>As shown in the flowchart, images of individual vehicles are sent to the
recognition model. First, we use <code class="docutils literal notranslate"><span class="pre">infer</span></code> function to get the result.</p>
<p>The detection model output has the format [image_id, label, conf, x_min,
y_min, x_max, y_max], where:</p>
<ul class="simple">
<li><p>image_id - ID of the image in the batch</p></li>
<li><p>label - predicted class ID (0 - vehicle)</p></li>
<li><p>conf - confidence for the predicted class</p></li>
<li><p>(x_min, y_min) - coordinates of the top left bounding box corner</p></li>
<li><p>(x_max, y_max) - coordinates of the bottom right bounding box corner</p></li>
</ul>
<p>Delete unused dims and filter out results that are not used.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run Inference</span>
<span class="n">boxes</span> <span class="o">=</span> <span class="n">compiled_model_de</span><span class="p">([</span><span class="n">input_image_de</span><span class="p">])[</span><span class="n">output_keys_de</span><span class="p">]</span>
<span class="c1"># delete the dim of 0, 1</span>
<span class="n">boxes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">boxes</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="c1"># Remove zero only boxes</span>
<span class="n">boxes</span> <span class="o">=</span> <span class="n">boxes</span><span class="p">[</span><span class="o">~</span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">boxes</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)]</span>
</pre></div>
</div>
<section id="detection-processing">
<h2>Detection Processing<a class="headerlink" href="#detection-processing" title="Permalink to this headline">¶</a></h2>
<p>In this function, we change the ratio to the real position in the image,
then we filter out low-confidence results</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">crop_images</span><span class="p">(</span><span class="n">bgr_image</span><span class="p">,</span> <span class="n">resized_image</span><span class="p">,</span> <span class="n">boxes</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Use bounding boxes from detection model to find the absolute car position</span>

<span class="sd">    :param: bgr_image: raw image</span>
<span class="sd">    :param: resized_image: resized image</span>
<span class="sd">    :param: boxes: detection model returns rectangle position</span>
<span class="sd">    :param: threshold: confidence threshold</span>
<span class="sd">    :returns: car_position: car&#39;s absolute position</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Fetch image shapes to calculate ratio</span>
    <span class="p">(</span><span class="n">real_y</span><span class="p">,</span> <span class="n">real_x</span><span class="p">),</span> <span class="p">(</span><span class="n">resized_y</span><span class="p">,</span> <span class="n">resized_x</span><span class="p">)</span> <span class="o">=</span> <span class="n">bgr_image</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">],</span> <span class="n">resized_image</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">ratio_x</span><span class="p">,</span> <span class="n">ratio_y</span> <span class="o">=</span> <span class="n">real_x</span> <span class="o">/</span> <span class="n">resized_x</span><span class="p">,</span> <span class="n">real_y</span> <span class="o">/</span> <span class="n">resized_y</span>

    <span class="c1"># Find the boxes ratio</span>
    <span class="n">boxes</span> <span class="o">=</span> <span class="n">boxes</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">:]</span>
    <span class="c1"># Store the vehicle&#39;s position</span>
    <span class="n">car_position</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># Iterate through non-zero boxes</span>
    <span class="k">for</span> <span class="n">box</span> <span class="ow">in</span> <span class="n">boxes</span><span class="p">:</span>
        <span class="c1"># Pick confidence factor from last place in array</span>
        <span class="n">conf</span> <span class="o">=</span> <span class="n">box</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">conf</span> <span class="o">&gt;</span> <span class="n">threshold</span><span class="p">:</span>
            <span class="c1"># Convert float to int and multiply corner position of each box by x and y ratio</span>
            <span class="c1"># In case that bounding box is found at the top of the image,</span>
            <span class="c1"># we position upper box bar little bit lower to make it visible on image</span>
            <span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">y_max</span><span class="p">)</span> <span class="o">=</span> <span class="p">[</span>
                <span class="nb">int</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">corner_position</span> <span class="o">*</span> <span class="n">ratio_y</span> <span class="o">*</span> <span class="n">resized_y</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span> <span class="k">if</span> <span class="n">idx</span> <span class="o">%</span> <span class="mi">2</span>
                <span class="k">else</span> <span class="nb">int</span><span class="p">(</span><span class="n">corner_position</span> <span class="o">*</span> <span class="n">ratio_x</span> <span class="o">*</span> <span class="n">resized_x</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">corner_position</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">box</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
            <span class="p">]</span>

            <span class="n">car_position</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">x_min</span><span class="p">,</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">y_max</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">car_position</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Find car position</span>
<span class="n">car_position</span> <span class="o">=</span> <span class="n">crop_images</span><span class="p">(</span><span class="n">image_de</span><span class="p">,</span> <span class="n">resized_image_de</span><span class="p">,</span> <span class="n">boxes</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="recognize-vehicle-attributes">
<h2>Recognize vehicle attributes<a class="headerlink" href="#recognize-vehicle-attributes" title="Permalink to this headline">¶</a></h2>
<p>Select one of the detected boxes, then crop to area containing the
vehicle to test with recognition model. Again, we need to resize the
input image and run infererence.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Select a vehicle to recognize</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">car_position</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="c1"># Crop the image with [y_min:y_max, x_min:x_max]</span>
<span class="n">test_car</span> <span class="o">=</span> <span class="n">image_de</span><span class="p">[</span><span class="n">pos</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span><span class="n">pos</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">pos</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">pos</span><span class="p">[</span><span class="mi">2</span><span class="p">]]</span>
<span class="c1"># resize image to input_size</span>
<span class="n">resized_image_re</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">test_car</span><span class="p">,</span> <span class="p">(</span><span class="n">width_re</span><span class="p">,</span> <span class="n">height_re</span><span class="p">))</span>
<span class="n">input_image_re</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">resized_image_re</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">plt_show</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">resized_image_re</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">))</span>
</pre></div>
</div>
<img alt="../_images/218-vehicle-detection-and-recognition-with-output_19_0.png" src="../_images/218-vehicle-detection-and-recognition-with-output_19_0.png" />
<section id="recognition-processing">
<h3>Recognition processing<a class="headerlink" href="#recognition-processing" title="Permalink to this headline">¶</a></h3>
<p>The result contains vehicle colors (white, gray, yellow, red, green,
blue, black) and vehicle types (car, bus, truck, van). Next, we need to
calculate the probability of each attribute. Finally, we determine the
maximum probability as the result.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">vehicle_recognition</span><span class="p">(</span><span class="n">compiled_model_re</span><span class="p">,</span> <span class="n">input_size</span><span class="p">,</span> <span class="n">raw_image</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Vehicle attributes recognition, input a single vehicle, return attributes</span>
<span class="sd">    :param: compiled_model_re: recognition net</span>
<span class="sd">    :param: input_size: recognition input size</span>
<span class="sd">    :param: raw_image: single vehicle image</span>
<span class="sd">    :returns: attr_color: predicted color</span>
<span class="sd">                       attr_type: predicted type</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># vehicle&#39;s attribute</span>
    <span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;White&#39;</span><span class="p">,</span> <span class="s1">&#39;Gray&#39;</span><span class="p">,</span> <span class="s1">&#39;Yellow&#39;</span><span class="p">,</span> <span class="s1">&#39;Red&#39;</span><span class="p">,</span> <span class="s1">&#39;Green&#39;</span><span class="p">,</span> <span class="s1">&#39;Blue&#39;</span><span class="p">,</span> <span class="s1">&#39;Black&#39;</span><span class="p">]</span>
    <span class="n">types</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Car&#39;</span><span class="p">,</span> <span class="s1">&#39;Bus&#39;</span><span class="p">,</span> <span class="s1">&#39;Truck&#39;</span><span class="p">,</span> <span class="s1">&#39;Van&#39;</span><span class="p">]</span>

    <span class="c1"># resize image to input size</span>
    <span class="n">resized_image_re</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">raw_image</span><span class="p">,</span> <span class="n">input_size</span><span class="p">)</span>
    <span class="n">input_image_re</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">resized_image_re</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Run Inference</span>
    <span class="c1"># Predict Result</span>
    <span class="n">predict_colors</span> <span class="o">=</span> <span class="n">compiled_model_re</span><span class="p">([</span><span class="n">input_image_re</span><span class="p">])[</span><span class="n">compiled_model_re</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="mi">1</span><span class="p">)]</span>
    <span class="c1"># delete the dim of 2, 3</span>
    <span class="n">predict_colors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">predict_colors</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
    <span class="n">predict_types</span> <span class="o">=</span> <span class="n">compiled_model_re</span><span class="p">([</span><span class="n">input_image_re</span><span class="p">])[</span><span class="n">compiled_model_re</span><span class="o">.</span><span class="n">output</span><span class="p">(</span><span class="mi">0</span><span class="p">)]</span>
    <span class="n">predict_types</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">predict_types</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

    <span class="n">attr_color</span><span class="p">,</span> <span class="n">attr_type</span> <span class="o">=</span> <span class="p">(</span><span class="n">colors</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predict_colors</span><span class="p">)],</span>
                             <span class="n">types</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predict_types</span><span class="p">)])</span>
    <span class="k">return</span> <span class="n">attr_color</span><span class="p">,</span> <span class="n">attr_type</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Attributes:</span><span class="si">{</span><span class="n">vehicle_recognition</span><span class="p">(</span><span class="n">compiled_model_re</span><span class="p">,</span> <span class="p">(</span><span class="mi">72</span><span class="p">,</span> <span class="mi">72</span><span class="p">),</span> <span class="n">test_car</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Attributes</span><span class="p">:(</span><span class="s1">&#39;Gray&#39;</span><span class="p">,</span> <span class="s1">&#39;Car&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="conbine-two-models">
<h2>Conbine two models<a class="headerlink" href="#conbine-two-models" title="Permalink to this headline">¶</a></h2>
<p>Congratulations! We succeassfully used a detection model to crop an
image with a vehicle and recognize the vehicle attributes.</p>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">convert_result_to_image</span><span class="p">(</span><span class="n">compiled_model_re</span><span class="p">,</span> <span class="n">bgr_image</span><span class="p">,</span> <span class="n">resized_image</span><span class="p">,</span> <span class="n">boxes</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.6</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Use Detection model boxes to draw rectangles and plot the result</span>

<span class="sd">    :param: compiled_model_re: recognition net</span>
<span class="sd">    :param: input_key_re: recognition input key</span>
<span class="sd">    :param: bgr_image: raw image</span>
<span class="sd">    :param: resized_image: resized image</span>
<span class="sd">    :param: boxes: detection model returns rectangle position</span>
<span class="sd">    :param: threshold: confidence threshold</span>
<span class="sd">    :returns: rgb_image: processed image</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Define colors for boxes and descriptions</span>
    <span class="n">colors</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;red&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="s2">&quot;green&quot;</span><span class="p">:</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">)}</span>

    <span class="c1"># Convert base image from bgr to rgb format</span>
    <span class="n">rgb_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">bgr_image</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span>

    <span class="c1"># Find cars&#39; positions</span>
    <span class="n">car_position</span> <span class="o">=</span> <span class="n">crop_images</span><span class="p">(</span><span class="n">image_de</span><span class="p">,</span> <span class="n">resized_image</span><span class="p">,</span> <span class="n">boxes</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">x_min</span><span class="p">,</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">y_max</span> <span class="ow">in</span> <span class="n">car_position</span><span class="p">:</span>
        <span class="c1"># Run vehicle recognition inference</span>
        <span class="n">attr_color</span><span class="p">,</span> <span class="n">attr_type</span> <span class="o">=</span> <span class="n">vehicle_recognition</span><span class="p">(</span><span class="n">compiled_model_re</span><span class="p">,</span> <span class="p">(</span><span class="mi">72</span><span class="p">,</span> <span class="mi">72</span><span class="p">),</span>
                                                    <span class="n">image_de</span><span class="p">[</span><span class="n">y_min</span><span class="p">:</span><span class="n">y_max</span><span class="p">,</span> <span class="n">x_min</span><span class="p">:</span><span class="n">x_max</span><span class="p">])</span>

        <span class="c1"># close the vehicle window</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="c1"># Draw bounding box based on position</span>
        <span class="c1"># Parameters in rectangle function are: image, start_point, end_point, color, thickness</span>
        <span class="n">rgb_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span><span class="n">rgb_image</span><span class="p">,</span> <span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">y_min</span><span class="p">),</span> <span class="p">(</span><span class="n">x_max</span><span class="p">,</span> <span class="n">y_max</span><span class="p">),</span> <span class="n">colors</span><span class="p">[</span><span class="s2">&quot;red&quot;</span><span class="p">],</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Print vehicle attributes</span>
        <span class="c1"># parameters in putText function are: img, text, org, fontFace, fontScale, color, thickness, lineType</span>
        <span class="n">rgb_image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span>
            <span class="n">rgb_image</span><span class="p">,</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">attr_color</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">attr_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">y_min</span> <span class="o">-</span> <span class="mi">10</span><span class="p">),</span>
            <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span>
            <span class="mi">2</span><span class="p">,</span>
            <span class="n">colors</span><span class="p">[</span><span class="s2">&quot;green&quot;</span><span class="p">],</span>
            <span class="mi">10</span><span class="p">,</span>
            <span class="n">cv2</span><span class="o">.</span><span class="n">LINE_AA</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">rgb_image</span>
</pre></div>
</div>
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt_show</span><span class="p">(</span><span class="n">convert_result_to_image</span><span class="p">(</span><span class="n">compiled_model_re</span><span class="p">,</span> <span class="n">image_de</span><span class="p">,</span> <span class="n">resized_image_de</span><span class="p">,</span> <span class="n">boxes</span><span class="p">))</span>
</pre></div>
</div>
<img alt="../_images/218-vehicle-detection-and-recognition-with-output_25_0.png" src="../_images/218-vehicle-detection-and-recognition-with-output_25_0.png" />
</section>
</section>


                </div>
            
            
                <div class='prev-next-bottom'>
                  
    <a class='button bttn-sec button-size-l' id="prev-link" href="217-vision-deblur-with-output.html" title="previous page">Prev</a>
    <a class='button bttn-sec button-size-l' id="next-link" href="301-tensorflow-training-openvino-with-output.html" title="next page">Next</a>

                </div>
            
          </main>
          

      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, Intel®.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.2.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>