
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>MonoDepth Python Demo &#8212; OpenVINO™  documentation</title>
    
    
  <link href="../../../_static/css/theme.css" rel="stylesheet">
  <link href="../../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/doxyrest-pygments.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <link href="../../../_static/css/media/favicon.ico" rel="shortcut icon">
    <link rel="stylesheet" href="../../../_static/css/openvino_sphinx_theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/button.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/input.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/textfield.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/tabs.css" type="text/css" />
    <script src="../../../_static/js/openvino_sphinx_theme.js"></script>
    <link rel="stylesheet" href="../../../_static/css/viewer.min.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/custom.css" type="text/css" />

    <script src="https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-datalabels"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/chartjs-plugin-annotation/0.5.7/chartjs-plugin-annotation.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-barchart-background@1.3.0/build/Plugin.Barchart.Background.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-deferred@1"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/PapaParse/5.3.1/papaparse.min.js"></script>
    <script src="../../../_static/js/viewer.min.js"></script>
    <script src="/assets/versions_raw.js"></script>

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/tabs.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/js/custom.js"></script>
    <script src="../../../_static/js/graphs.js"></script>
    <script src="../../../_static/js/graphs_ov_tf.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/target-highlight.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <link rel="canonical" href="https://docs.openvino.ai/latest/demos/monodepth_demo/python/README.html" />
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="MRI Reconstruction C++ Demo" href="../../mri_reconstruction_demo/cpp/README.html" />
    <link rel="prev" title="TensorFlow* Object Detection Mask R-CNNs Segmentation C++ Demo" href="../../mask_rcnn_demo/cpp/README.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
      <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../../index.html">
  <img src="../../../_static/logo.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../pages/get_started.html">
  Get Started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../pages/documentation.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../tutorials.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../api/api_reference.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../../../model_zoo.html">
  Model Zoo
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../pages/resources.html">
  Resources
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/openvinotoolkit/openvino" rel="noopener" target="_blank" title="GitHub">
            <span><i class="sst-github"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
</ul>
      </div>
      
      <div class="navbar-end-item">
        
<div class="dropdown sst-dropdown sst-dropdown-navbar">
  <button class="btn sst-btn dropdown-toggle" type="button" id="version-selector" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"></button>
  <div class="dropdown-menu" aria-labelledby="version-selector">
  </div>
</div>
      </div>
      
      <div class="navbar-end-item">
        

<div class="dropdown sst-dropdown sst-dropdown-navbar">
  <button class="btn sst-btn dropdown-toggle" type="button" id="language-selector" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">English</button>
  <div class="dropdown-menu" aria-labelledby="language-selector">
    
      
        <a class="dropdown-item font-weight-bold" href="/latest/demos/monodepth_demo/python/README.html">English</a>
      
    
      
        <a  class="dropdown-item" href="/cn/latest/demos/monodepth_demo/python/README.html">Chinese</a>
      
    
  </div>
</div>

      </div>
      
    </div>
  </div>
</div>
        <div id="collapse-nav-wrapper" class="container-xl">
          <button id="collapse-nav" class="button bttn-prm button-size-m" type="button" data-toggle="collapse" data-target="#nav-tree" aria-expanded="false" aria-controls="nav-tree">
            Documentation navigation <i class="fas fa-chevron-down"></i>
          </button>
        </div>
      </nav>
      <div class="transition-banner container-fluid alert alert-info alert-dismissible fade show" role="alert">
        <p>OpenVINO 2022.1 introduces a new version of OpenVINO API (API 2.0). For more information on the changes and transition steps, see the <a href="https://docs.openvino.ai/latest/openvino_2_0_transition_guide.html">transition guide</a></p>
        <button type="button" class="close" data-dismiss="alert" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
    </div>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar" id="nav-tree"><form class="searchForm bd-search d-flex align-items-center" action="../../../search.html" method="get">
    <i class="icon fas fa-search"></i>
    <input type="search" class="form-control" name="query" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Pre-Trained Models
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../models/intel/index.html">
   Overview of OpenVINO™ Toolkit Intel’s Pre-Trained Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/action-recognition-0001/README.html">
     action-recognition-0001 (composite)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/age-gender-recognition-retail-0013/README.html">
     age-gender-recognition-retail-0013
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/asl-recognition-0004/README.html">
     asl-recognition-0004
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/bert-large-uncased-whole-word-masking-squad-0001/README.html">
     bert-large-uncased-whole-word-masking-squad-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/bert-large-uncased-whole-word-masking-squad-emb-0001/README.html">
     bert-large-uncased-whole-word-masking-squad-emb-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/bert-large-uncased-whole-word-masking-squad-int8-0001/README.html">
     bert-large-uncased-whole-word-masking-squad-int8-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/bert-small-uncased-whole-word-masking-squad-0001/README.html">
     bert-small-uncased-whole-word-masking-squad-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/bert-small-uncased-whole-word-masking-squad-0002/README.html">
     bert-small-uncased-whole-word-masking-squad-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/bert-small-uncased-whole-word-masking-squad-emb-int8-0001/README.html">
     bert-small-uncased-whole-word-masking-squad-emb-int8-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/bert-small-uncased-whole-word-masking-squad-int8-0002/README.html">
     bert-small-uncased-whole-word-masking-squad-int8-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/common-sign-language-0002/README.html">
     common-sign-language-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/device_support.html">
     Intel’s Pre-Trained Models Device Support
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/driver-action-recognition-adas-0002/README.html">
     driver-action-recognition-adas-0002 (composite)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/emotions-recognition-retail-0003/README.html">
     emotions-recognition-retail-0003
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/face-detection-0200/README.html">
     face-detection-0200
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/face-detection-0202/README.html">
     face-detection-0202
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/face-detection-0204/README.html">
     face-detection-0204
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/face-detection-0205/README.html">
     face-detection-0205
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/face-detection-0206/README.html">
     face-detection-0206
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/face-detection-adas-0001/README.html">
     face-detection-adas-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/face-detection-retail-0004/README.html">
     face-detection-retail-0004
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/face-detection-retail-0005/README.html">
     face-detection-retail-0005
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/face-reidentification-retail-0095/README.html">
     face-reidentification-retail-0095
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/facial-landmarks-35-adas-0002/README.html">
     facial-landmarks-35-adas-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/facial-landmarks-98-detection-0001/README.html">
     facial-landmarks-98-detection-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/faster-rcnn-resnet101-coco-sparse-60-0001/README.html">
     faster-rcnn-resnet101-coco-sparse-60-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/formula-recognition-medium-scan-0001/README.html">
     formula-recognition-medium-scan-0001 (composite)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/formula-recognition-polynomials-handwritten-0001/README.html">
     formula-recognition-polynomials-handwritten-0001 (composite)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/gaze-estimation-adas-0002/README.html">
     gaze-estimation-adas-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/handwritten-english-recognition-0001/README.html">
     handwritten-english-recognition-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/handwritten-japanese-recognition-0001/README.html">
     handwritten-japanese-recognition-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/handwritten-score-recognition-0003/README.html">
     handwritten-score-recognition-0003
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/handwritten-simplified-chinese-recognition-0001/README.html">
     handwritten-simplified-chinese-recognition-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/head-pose-estimation-adas-0001/README.html">
     head-pose-estimation-adas-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/horizontal-text-detection-0001/README.html">
     horizontal-text-detection-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/human-pose-estimation-0001/README.html">
     human-pose-estimation-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/human-pose-estimation-0005/README.html">
     human-pose-estimation-0005
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/human-pose-estimation-0006/README.html">
     human-pose-estimation-0006
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/human-pose-estimation-0007/README.html">
     human-pose-estimation-0007
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/icnet-camvid-ava-0001/README.html">
     icnet-camvid-ava-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/icnet-camvid-ava-sparse-30-0001/README.html">
     icnet-camvid-ava-sparse-30-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/icnet-camvid-ava-sparse-60-0001/README.html">
     icnet-camvid-ava-sparse-60-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/image-retrieval-0001/README.html">
     image-retrieval-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/instance-segmentation-person-0007/README.html">
     instance-segmentation-person-0007
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/instance-segmentation-security-0002/README.html">
     instance-segmentation-security-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/instance-segmentation-security-0091/README.html">
     instance-segmentation-security-0091
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/instance-segmentation-security-0228/README.html">
     instance-segmentation-security-0228
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/instance-segmentation-security-1039/README.html">
     instance-segmentation-security-1039
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/instance-segmentation-security-1040/README.html">
     instance-segmentation-security-1040
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/landmarks-regression-retail-0009/README.html">
     landmarks-regression-retail-0009
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/license-plate-recognition-barrier-0001/README.html">
     license-plate-recognition-barrier-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/machine-translation-nar-de-en-0002/README.html">
     machine-translation-nar-de-en-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/machine-translation-nar-en-de-0002/README.html">
     machine-translation-nar-en-de-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/machine-translation-nar-en-ru-0002/README.html">
     machine-translation-nar-en-ru-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/machine-translation-nar-ru-en-0002/README.html">
     machine-translation-nar-ru-en-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/noise-suppression-denseunet-ll-0001/README.html">
     noise-suppression-denseunet-ll-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/noise-suppression-poconetlike-0001/README.html">
     noise-suppression-poconetlike-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/pedestrian-and-vehicle-detector-adas-0001/README.html">
     pedestrian-and-vehicle-detector-adas-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/pedestrian-detection-adas-0002/README.html">
     pedestrian-detection-adas-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-attributes-recognition-crossroad-0230/README.html">
     person-attributes-recognition-crossroad-0230
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-attributes-recognition-crossroad-0234/README.html">
     person-attributes-recognition-crossroad-0234
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-attributes-recognition-crossroad-0238/README.html">
     person-attributes-recognition-crossroad-0238
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-0106/README.html">
     person-detection-0106
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-0200/README.html">
     person-detection-0200
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-0201/README.html">
     person-detection-0201
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-0202/README.html">
     person-detection-0202
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-0203/README.html">
     person-detection-0203
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-0301/README.html">
     person-detection-0301
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-0302/README.html">
     person-detection-0302
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-0303/README.html">
     person-detection-0303
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-action-recognition-0005/README.html">
     person-detection-action-recognition-0005
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-action-recognition-0006/README.html">
     person-detection-action-recognition-0006
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-action-recognition-teacher-0002/README.html">
     person-detection-action-recognition-teacher-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-asl-0001/README.html">
     person-detection-asl-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-raisinghand-recognition-0001/README.html">
     person-detection-raisinghand-recognition-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-retail-0002/README.html">
     person-detection-retail-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-retail-0013/README.html">
     person-detection-retail-0013
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-reidentification-retail-0277/README.html">
     person-reidentification-retail-0277
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-reidentification-retail-0286/README.html">
     person-reidentification-retail-0286
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-reidentification-retail-0287/README.html">
     person-reidentification-retail-0287
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-reidentification-retail-0288/README.html">
     person-reidentification-retail-0288
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-vehicle-bike-detection-2000/README.html">
     person-vehicle-bike-detection-2000
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-vehicle-bike-detection-2001/README.html">
     person-vehicle-bike-detection-2001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-vehicle-bike-detection-2002/README.html">
     person-vehicle-bike-detection-2002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-vehicle-bike-detection-2003/README.html">
     person-vehicle-bike-detection-2003
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-vehicle-bike-detection-2004/README.html">
     person-vehicle-bike-detection-2004
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-vehicle-bike-detection-crossroad-0078/README.html">
     person-vehicle-bike-detection-crossroad-0078
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-vehicle-bike-detection-crossroad-1016/README.html">
     person-vehicle-bike-detection-crossroad-1016
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-vehicle-bike-detection-crossroad-yolov3-1020/README.html">
     person-vehicle-bike-detection-crossroad-yolov3-1020
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/product-detection-0001/README.html">
     product-detection-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/resnet18-xnor-binary-onnx-0001/README.html">
     resnet18-xnor-binary-onnx-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/resnet50-binary-0001/README.html">
     resnet50-binary-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/road-segmentation-adas-0001/README.html">
     road-segmentation-adas-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/semantic-segmentation-adas-0001/README.html">
     semantic-segmentation-adas-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/single-image-super-resolution-1032/README.html">
     single-image-super-resolution-1032
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/single-image-super-resolution-1033/README.html">
     single-image-super-resolution-1033
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/smartlab-object-detection-0001/README.html">
     smartlab-object-detection-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/smartlab-object-detection-0002/README.html">
     smartlab-object-detection-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/smartlab-object-detection-0003/README.html">
     smartlab-object-detection-0003
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/smartlab-object-detection-0004/README.html">
     smartlab-object-detection-0004
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/smartlab-sequence-modelling-0001/README.html">
     smartlab-sequence-modelling-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/text-detection-0003/README.html">
     text-detection-0003
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/text-detection-0004/README.html">
     text-detection-0004
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/text-image-super-resolution-0001/README.html">
     text-image-super-resolution-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/text-recognition-0012/README.html">
     text-recognition-0012
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/text-recognition-0014/README.html">
     text-recognition-0014
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/text-recognition-0015/README.html">
     text-recognition-0015 (composite)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/text-recognition-0016/README.html">
     text-recognition-0016 (composite)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/text-spotting-0005/README.html">
     text-spotting-0005 (composite)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/text-to-speech-en-0001/README.html">
     text-to-speech-en-0001 (composite)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/text-to-speech-en-multi-0001/README.html">
     text-to-speech-en-multi-0001 (composite)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/time-series-forecasting-electricity-0001/README.html">
     time-series-forecasting-electricity-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/unet-camvid-onnx-0001/README.html">
     unet-camvid-onnx-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/vehicle-attributes-recognition-barrier-0039/README.html">
     vehicle-attributes-recognition-barrier-0039
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/vehicle-attributes-recognition-barrier-0042/README.html">
     vehicle-attributes-recognition-barrier-0042
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/vehicle-detection-0200/README.html">
     vehicle-detection-0200
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/vehicle-detection-0201/README.html">
     vehicle-detection-0201
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/vehicle-detection-0202/README.html">
     vehicle-detection-0202
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/vehicle-detection-adas-0002/README.html">
     vehicle-detection-adas-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/vehicle-license-plate-detection-barrier-0106/README.html">
     vehicle-license-plate-detection-barrier-0106
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/weld-porosity-detection-0001/README.html">
     weld-porosity-detection-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/yolo-v2-ava-0001/README.html">
     yolo-v2-ava-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/yolo-v2-ava-sparse-35-0001/README.html">
     yolo-v2-ava-sparse-35-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/yolo-v2-ava-sparse-70-0001/README.html">
     yolo-v2-ava-sparse-70-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/yolo-v2-tiny-ava-0001/README.html">
     yolo-v2-tiny-ava-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/yolo-v2-tiny-ava-sparse-30-0001/README.html">
     yolo-v2-tiny-ava-sparse-30-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/yolo-v2-tiny-ava-sparse-60-0001/README.html">
     yolo-v2-tiny-ava-sparse-60-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/yolo-v2-tiny-vehicle-detection-0001/README.html">
     yolo-v2-tiny-vehicle-detection-0001
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../models/public/index.html">
   Overview of OpenVINO™ Toolkit Public Pre-Trained Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/Sphereface/README.html">
     Sphereface
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/aclnet/README.html">
     aclnet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/aclnet-int8/README.html">
     aclnet-int8
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/alexnet/README.html">
     alexnet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/anti-spoof-mn3/README.html">
     anti-spoof-mn3
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/background-matting-mobilenetv2/README.html">
     background-matting-mobilenetv2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/bert-base-ner/README.html">
     bert-base-ner
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/brain-tumor-segmentation-0001/README.html">
     brain-tumor-segmentation-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/brain-tumor-segmentation-0002/README.html">
     brain-tumor-segmentation-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/caffenet/README.html">
     caffenet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/cocosnet/README.html">
     cocosnet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/colorization-siggraph/README.html">
     colorization-siggraph
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/colorization-v2/README.html">
     colorization-v2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/common-sign-language-0001/README.html">
     common-sign-language-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/convnext-tiny/README.html">
     convnext-tiny
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/ctdet_coco_dlav0_512/README.html">
     ctdet_coco_dlav0_512
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/ctpn/README.html">
     ctpn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/deblurgan-v2/README.html">
     deblurgan-v2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/deeplabv3/README.html">
     deeplabv3
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/densenet-121/README.html">
     densenet-121
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/densenet-121-tf/README.html">
     densenet-121-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/detr-resnet50/README.html">
     detr-resnet50
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/device_support.html">
     Public Pre-Trained Models Device Support
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/dla-34/README.html">
     dla-34
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/drn-d-38/README.html">
     drn-d-38
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/efficientdet-d0-tf/README.html">
     efficientdet-d0-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/efficientdet-d1-tf/README.html">
     efficientdet-d1-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/efficientnet-b0/README.html">
     efficientnet-b0
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/efficientnet-b0-pytorch/README.html">
     efficientnet-b0-pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/efficientnet-v2-b0/README.html">
     efficientnet-v2-b0
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/efficientnet-v2-s/README.html">
     efficientnet-v2-s
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/f3net/README.html">
     f3net
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/face-detection-retail-0044/README.html">
     face-detection-retail-0044
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/face-recognition-resnet100-arcface-onnx/README.html">
     face-recognition-resnet100-arcface-onnx
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/faceboxes-pytorch/README.html">
     faceboxes-pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/facenet-20180408-102900/README.html">
     facenet-20180408-102900
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/fast-neural-style-mosaic-onnx/README.html">
     fast-neural-style-mosaic-onnx
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/faster_rcnn_inception_resnet_v2_atrous_coco/README.html">
     faster_rcnn_inception_resnet_v2_atrous_coco
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/faster_rcnn_resnet50_coco/README.html">
     faster_rcnn_resnet50_coco
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/fastseg-large/README.html">
     fastseg-large
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/fastseg-small/README.html">
     fastseg-small
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/fbcnn/README.html">
     fbcnn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/fcrn-dp-nyu-depth-v2-tf/README.html">
     fcrn-dp-nyu-depth-v2-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/forward-tacotron/README.html">
     forward-tacotron (composite)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/gmcnn-places2-tf/README.html">
     gmcnn-places2-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/googlenet-v1/README.html">
     googlenet-v1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/googlenet-v1-tf/README.html">
     googlenet-v1-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/googlenet-v2/README.html">
     googlenet-v2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/googlenet-v2-tf/README.html">
     googlenet-v2-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/googlenet-v3/README.html">
     googlenet-v3
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/googlenet-v3-pytorch/README.html">
     googlenet-v3-pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/googlenet-v4-tf/README.html">
     googlenet-v4-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/gpt-2/README.html">
     gpt-2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/hbonet-0.25/README.html">
     hbonet-0.25
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/hbonet-1.0/README.html">
     hbonet-1.0
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/higher-hrnet-w32-human-pose-estimation/README.html">
     higher-hrnet-w32-human-pose-estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/hrnet-v2-c1-segmentation/README.html">
     hrnet-v2-c1-segmentation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/human-pose-estimation-3d-0001/README.html">
     human-pose-estimation-3d-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/hybrid-cs-model-mri/README.html">
     hybrid-cs-model-mri
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/i3d-rgb-tf/README.html">
     i3d-rgb-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/inception-resnet-v2-tf/README.html">
     inception-resnet-v2-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/levit-128s/README.html">
     levit-128s
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/license-plate-recognition-barrier-0007/README.html">
     license-plate-recognition-barrier-0007
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mask_rcnn_inception_resnet_v2_atrous_coco/README.html">
     mask_rcnn_inception_resnet_v2_atrous_coco
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mask_rcnn_resnet50_atrous_coco/README.html">
     mask_rcnn_resnet50_atrous_coco
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/midasnet/README.html">
     midasnet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mixnet-l/README.html">
     mixnet-l
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilefacedet-v1-mxnet/README.html">
     mobilefacedet-v1-mxnet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilenet-ssd/README.html">
     mobilenet-ssd
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilenet-v1-0.25-128/README.html">
     mobilenet-v1-0.25-128
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilenet-v1-1.0-224/README.html">
     mobilenet-v1-1.0-224
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilenet-v1-1.0-224-tf/README.html">
     mobilenet-v1-1.0-224-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilenet-v2/README.html">
     mobilenet-v2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilenet-v2-1.0-224/README.html">
     mobilenet-v2-1.0-224
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilenet-v2-1.4-224/README.html">
     mobilenet-v2-1.4-224
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilenet-v2-pytorch/README.html">
     mobilenet-v2-pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilenet-v3-large-1.0-224-paddle/README.html">
     mobilenet-v3-large-1.0-224-paddle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilenet-v3-large-1.0-224-tf/README.html">
     mobilenet-v3-large-1.0-224-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilenet-v3-small-1.0-224-paddle/README.html">
     mobilenet-v3-small-1.0-224-paddle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilenet-v3-small-1.0-224-tf/README.html">
     mobilenet-v3-small-1.0-224-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilenet-yolo-v4-syg/README.html">
     mobilenet-yolo-v4-syg
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/modnet-photographic-portrait-matting/README.html">
     modnet-photographic-portrait-matting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/modnet-webcam-portrait-matting/README.html">
     modnet-webcam-portrait-matting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mozilla-deepspeech-0.6.1/README.html">
     mozilla-deepspeech-0.6.1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mozilla-deepspeech-0.8.2/README.html">
     mozilla-deepspeech-0.8.2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mtcnn/README.html">
     mtcnn (composite)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/nanodet-m-1.5x-416/README.html">
     nanodet-m-1.5x-416
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/nanodet-plus-m-1.5x-416/README.html">
     nanodet-plus-m-1.5x-416
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/netvlad-tf/README.html">
     netvlad-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/nfnet-f0/README.html">
     nfnet-f0
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/ocrnet-hrnet-w48-paddle/README.html">
     ocrnet-hrnet-w48-paddle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/octave-resnet-26-0.25/README.html">
     octave-resnet-26-0.25
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/open-closed-eye-0001/README.html">
     open-closed-eye-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/pelee-coco/README.html">
     pelee-coco
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/pspnet-pytorch/README.html">
     pspnet-pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/quartznet-15x5-en/README.html">
     quartznet-15x5-en
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/regnetx-3.2gf/README.html">
     regnetx-3.2gf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/repvgg-a0/README.html">
     repvgg-a0
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/repvgg-b1/README.html">
     repvgg-b1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/repvgg-b3/README.html">
     repvgg-b3
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/resnest-50-pytorch/README.html">
     resnest-50-pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/resnet-18-pytorch/README.html">
     resnet-18-pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/resnet-34-pytorch/README.html">
     resnet-34-pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/resnet-50-pytorch/README.html">
     resnet-50-pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/resnet-50-tf/README.html">
     resnet-50-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/retinaface-resnet50-pytorch/README.html">
     retinaface-resnet50-pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/retinanet-tf/README.html">
     retinanet-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/rexnet-v1-x1.0/README.html">
     rexnet-v1-x1.0
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/rfcn-resnet101-coco-tf/README.html">
     rfcn-resnet101-coco-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/robust-video-matting-mobilenetv3/README.html">
     robust-video-matting-mobilenetv3
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/se-inception/README.html">
     se-inception
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/se-resnet-50/README.html">
     se-resnet-50
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/se-resnext-50/README.html">
     se-resnext-50
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/shufflenet-v2-x0.5/README.html">
     shufflenet-v2-x0.5
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/shufflenet-v2-x1.0/README.html">
     shufflenet-v2-x1.0
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/single-human-pose-estimation-0001/README.html">
     single-human-pose-estimation-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/squeezenet1.0/README.html">
     squeezenet1.0
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/squeezenet1.1/README.html">
     squeezenet1.1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/ssd-resnet34-1200-onnx/README.html">
     ssd-resnet34-1200-onnx
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/ssd300/README.html">
     ssd300
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/ssd512/README.html">
     ssd512
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/ssd_mobilenet_v1_coco/README.html">
     ssd_mobilenet_v1_coco
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/ssd_mobilenet_v1_fpn_coco/README.html">
     ssd_mobilenet_v1_fpn_coco
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/ssdlite_mobilenet_v2/README.html">
     ssdlite_mobilenet_v2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/swin-tiny-patch4-window7-224/README.html">
     swin-tiny-patch4-window7-224
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/t2t-vit-14/README.html">
     t2t-vit-14
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/text-recognition-resnet-fc/README.html">
     text-recognition-resnet-fc
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/ultra-lightweight-face-detection-rfb-320/README.html">
     ultra-lightweight-face-detection-rfb-320
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/ultra-lightweight-face-detection-slim-320/README.html">
     ultra-lightweight-face-detection-slim-320
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/vehicle-license-plate-detection-barrier-0123/README.html">
     vehicle-license-plate-detection-barrier-0123
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/vehicle-reid-0001/README.html">
     vehicle-reid-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/vgg16/README.html">
     vgg16
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/vgg19/README.html">
     vgg19
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/vitstr-small-patch16-224/README.html">
     vitstr-small-patch16-224
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/wav2vec2-base/README.html">
     wav2vec2-base
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/wavernn/README.html">
     wavernn (composite)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/yolact-resnet50-fpn-pytorch/README.html">
     yolact-resnet50-fpn-pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/yolo-v1-tiny-tf/README.html">
     yolo-v1-tiny-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/yolo-v2-tf/README.html">
     yolo-v2-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/yolo-v2-tiny-tf/README.html">
     yolo-v2-tiny-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/yolo-v3-onnx/README.html">
     yolo-v3-onnx
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/yolo-v3-tf/README.html">
     yolo-v3-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/yolo-v3-tiny-onnx/README.html">
     yolo-v3-tiny-onnx
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/yolo-v3-tiny-tf/README.html">
     yolo-v3-tiny-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/yolo-v4-tf/README.html">
     yolo-v4-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/yolo-v4-tiny-tf/README.html">
     yolo-v4-tiny-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/yolof/README.html">
     yolof
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/yolox-tiny/README.html">
     yolox-tiny
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Demo Applications
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../../README.html">
   Open Model Zoo Demos
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../../3d_segmentation_demo/python/README.html">
     3D Segmentation Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../action_recognition_demo/python/README.html">
     Action Recognition Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../background_subtraction_demo/cpp_gapi/README.html">
     G-API Background Subtraction Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../background_subtraction_demo/python/README.html">
     Background subtraction Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../bert_named_entity_recognition_demo/python/README.html">
     BERT Named Entity Recognition Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../bert_question_answering_demo/python/README.html">
     BERT Question Answering Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../bert_question_answering_embedding_demo/python/README.html">
     BERT Question Answering Embedding Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../classification_benchmark_demo/cpp/README.html">
     Classification Benchmark C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../classification_demo/python/README.html">
     Classification Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../colorization_demo/python/README.html">
     Colorization Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../crossroad_camera_demo/cpp/README.html">
     Crossroad Camera C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deblurring_demo/python/README.html">
     Image Deblurring Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../face_detection_mtcnn_demo/cpp_gapi/README.html">
     G-API Face Detection MTCNN Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../face_detection_mtcnn_demo/python/README.html">
     Face Detection MTCNN Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../face_recognition_demo/python/README.html">
     Face Recognition Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../formula_recognition_demo/python/README.html">
     Formula Recognition Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../gaze_estimation_demo/cpp/README.html">
     Gaze Estimation Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../gaze_estimation_demo/cpp_gapi/README.html">
     G-API Gaze Estimation Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../gesture_recognition_demo/cpp_gapi/README.html">
     G-API Gesture Recognition Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../gesture_recognition_demo/python/README.html">
     Gesture Recognition Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../gpt2_text_prediction_demo/python/README.html">
     GPT-2 Text Prediction Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../handwritten_text_recognition_demo/python/README.html">
     Handwritten Text Recognition Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../human_pose_estimation_3d_demo/python/README.html">
     3D Human Pose Estimation Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../human_pose_estimation_demo/cpp/README.html">
     Human Pose Estimation C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../human_pose_estimation_demo/python/README.html">
     Human Pose Estimation Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../image_inpainting_demo/python/README.html">
     Image Inpainting Python Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../image_processing_demo/cpp/README.html">
     Image Processing C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../image_retrieval_demo/python/README.html">
     Image Retrieval Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../image_translation_demo/python/README.html">
     Image Translation Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../instance_segmentation_demo/python/README.html">
     Instance Segmentation Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../interactive_face_detection_demo/cpp/README.html">
     Interactive Face Detection C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../interactive_face_detection_demo/cpp_gapi/README.html">
     G-API Interactive Face Detection Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../machine_translation_demo/python/README.html">
     Machine Translation Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../mask_rcnn_demo/cpp/README.html">
     TensorFlow* Object Detection Mask R-CNNs Segmentation C++ Demo
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     MonoDepth Python Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../mri_reconstruction_demo/cpp/README.html">
     MRI Reconstruction C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../mri_reconstruction_demo/python/README.html">
     MRI Reconstruction Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../multi_camera_multi_target_tracking_demo/python/README.html">
     Multi Camera Multi Target Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../multi_channel_face_detection_demo/cpp/README.html">
     Multi-Channel Face Detection C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../multi_channel_human_pose_estimation_demo/cpp/README.html">
     Multi-Channel Human Pose Estimation C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../multi_channel_object_detection_demo_yolov3/cpp/README.html">
     Multi-Channel Object Detection Yolov3 C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../noise_suppression_demo/cpp/README.html">
     Noise Suppression C++* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../noise_suppression_demo/python/README.html">
     Noise Suppression Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../object_detection_demo/cpp/README.html">
     Object Detection C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../object_detection_demo/python/README.html">
     Object Detection Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../pedestrian_tracker_demo/cpp/README.html">
     Pedestrian Tracker C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../place_recognition_demo/python/README.html">
     Place Recognition Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../security_barrier_camera_demo/cpp/README.html">
     Security Barrier Camera C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../segmentation_demo/cpp/README.html">
     Image Segmentation C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../segmentation_demo/python/README.html">
     Image Segmentation Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../single_human_pose_estimation_demo/python/README.html">
     Single Human Pose Estimation Demo (top-down pipeline)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../smart_classroom_demo/cpp/README.html">
     Smart Classroom C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../smart_classroom_demo/cpp_gapi/README.html">
     Smart Classroom C++ G-API Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../smartlab_demo/python/README.html">
     Smartlab Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../social_distance_demo/cpp/README.html">
     Social Distance C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../sound_classification_demo/python/README.html">
     Sound Classification Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../speech_recognition_deepspeech_demo/python/README.html">
     Speech Recognition DeepSpeech Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../speech_recognition_quartznet_demo/python/README.html">
     Speech Recognition QuartzNet Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../speech_recognition_wav2vec_demo/python/README.html">
     Speech Recognition Wav2Vec Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../text_detection_demo/cpp/README.html">
     Text Detection C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../text_spotting_demo/python/README.html">
     Text Spotting Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../text_to_speech_demo/python/README.html">
     Text-to-speech Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../time_series_forecasting_demo/python/README.html">
     Time Series Forecasting Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../whiteboard_inpainting_demo/python/README.html">
     Whiteboard Inpainting Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../common/python/openvino/model_zoo/model_api/adapters/ovms_adapter.html">
     OpenVINO Model Server Adapter
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Model API
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../common/python/openvino/model_zoo/model_api/adapters/ovms_adapter.html">
   OpenVINO Model Server Adapter
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-it-works">
   How It Works
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-api">
   Model API
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#preparing-to-run">
   Preparing to Run
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#supported-models">
     Supported Models
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#running">
   Running
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#running-with-openvino-model-server">
   Running with OpenVINO Model Server
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#demo-output">
   Demo Output
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#see-also">
   See Also
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                <div class="tocsection download-docs">
  <div class="dropdown sst-dropdown">
    <button class="button bttn-prm button-size-m" data-display="static" type="button" id="download-options"
      data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
      Download Docs
    </button>
    <div class="dropdown-menu" aria-labelledby="download-options">
      <a class="dropdown-item" href="#" onclick="window.print()">.pdf</a>
      <a id="download-zip-btn" class="dropdown-item" href="#">.zip</a>
    </div>
  </div>
</div>
              </div>
              
            
          </div>
          

          
          
              
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">

<div class="tocsection editthispage">
    <a href="None">
        <i class="fas fa-pencil-alt"></i> Edit this page
    </a>
</div>

            
                <div>
                  
  <section id="monodepth-python-demo">
<h1>MonoDepth Python Demo<a class="headerlink" href="#monodepth-python-demo" title="Permalink to this headline">¶</a></h1>
<p>This topic demonstrates how to run the MonoDepth demo application, which produces a disparity map for a given input image.
To this end, the code uses the network described in <a class="reference external" href="https://arxiv.org/abs/1907.01341">Towards Robust Monocular Depth Estimation: Mixing Datasets for Zero-shot Cross-dataset Transfer</a>.</p>
<p>Below is the <code class="docutils literal notranslate"><span class="pre">midasnet</span></code> model inference result:</p>
<p><img alt="example" src="../../../_images/disp.png" /></p>
<section id="how-it-works">
<h2>How It Works<a class="headerlink" href="#how-it-works" title="Permalink to this headline">¶</a></h2>
<p>On startup, the application reads command-line parameters and loads a model to OpenVINO™ Runtime plugin. Upon getting a frame from the OpenCV VideoCapture, it performs inference and displays the results.</p>
<p>Async API operates with a notion of the “Infer Request” that encapsulates the inputs/outputs and separates
<em>scheduling and waiting for result</em>.</p>
<blockquote>
<div><p><strong>NOTE</strong>: By default, Open Model Zoo demos expect input with BGR channels order. If you trained your model to work with RGB order, you need to manually rearrange the default channels order in the demo application or reconvert your model using the Model Optimizer tool with the <code class="docutils literal notranslate"><span class="pre">--reverse_input_channels</span></code> argument specified. For more information about the argument, refer to <strong>When to Reverse Input Channels</strong> section of [Embedding Preprocessing Computation](&#64;ref openvino_docs_MO_DG_Additional_Optimization_Use_Cases).</p>
</div></blockquote>
</section>
<section id="model-api">
<h2>Model API<a class="headerlink" href="#model-api" title="Permalink to this headline">¶</a></h2>
<p>The demo utilizes model wrappers, adapters and pipelines from <a class="reference internal" href="../../common/python/openvino/model_zoo/model_api/README.html"><span class="doc std std-doc">Python* Model API</span></a>.</p>
<p>The generalized interface of wrappers with its unified results representation provides the support of multiple different monocular depth estimation model topologies in one demo.</p>
</section>
<section id="preparing-to-run">
<h2>Preparing to Run<a class="headerlink" href="#preparing-to-run" title="Permalink to this headline">¶</a></h2>
<p>For demo input image or video files, refer to the section <strong>Media Files Available for Demos</strong> in the <a class="reference internal" href="../../README.html"><span class="doc std std-doc">Open Model Zoo Demos Overview</span></a>.
The list of models supported by the demo is in <code class="docutils literal notranslate"><span class="pre">&lt;omz_dir&gt;/demos/monodepth_demo/python/models.lst</span></code> file.
This file can be used as a parameter for <span class="xref myst">Model Downloader</span> and Converter to download and, if necessary, convert models to OpenVINO IR format (*.xml + *.bin).</p>
<p>An example of using the Model Downloader:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>omz_downloader --list models.lst
</pre></div>
</div>
<p>An example of using the Model Converter:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>omz_converter --list models.lst
</pre></div>
</div>
<section id="supported-models">
<h3>Supported Models<a class="headerlink" href="#supported-models" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>fcrn-dp-nyu-depth-v2-tf</p></li>
<li><p>midasnet</p></li>
</ul>
<blockquote>
<div><p><strong>NOTE</strong>: Refer to the tables <a class="reference internal" href="../../../models/intel/device_support.html"><span class="doc std std-doc">Intel’s Pre-Trained Models Device Support</span></a> and <a class="reference internal" href="../../../models/public/device_support.html"><span class="doc std std-doc">Public Pre-Trained Models Device Support</span></a> for the details on models inference support at different devices.</p>
</div></blockquote>
</section>
</section>
<section id="running">
<h2>Running<a class="headerlink" href="#running" title="Permalink to this headline">¶</a></h2>
<p>Running the application with the <code class="docutils literal notranslate"><span class="pre">-h</span></code> option yields the following usage message:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">usage</span><span class="p">:</span> <span class="n">monodepth_demo</span><span class="o">.</span><span class="n">py</span> <span class="p">[</span><span class="o">-</span><span class="n">h</span><span class="p">]</span> <span class="o">-</span><span class="n">m</span> <span class="n">MODEL</span> <span class="o">-</span><span class="n">i</span> <span class="n">INPUT</span> <span class="p">[</span><span class="o">-</span><span class="n">d</span> <span class="n">DEVICE</span><span class="p">]</span>
                         <span class="p">[</span><span class="o">--</span><span class="n">adapter</span> <span class="p">{</span><span class="n">openvino</span><span class="p">,</span><span class="n">ovms</span><span class="p">}]</span> <span class="p">[</span><span class="o">-</span><span class="n">nireq</span> <span class="n">NUM_INFER_REQUESTS</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">nstreams</span> <span class="n">NUM_STREAMS</span><span class="p">]</span>
                         <span class="p">[</span><span class="o">-</span><span class="n">nthreads</span> <span class="n">NUM_THREADS</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">loop</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">o</span> <span class="n">OUTPUT</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">limit</span> <span class="n">OUTPUT_LIMIT</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">no_show</span><span class="p">]</span>
                         <span class="p">[</span><span class="o">--</span><span class="n">output_resolution</span> <span class="n">OUTPUT_RESOLUTION</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">u</span> <span class="n">UTILIZATION_MONITORS</span><span class="p">]</span>

<span class="n">Options</span><span class="p">:</span>
  <span class="o">-</span><span class="n">h</span><span class="p">,</span> <span class="o">--</span><span class="n">help</span>            <span class="n">Show</span> <span class="n">this</span> <span class="n">help</span> <span class="n">message</span> <span class="ow">and</span> <span class="n">exit</span><span class="o">.</span>
  <span class="o">-</span><span class="n">m</span> <span class="n">MODEL</span><span class="p">,</span> <span class="o">--</span><span class="n">model</span> <span class="n">MODEL</span>
                        <span class="n">Required</span><span class="o">.</span> <span class="n">Path</span> <span class="n">to</span> <span class="n">an</span> <span class="o">.</span><span class="n">xml</span> <span class="n">file</span> <span class="k">with</span> <span class="n">a</span> <span class="n">trained</span> <span class="n">model</span> <span class="ow">or</span>
                        <span class="n">address</span> <span class="n">of</span> <span class="n">model</span> <span class="n">inference</span> <span class="n">service</span> <span class="k">if</span> <span class="n">using</span> <span class="n">OVMS</span> <span class="n">adapter</span><span class="o">.</span>
  <span class="o">-</span><span class="n">i</span> <span class="n">INPUT</span><span class="p">,</span> <span class="o">--</span><span class="nb">input</span> <span class="n">INPUT</span>
                        <span class="n">Required</span><span class="o">.</span> <span class="n">An</span> <span class="nb">input</span> <span class="n">to</span> <span class="n">process</span><span class="o">.</span> <span class="n">The</span> <span class="nb">input</span> <span class="n">must</span> <span class="n">be</span> <span class="n">a</span> <span class="n">single</span> <span class="n">image</span><span class="p">,</span> <span class="n">a</span> <span class="n">folder</span> <span class="n">of</span> <span class="n">images</span><span class="p">,</span> <span class="n">video</span>
                        <span class="n">file</span> <span class="ow">or</span> <span class="n">camera</span> <span class="nb">id</span><span class="o">.</span>
  <span class="o">--</span><span class="n">adapter</span> <span class="p">{</span><span class="n">openvino</span><span class="p">,</span><span class="n">ovms</span><span class="p">}</span>
                        <span class="n">Optional</span><span class="o">.</span> <span class="n">Specify</span> <span class="n">the</span> <span class="n">model</span> <span class="n">adapter</span><span class="o">.</span> <span class="n">Default</span> <span class="ow">is</span>
                        <span class="n">openvino</span><span class="o">.</span>
  <span class="o">-</span><span class="n">d</span> <span class="n">DEVICE</span><span class="p">,</span> <span class="o">--</span><span class="n">device</span> <span class="n">DEVICE</span>
                        <span class="n">Optional</span><span class="o">.</span> <span class="n">Specify</span> <span class="n">the</span> <span class="n">target</span> <span class="n">device</span> <span class="n">to</span> <span class="n">infer</span> <span class="n">on</span><span class="p">;</span> <span class="n">CPU</span><span class="p">,</span> <span class="n">GPU</span><span class="p">,</span> <span class="n">HDDL</span> <span class="ow">or</span> <span class="n">MYRIAD</span> <span class="ow">is</span> <span class="n">acceptable</span><span class="o">.</span> <span class="n">The</span>
                        <span class="n">demo</span> <span class="n">will</span> <span class="n">look</span> <span class="k">for</span> <span class="n">a</span> <span class="n">suitable</span> <span class="n">plugin</span> <span class="k">for</span> <span class="n">device</span> <span class="n">specified</span><span class="o">.</span> <span class="n">Default</span> <span class="n">value</span> <span class="ow">is</span> <span class="n">CPU</span><span class="o">.</span>

<span class="n">Inference</span> <span class="n">options</span><span class="p">:</span>
  <span class="o">-</span><span class="n">nireq</span> <span class="n">NUM_INFER_REQUESTS</span><span class="p">,</span> <span class="o">--</span><span class="n">num_infer_requests</span> <span class="n">NUM_INFER_REQUESTS</span>
                        <span class="n">Optional</span><span class="o">.</span> <span class="n">Number</span> <span class="n">of</span> <span class="n">infer</span> <span class="n">requests</span><span class="o">.</span>
  <span class="o">-</span><span class="n">nstreams</span> <span class="n">NUM_STREAMS</span><span class="p">,</span> <span class="o">--</span><span class="n">num_streams</span> <span class="n">NUM_STREAMS</span>
                        <span class="n">Optional</span><span class="o">.</span> <span class="n">Number</span> <span class="n">of</span> <span class="n">streams</span> <span class="n">to</span> <span class="n">use</span> <span class="k">for</span> <span class="n">inference</span> <span class="n">on</span> <span class="n">the</span> <span class="n">CPU</span> <span class="ow">or</span><span class="o">/</span><span class="ow">and</span> <span class="n">GPU</span> <span class="ow">in</span> <span class="n">throughput</span> <span class="n">mode</span> <span class="p">(</span><span class="k">for</span>
                        <span class="n">HETERO</span> <span class="ow">and</span> <span class="n">MULTI</span> <span class="n">device</span> <span class="n">cases</span> <span class="n">use</span> <span class="nb">format</span> <span class="o">&lt;</span><span class="n">device1</span><span class="o">&gt;</span><span class="p">:</span><span class="o">&lt;</span><span class="n">nstreams1</span><span class="o">&gt;</span><span class="p">,</span><span class="o">&lt;</span><span class="n">device2</span><span class="o">&gt;</span><span class="p">:</span><span class="o">&lt;</span><span class="n">nstreams2</span><span class="o">&gt;</span> <span class="ow">or</span> <span class="n">just</span>
                        <span class="o">&lt;</span><span class="n">nstreams</span><span class="o">&gt;</span><span class="p">)</span><span class="o">.</span>
  <span class="o">-</span><span class="n">nthreads</span> <span class="n">NUM_THREADS</span><span class="p">,</span> <span class="o">--</span><span class="n">num_threads</span> <span class="n">NUM_THREADS</span>
                        <span class="n">Optional</span><span class="o">.</span> <span class="n">Number</span> <span class="n">of</span> <span class="n">threads</span> <span class="n">to</span> <span class="n">use</span> <span class="k">for</span> <span class="n">inference</span> <span class="n">on</span> <span class="n">CPU</span> <span class="p">(</span><span class="n">including</span> <span class="n">HETERO</span> <span class="n">cases</span><span class="p">)</span><span class="o">.</span>

<span class="n">Input</span><span class="o">/</span><span class="n">output</span> <span class="n">options</span><span class="p">:</span>
  <span class="o">--</span><span class="n">loop</span>                <span class="n">Optional</span><span class="o">.</span> <span class="n">Enable</span> <span class="n">reading</span> <span class="n">the</span> <span class="nb">input</span> <span class="ow">in</span> <span class="n">a</span> <span class="n">loop</span><span class="o">.</span>
  <span class="o">-</span><span class="n">o</span> <span class="n">OUTPUT</span><span class="p">,</span> <span class="o">--</span><span class="n">output</span> <span class="n">OUTPUT</span>
                        <span class="n">Optional</span><span class="o">.</span> <span class="n">Name</span> <span class="n">of</span> <span class="n">the</span> <span class="n">output</span> <span class="n">file</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="n">to</span> <span class="n">save</span><span class="o">.</span>
  <span class="o">-</span><span class="n">limit</span> <span class="n">OUTPUT_LIMIT</span><span class="p">,</span> <span class="o">--</span><span class="n">output_limit</span> <span class="n">OUTPUT_LIMIT</span>
                        <span class="n">Optional</span><span class="o">.</span> <span class="n">Number</span> <span class="n">of</span> <span class="n">frames</span> <span class="n">to</span> <span class="n">store</span> <span class="ow">in</span> <span class="n">output</span><span class="o">.</span> <span class="n">If</span> <span class="mi">0</span> <span class="ow">is</span> <span class="nb">set</span><span class="p">,</span> <span class="nb">all</span> <span class="n">frames</span> <span class="n">are</span> <span class="n">stored</span><span class="o">.</span>
  <span class="o">--</span><span class="n">no_show</span>             <span class="n">Optional</span><span class="o">.</span> <span class="n">Don</span><span class="s1">&#39;t show output.</span>
  <span class="o">--</span><span class="n">output_resolution</span> <span class="n">OUTPUT_RESOLUTION</span>
                        <span class="n">Optional</span><span class="o">.</span> <span class="n">Specify</span> <span class="n">the</span> <span class="n">maximum</span> <span class="n">output</span> <span class="n">window</span> <span class="n">resolution</span> <span class="ow">in</span> <span class="p">(</span><span class="n">width</span> <span class="n">x</span> <span class="n">height</span><span class="p">)</span> <span class="nb">format</span><span class="o">.</span> <span class="n">Example</span><span class="p">:</span>
                        <span class="mi">1280</span><span class="n">x720</span><span class="o">.</span> <span class="n">Input</span> <span class="n">frame</span> <span class="n">size</span> <span class="n">used</span> <span class="n">by</span> <span class="n">default</span><span class="o">.</span>
  <span class="o">-</span><span class="n">u</span> <span class="n">UTILIZATION_MONITORS</span><span class="p">,</span> <span class="o">--</span><span class="n">utilization_monitors</span> <span class="n">UTILIZATION_MONITORS</span>
                        <span class="n">Optional</span><span class="o">.</span> <span class="n">List</span> <span class="n">of</span> <span class="n">monitors</span> <span class="n">to</span> <span class="n">show</span> <span class="n">initially</span><span class="o">.</span>
</pre></div>
</div>
<p>Running the application with the empty list of options yields the usage message given above and an error message.</p>
<p>You can use the following command to do inference on GPU with a pre-trained midasnet model:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>python3 monodepth_demo.py <span class="se">\</span>
  -d GPU <span class="se">\</span>
  -i &lt;path_to_video&gt;/inputVideo.mp4 <span class="se">\</span>
  -m &lt;path_to_model&gt;/midasnet.xml
</pre></div>
</div>
<p>The number of Infer Requests is specified by <code class="docutils literal notranslate"><span class="pre">-nireq</span></code> flag. An increase of this number usually leads to an increase
of performance (throughput), since in this case several Infer Requests can be processed simultaneously if the device
supports parallelization. However, a large number of Infer Requests increases the latency because each frame still
has to wait before being sent for inference.</p>
<p>For higher FPS, it is recommended that you set <code class="docutils literal notranslate"><span class="pre">-nireq</span></code> to slightly exceed the <code class="docutils literal notranslate"><span class="pre">-nstreams</span></code> value,
summed across all devices used.</p>
<blockquote>
<div><p><strong>NOTE</strong>: This demo is based on the callback functionality from the OpenVINO™ Runtime API.
The selected approach makes the execution in multi-device mode optimal by preventing wait delays caused by
the differences in device performance. However, the internal organization of the callback mechanism in Python API
leads to a decrease in FPS.</p>
</div></blockquote>
<blockquote>
<div><p><strong>NOTE</strong>: If you provide a single image as an input, the demo processes and renders it quickly, then exits. To continuously visualize inference results on the screen, apply the <code class="docutils literal notranslate"><span class="pre">loop</span></code> option, which enforces processing a single image in a loop.</p>
</div></blockquote>
<p>You can save processed results to a Motion JPEG AVI file or separate JPEG or PNG files using the <code class="docutils literal notranslate"><span class="pre">-o</span></code> option:</p>
<ul class="simple">
<li><p>To save processed results in an AVI file, specify the name of the output file with <code class="docutils literal notranslate"><span class="pre">avi</span></code> extension, for example: <code class="docutils literal notranslate"><span class="pre">-o</span> <span class="pre">output.avi</span></code>.</p></li>
<li><p>To save processed results as images, specify the template name of the output image file with <code class="docutils literal notranslate"><span class="pre">jpg</span></code> or <code class="docutils literal notranslate"><span class="pre">png</span></code> extension, for example: <code class="docutils literal notranslate"><span class="pre">-o</span> <span class="pre">output_%03d.jpg</span></code>. The actual file names are constructed from the template at runtime by replacing regular expression <code class="docutils literal notranslate"><span class="pre">%03d</span></code> with the frame number, resulting in the following: <code class="docutils literal notranslate"><span class="pre">output_000.jpg</span></code>, <code class="docutils literal notranslate"><span class="pre">output_001.jpg</span></code>, and so on.
To avoid disk space overrun in case of continuous input stream, like camera, you can limit the amount of data stored in the output file(s) with the <code class="docutils literal notranslate"><span class="pre">limit</span></code> option. The default value is 1000. To change it, you can apply the <code class="docutils literal notranslate"><span class="pre">-limit</span> <span class="pre">N</span></code> option, where <code class="docutils literal notranslate"><span class="pre">N</span></code> is the number of frames to store.</p></li>
</ul>
<blockquote>
<div><p><strong>NOTE</strong>: Windows* systems may not have the Motion JPEG codec installed by default. If this is the case, you can download OpenCV FFMPEG back end using the PowerShell script provided with the OpenVINO ™ install package and located at <code class="docutils literal notranslate"><span class="pre">&lt;INSTALL_DIR&gt;/opencv/ffmpeg-download.ps1</span></code>. The script should be run with administrative privileges if OpenVINO ™ is installed in a system protected folder (this is a typical case). Alternatively, you can save results as images.</p>
</div></blockquote>
</section>
<section id="running-with-openvino-model-server">
<h2>Running with OpenVINO Model Server<a class="headerlink" href="#running-with-openvino-model-server" title="Permalink to this headline">¶</a></h2>
<p>You can also run this demo with model served in <a class="reference external" href="https://github.com/openvinotoolkit/model_server">OpenVINO Model Server</a>. Refer to <a class="reference internal" href="../../common/python/openvino/model_zoo/model_api/adapters/ovms_adapter.html"><span class="doc std std-doc"><code class="docutils literal notranslate"><span class="pre">OVMSAdapter</span></code></span></a> to learn about running demos with OVMS.</p>
<p>Exemplary command:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>python3 monodepth_demo.py <span class="se">\</span>
  -i &lt;path_to_video&gt;/inputVideo.mp4 <span class="se">\</span>
  -m localhost:9000/models/monodepth <span class="se">\</span>
  --adapter ovms
</pre></div>
</div>
</section>
<section id="demo-output">
<h2>Demo Output<a class="headerlink" href="#demo-output" title="Permalink to this headline">¶</a></h2>
<p>The demo uses OpenCV to display the resulting frame with colored depth map.
The demo reports:</p>
<ul class="simple">
<li><p><strong>FPS</strong>: average rate of video frame processing (frames per second).</p></li>
<li><p><strong>Latency</strong>: average time required to process one frame (from reading the frame to displaying the results).
You can use both of these metrics to measure application-level performance.</p></li>
</ul>
</section>
<section id="see-also">
<h2>See Also<a class="headerlink" href="#see-also" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="../../README.html"><span class="doc std std-doc">Open Model Zoo Demos</span></a></p></li>
<li><p><a class="reference external" href="https://docs.openvino.ai/latest/openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html">Model Optimizer</a></p></li>
<li><p><span class="xref myst">Model Downloader</span></p></li>
</ul>
</section>
</section>


                </div>
            
            
                <div class='prev-next-bottom'>
                  
    <a class='button bttn-sec button-size-l' id="prev-link" href="../../mask_rcnn_demo/cpp/README.html" title="previous page">Prev</a>
    <a class='button bttn-sec button-size-l' id="next-link" href="../../mri_reconstruction_demo/cpp/README.html" title="next page">Next</a>

                </div>
            
          </main>
          

      </div>
    </div>
  
  <script src="../../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, Intel®.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.2.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>