
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Instance Segmentation Python* Demo &#8212; OpenVINOâ„¢  documentation</title>
    
    
  <link href="../../../_static/css/theme.css" rel="stylesheet">
  <link href="../../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/blank.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/doxyrest-pygments.css" />
    
  <link rel="preload" as="script" href="../../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <link href="../../../_static/css/media/favicon.ico" rel="shortcut icon">
    <link rel="stylesheet" href="../../../_static/css/openvino_sphinx_theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/button.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/input.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/textfield.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/tabs.css" type="text/css" />
    <script src="../../../_static/js/openvino_sphinx_theme.js"></script>
    <link rel="stylesheet" href="../../../_static/css/viewer.min.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/css/custom.css" type="text/css" />

    <script src="https://cdn.jsdelivr.net/npm/chart.js@2.9.3/dist/Chart.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-datalabels"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/chartjs-plugin-annotation/0.5.7/chartjs-plugin-annotation.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-barchart-background@1.3.0/build/Plugin.Barchart.Background.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chartjs-plugin-deferred@1"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/PapaParse/5.3.1/papaparse.min.js"></script>
    <script src="../../../_static/js/viewer.min.js"></script>
    <script src="/assets/versions_raw.js"></script>

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/tabs.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/js/custom.js"></script>
    <script src="../../../_static/js/graphs.js"></script>
    <script src="../../../_static/js/graphs_ov_tf.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/target-highlight.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <link rel="canonical" href="https://docs.openvino.ai/latest/demos/instance_segmentation_demo/python/README.html" />
    <link rel="shortcut icon" href="../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Interactive Face Detection C++ Demo" href="../../interactive_face_detection_demo/cpp/README.html" />
    <link rel="prev" title="Image Translation Demo" href="../../image_translation_demo/python/README.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    
      <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="../../../index.html">
  <img src="../../../_static/logo.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../pages/documentation.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../tutorials.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../api/api_reference.html">
  API Reference
 </a>
</li>

<li class="toctree-l1 current active nav-item">
 <a class="reference internal nav-link" href="../../../model_zoo.html">
  Model Zoo
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../pages/resources.html">
  Resources
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/openvinotoolkit/openvino" rel="noopener" target="_blank" title="GitHub">
            <span><i class="sst-github"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
</ul>
      </div>
      
      <div class="navbar-end-item">
        
<div class="dropdown sst-dropdown sst-dropdown-navbar">
  <button class="btn sst-btn dropdown-toggle" type="button" id="version-selector" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"></button>
  <div class="dropdown-menu" aria-labelledby="version-selector">
  </div>
</div>
      </div>
      
      <div class="navbar-end-item">
        

<div class="dropdown sst-dropdown sst-dropdown-navbar">
  <button class="btn sst-btn dropdown-toggle" type="button" id="language-selector" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">English</button>
  <div class="dropdown-menu" aria-labelledby="language-selector">
    
      
        <a class="dropdown-item font-weight-bold" href="/latest/demos/instance_segmentation_demo/python/README.html">English</a>
      
    
      
        <a  class="dropdown-item" href="/cn/latest/demos/instance_segmentation_demo/python/README.html">Chinese</a>
      
    
  </div>
</div>

      </div>
      
    </div>
  </div>
</div>
        <div id="collapse-nav-wrapper" class="container-xl">
          <button id="collapse-nav" class="button bttn-prm button-size-m" type="button" data-toggle="collapse" data-target="#nav-tree" aria-expanded="false" aria-controls="nav-tree">
            Documentation navigation <i class="fas fa-chevron-down"></i>
          </button>
        </div>
      </nav>
      <div class="transition-banner container-fluid alert alert-info alert-dismissible fade show" role="alert">
        <p>OpenVINO 2022.1 introduces a new version of OpenVINO API (API 2.0). For more information on the changes and transition steps, see the <a href="https://docs.openvino.ai/latest/openvino_2_0_transition_guide.html">transition guide</a></p>
        <button type="button" class="close" data-dismiss="alert" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
    </div>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar" id="nav-tree"><form class="searchForm bd-search d-flex align-items-center" action="../../../search.html" method="get">
    <i class="icon fas fa-search"></i>
    <input type="search" class="form-control" name="query" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Pre-Trained Models
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../models/intel/index.html">
   Overview of OpenVINOâ„¢ Toolkit Intelâ€™s Pre-Trained Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/action-recognition-0001/README.html">
     action-recognition-0001 (composite)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/age-gender-recognition-retail-0013/README.html">
     age-gender-recognition-retail-0013
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/asl-recognition-0004/README.html">
     asl-recognition-0004
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/bert-large-uncased-whole-word-masking-squad-0001/README.html">
     bert-large-uncased-whole-word-masking-squad-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/bert-large-uncased-whole-word-masking-squad-emb-0001/README.html">
     bert-large-uncased-whole-word-masking-squad-emb-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/bert-large-uncased-whole-word-masking-squad-int8-0001/README.html">
     bert-large-uncased-whole-word-masking-squad-int8-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/bert-small-uncased-whole-word-masking-squad-0001/README.html">
     bert-small-uncased-whole-word-masking-squad-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/bert-small-uncased-whole-word-masking-squad-0002/README.html">
     bert-small-uncased-whole-word-masking-squad-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/bert-small-uncased-whole-word-masking-squad-emb-int8-0001/README.html">
     bert-small-uncased-whole-word-masking-squad-emb-int8-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/bert-small-uncased-whole-word-masking-squad-int8-0002/README.html">
     bert-small-uncased-whole-word-masking-squad-int8-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/common-sign-language-0002/README.html">
     common-sign-language-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/device_support.html">
     Intelâ€™s Pre-Trained Models Device Support
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/driver-action-recognition-adas-0002/README.html">
     driver-action-recognition-adas-0002 (composite)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/emotions-recognition-retail-0003/README.html">
     emotions-recognition-retail-0003
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/face-detection-0200/README.html">
     face-detection-0200
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/face-detection-0202/README.html">
     face-detection-0202
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/face-detection-0204/README.html">
     face-detection-0204
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/face-detection-0205/README.html">
     face-detection-0205
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/face-detection-0206/README.html">
     face-detection-0206
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/face-detection-adas-0001/README.html">
     face-detection-adas-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/face-detection-retail-0004/README.html">
     face-detection-retail-0004
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/face-detection-retail-0005/README.html">
     face-detection-retail-0005
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/face-reidentification-retail-0095/README.html">
     face-reidentification-retail-0095
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/facial-landmarks-35-adas-0002/README.html">
     facial-landmarks-35-adas-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/facial-landmarks-98-detection-0001/README.html">
     facial-landmarks-98-detection-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/faster-rcnn-resnet101-coco-sparse-60-0001/README.html">
     faster-rcnn-resnet101-coco-sparse-60-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/formula-recognition-medium-scan-0001/README.html">
     formula-recognition-medium-scan-0001 (composite)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/formula-recognition-polynomials-handwritten-0001/README.html">
     formula-recognition-polynomials-handwritten-0001 (composite)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/gaze-estimation-adas-0002/README.html">
     gaze-estimation-adas-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/handwritten-english-recognition-0001/README.html">
     handwritten-english-recognition-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/handwritten-japanese-recognition-0001/README.html">
     handwritten-japanese-recognition-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/handwritten-score-recognition-0003/README.html">
     handwritten-score-recognition-0003
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/handwritten-simplified-chinese-recognition-0001/README.html">
     handwritten-simplified-chinese-recognition-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/head-pose-estimation-adas-0001/README.html">
     head-pose-estimation-adas-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/horizontal-text-detection-0001/README.html">
     horizontal-text-detection-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/human-pose-estimation-0001/README.html">
     human-pose-estimation-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/human-pose-estimation-0005/README.html">
     human-pose-estimation-0005
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/human-pose-estimation-0006/README.html">
     human-pose-estimation-0006
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/human-pose-estimation-0007/README.html">
     human-pose-estimation-0007
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/icnet-camvid-ava-0001/README.html">
     icnet-camvid-ava-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/icnet-camvid-ava-sparse-30-0001/README.html">
     icnet-camvid-ava-sparse-30-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/icnet-camvid-ava-sparse-60-0001/README.html">
     icnet-camvid-ava-sparse-60-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/image-retrieval-0001/README.html">
     image-retrieval-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/instance-segmentation-person-0007/README.html">
     instance-segmentation-person-0007
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/instance-segmentation-security-0002/README.html">
     instance-segmentation-security-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/instance-segmentation-security-0091/README.html">
     instance-segmentation-security-0091
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/instance-segmentation-security-0228/README.html">
     instance-segmentation-security-0228
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/instance-segmentation-security-1039/README.html">
     instance-segmentation-security-1039
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/instance-segmentation-security-1040/README.html">
     instance-segmentation-security-1040
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/landmarks-regression-retail-0009/README.html">
     landmarks-regression-retail-0009
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/license-plate-recognition-barrier-0001/README.html">
     license-plate-recognition-barrier-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/machine-translation-nar-de-en-0002/README.html">
     machine-translation-nar-de-en-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/machine-translation-nar-en-de-0002/README.html">
     machine-translation-nar-en-de-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/machine-translation-nar-en-ru-0002/README.html">
     machine-translation-nar-en-ru-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/machine-translation-nar-ru-en-0002/README.html">
     machine-translation-nar-ru-en-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/noise-suppression-denseunet-ll-0001/README.html">
     noise-suppression-denseunet-ll-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/noise-suppression-poconetlike-0001/README.html">
     noise-suppression-poconetlike-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/pedestrian-and-vehicle-detector-adas-0001/README.html">
     pedestrian-and-vehicle-detector-adas-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/pedestrian-detection-adas-0002/README.html">
     pedestrian-detection-adas-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-attributes-recognition-crossroad-0230/README.html">
     person-attributes-recognition-crossroad-0230
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-attributes-recognition-crossroad-0234/README.html">
     person-attributes-recognition-crossroad-0234
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-attributes-recognition-crossroad-0238/README.html">
     person-attributes-recognition-crossroad-0238
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-0106/README.html">
     person-detection-0106
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-0200/README.html">
     person-detection-0200
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-0201/README.html">
     person-detection-0201
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-0202/README.html">
     person-detection-0202
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-0203/README.html">
     person-detection-0203
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-0301/README.html">
     person-detection-0301
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-0302/README.html">
     person-detection-0302
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-0303/README.html">
     person-detection-0303
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-action-recognition-0005/README.html">
     person-detection-action-recognition-0005
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-action-recognition-0006/README.html">
     person-detection-action-recognition-0006
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-action-recognition-teacher-0002/README.html">
     person-detection-action-recognition-teacher-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-asl-0001/README.html">
     person-detection-asl-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-raisinghand-recognition-0001/README.html">
     person-detection-raisinghand-recognition-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-retail-0002/README.html">
     person-detection-retail-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-detection-retail-0013/README.html">
     person-detection-retail-0013
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-reidentification-retail-0277/README.html">
     person-reidentification-retail-0277
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-reidentification-retail-0286/README.html">
     person-reidentification-retail-0286
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-reidentification-retail-0287/README.html">
     person-reidentification-retail-0287
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-reidentification-retail-0288/README.html">
     person-reidentification-retail-0288
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-vehicle-bike-detection-2000/README.html">
     person-vehicle-bike-detection-2000
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-vehicle-bike-detection-2001/README.html">
     person-vehicle-bike-detection-2001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-vehicle-bike-detection-2002/README.html">
     person-vehicle-bike-detection-2002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-vehicle-bike-detection-2003/README.html">
     person-vehicle-bike-detection-2003
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-vehicle-bike-detection-2004/README.html">
     person-vehicle-bike-detection-2004
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-vehicle-bike-detection-crossroad-0078/README.html">
     person-vehicle-bike-detection-crossroad-0078
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-vehicle-bike-detection-crossroad-1016/README.html">
     person-vehicle-bike-detection-crossroad-1016
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/person-vehicle-bike-detection-crossroad-yolov3-1020/README.html">
     person-vehicle-bike-detection-crossroad-yolov3-1020
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/product-detection-0001/README.html">
     product-detection-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/resnet18-xnor-binary-onnx-0001/README.html">
     resnet18-xnor-binary-onnx-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/resnet50-binary-0001/README.html">
     resnet50-binary-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/road-segmentation-adas-0001/README.html">
     road-segmentation-adas-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/semantic-segmentation-adas-0001/README.html">
     semantic-segmentation-adas-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/single-image-super-resolution-1032/README.html">
     single-image-super-resolution-1032
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/single-image-super-resolution-1033/README.html">
     single-image-super-resolution-1033
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/smartlab-object-detection-0001/README.html">
     smartlab-object-detection-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/smartlab-object-detection-0002/README.html">
     smartlab-object-detection-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/smartlab-object-detection-0003/README.html">
     smartlab-object-detection-0003
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/smartlab-object-detection-0004/README.html">
     smartlab-object-detection-0004
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/smartlab-sequence-modelling-0001/README.html">
     smartlab-sequence-modelling-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/text-detection-0003/README.html">
     text-detection-0003
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/text-detection-0004/README.html">
     text-detection-0004
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/text-image-super-resolution-0001/README.html">
     text-image-super-resolution-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/text-recognition-0012/README.html">
     text-recognition-0012
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/text-recognition-0014/README.html">
     text-recognition-0014
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/text-recognition-0015/README.html">
     text-recognition-0015 (composite)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/text-recognition-0016/README.html">
     text-recognition-0016 (composite)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/text-spotting-0005/README.html">
     text-spotting-0005 (composite)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/text-to-speech-en-0001/README.html">
     text-to-speech-en-0001 (composite)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/text-to-speech-en-multi-0001/README.html">
     text-to-speech-en-multi-0001 (composite)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/time-series-forecasting-electricity-0001/README.html">
     time-series-forecasting-electricity-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/unet-camvid-onnx-0001/README.html">
     unet-camvid-onnx-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/vehicle-attributes-recognition-barrier-0039/README.html">
     vehicle-attributes-recognition-barrier-0039
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/vehicle-attributes-recognition-barrier-0042/README.html">
     vehicle-attributes-recognition-barrier-0042
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/vehicle-detection-0200/README.html">
     vehicle-detection-0200
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/vehicle-detection-0201/README.html">
     vehicle-detection-0201
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/vehicle-detection-0202/README.html">
     vehicle-detection-0202
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/vehicle-detection-adas-0002/README.html">
     vehicle-detection-adas-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/vehicle-license-plate-detection-barrier-0106/README.html">
     vehicle-license-plate-detection-barrier-0106
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/weld-porosity-detection-0001/README.html">
     weld-porosity-detection-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/yolo-v2-ava-0001/README.html">
     yolo-v2-ava-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/yolo-v2-ava-sparse-35-0001/README.html">
     yolo-v2-ava-sparse-35-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/yolo-v2-ava-sparse-70-0001/README.html">
     yolo-v2-ava-sparse-70-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/yolo-v2-tiny-ava-0001/README.html">
     yolo-v2-tiny-ava-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/yolo-v2-tiny-ava-sparse-30-0001/README.html">
     yolo-v2-tiny-ava-sparse-30-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/yolo-v2-tiny-ava-sparse-60-0001/README.html">
     yolo-v2-tiny-ava-sparse-60-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/intel/yolo-v2-tiny-vehicle-detection-0001/README.html">
     yolo-v2-tiny-vehicle-detection-0001
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../../models/public/index.html">
   Overview of OpenVINOâ„¢ Toolkit Public Pre-Trained Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/Sphereface/README.html">
     Sphereface
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/aclnet/README.html">
     aclnet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/aclnet-int8/README.html">
     aclnet-int8
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/alexnet/README.html">
     alexnet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/anti-spoof-mn3/README.html">
     anti-spoof-mn3
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/background-matting-mobilenetv2/README.html">
     background-matting-mobilenetv2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/bert-base-ner/README.html">
     bert-base-ner
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/brain-tumor-segmentation-0001/README.html">
     brain-tumor-segmentation-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/brain-tumor-segmentation-0002/README.html">
     brain-tumor-segmentation-0002
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/caffenet/README.html">
     caffenet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/cocosnet/README.html">
     cocosnet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/colorization-siggraph/README.html">
     colorization-siggraph
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/colorization-v2/README.html">
     colorization-v2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/common-sign-language-0001/README.html">
     common-sign-language-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/convnext-tiny/README.html">
     convnext-tiny
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/ctdet_coco_dlav0_512/README.html">
     ctdet_coco_dlav0_512
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/ctpn/README.html">
     ctpn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/deblurgan-v2/README.html">
     deblurgan-v2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/deeplabv3/README.html">
     deeplabv3
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/densenet-121/README.html">
     densenet-121
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/densenet-121-tf/README.html">
     densenet-121-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/detr-resnet50/README.html">
     detr-resnet50
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/device_support.html">
     Public Pre-Trained Models Device Support
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/dla-34/README.html">
     dla-34
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/drn-d-38/README.html">
     drn-d-38
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/efficientdet-d0-tf/README.html">
     efficientdet-d0-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/efficientdet-d1-tf/README.html">
     efficientdet-d1-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/efficientnet-b0/README.html">
     efficientnet-b0
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/efficientnet-b0-pytorch/README.html">
     efficientnet-b0-pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/efficientnet-v2-b0/README.html">
     efficientnet-v2-b0
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/efficientnet-v2-s/README.html">
     efficientnet-v2-s
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/f3net/README.html">
     f3net
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/face-detection-retail-0044/README.html">
     face-detection-retail-0044
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/face-recognition-resnet100-arcface-onnx/README.html">
     face-recognition-resnet100-arcface-onnx
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/faceboxes-pytorch/README.html">
     faceboxes-pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/facenet-20180408-102900/README.html">
     facenet-20180408-102900
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/fast-neural-style-mosaic-onnx/README.html">
     fast-neural-style-mosaic-onnx
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/faster_rcnn_inception_resnet_v2_atrous_coco/README.html">
     faster_rcnn_inception_resnet_v2_atrous_coco
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/faster_rcnn_resnet50_coco/README.html">
     faster_rcnn_resnet50_coco
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/fastseg-large/README.html">
     fastseg-large
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/fastseg-small/README.html">
     fastseg-small
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/fbcnn/README.html">
     fbcnn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/fcrn-dp-nyu-depth-v2-tf/README.html">
     fcrn-dp-nyu-depth-v2-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/forward-tacotron/README.html">
     forward-tacotron (composite)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/gmcnn-places2-tf/README.html">
     gmcnn-places2-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/googlenet-v1/README.html">
     googlenet-v1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/googlenet-v1-tf/README.html">
     googlenet-v1-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/googlenet-v2/README.html">
     googlenet-v2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/googlenet-v2-tf/README.html">
     googlenet-v2-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/googlenet-v3/README.html">
     googlenet-v3
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/googlenet-v3-pytorch/README.html">
     googlenet-v3-pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/googlenet-v4-tf/README.html">
     googlenet-v4-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/gpt-2/README.html">
     gpt-2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/hbonet-0.25/README.html">
     hbonet-0.25
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/hbonet-1.0/README.html">
     hbonet-1.0
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/higher-hrnet-w32-human-pose-estimation/README.html">
     higher-hrnet-w32-human-pose-estimation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/hrnet-v2-c1-segmentation/README.html">
     hrnet-v2-c1-segmentation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/human-pose-estimation-3d-0001/README.html">
     human-pose-estimation-3d-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/hybrid-cs-model-mri/README.html">
     hybrid-cs-model-mri
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/i3d-rgb-tf/README.html">
     i3d-rgb-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/inception-resnet-v2-tf/README.html">
     inception-resnet-v2-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/levit-128s/README.html">
     levit-128s
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/license-plate-recognition-barrier-0007/README.html">
     license-plate-recognition-barrier-0007
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mask_rcnn_inception_resnet_v2_atrous_coco/README.html">
     mask_rcnn_inception_resnet_v2_atrous_coco
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mask_rcnn_resnet50_atrous_coco/README.html">
     mask_rcnn_resnet50_atrous_coco
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/midasnet/README.html">
     midasnet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mixnet-l/README.html">
     mixnet-l
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilefacedet-v1-mxnet/README.html">
     mobilefacedet-v1-mxnet
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilenet-ssd/README.html">
     mobilenet-ssd
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilenet-v1-0.25-128/README.html">
     mobilenet-v1-0.25-128
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilenet-v1-1.0-224/README.html">
     mobilenet-v1-1.0-224
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilenet-v1-1.0-224-tf/README.html">
     mobilenet-v1-1.0-224-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilenet-v2/README.html">
     mobilenet-v2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilenet-v2-1.0-224/README.html">
     mobilenet-v2-1.0-224
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilenet-v2-1.4-224/README.html">
     mobilenet-v2-1.4-224
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilenet-v2-pytorch/README.html">
     mobilenet-v2-pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilenet-v3-large-1.0-224-paddle/README.html">
     mobilenet-v3-large-1.0-224-paddle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilenet-v3-large-1.0-224-tf/README.html">
     mobilenet-v3-large-1.0-224-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilenet-v3-small-1.0-224-paddle/README.html">
     mobilenet-v3-small-1.0-224-paddle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilenet-v3-small-1.0-224-tf/README.html">
     mobilenet-v3-small-1.0-224-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mobilenet-yolo-v4-syg/README.html">
     mobilenet-yolo-v4-syg
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/modnet-photographic-portrait-matting/README.html">
     modnet-photographic-portrait-matting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/modnet-webcam-portrait-matting/README.html">
     modnet-webcam-portrait-matting
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mozilla-deepspeech-0.6.1/README.html">
     mozilla-deepspeech-0.6.1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mozilla-deepspeech-0.8.2/README.html">
     mozilla-deepspeech-0.8.2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/mtcnn/README.html">
     mtcnn (composite)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/nanodet-m-1.5x-416/README.html">
     nanodet-m-1.5x-416
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/nanodet-plus-m-1.5x-416/README.html">
     nanodet-plus-m-1.5x-416
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/netvlad-tf/README.html">
     netvlad-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/nfnet-f0/README.html">
     nfnet-f0
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/ocrnet-hrnet-w48-paddle/README.html">
     ocrnet-hrnet-w48-paddle
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/octave-resnet-26-0.25/README.html">
     octave-resnet-26-0.25
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/open-closed-eye-0001/README.html">
     open-closed-eye-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/pelee-coco/README.html">
     pelee-coco
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/pspnet-pytorch/README.html">
     pspnet-pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/quartznet-15x5-en/README.html">
     quartznet-15x5-en
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/regnetx-3.2gf/README.html">
     regnetx-3.2gf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/repvgg-a0/README.html">
     repvgg-a0
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/repvgg-b1/README.html">
     repvgg-b1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/repvgg-b3/README.html">
     repvgg-b3
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/resnest-50-pytorch/README.html">
     resnest-50-pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/resnet-18-pytorch/README.html">
     resnet-18-pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/resnet-34-pytorch/README.html">
     resnet-34-pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/resnet-50-pytorch/README.html">
     resnet-50-pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/resnet-50-tf/README.html">
     resnet-50-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/retinaface-resnet50-pytorch/README.html">
     retinaface-resnet50-pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/retinanet-tf/README.html">
     retinanet-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/rexnet-v1-x1.0/README.html">
     rexnet-v1-x1.0
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/rfcn-resnet101-coco-tf/README.html">
     rfcn-resnet101-coco-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/robust-video-matting-mobilenetv3/README.html">
     robust-video-matting-mobilenetv3
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/se-inception/README.html">
     se-inception
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/se-resnet-50/README.html">
     se-resnet-50
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/se-resnext-50/README.html">
     se-resnext-50
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/shufflenet-v2-x0.5/README.html">
     shufflenet-v2-x0.5
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/shufflenet-v2-x1.0/README.html">
     shufflenet-v2-x1.0
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/single-human-pose-estimation-0001/README.html">
     single-human-pose-estimation-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/squeezenet1.0/README.html">
     squeezenet1.0
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/squeezenet1.1/README.html">
     squeezenet1.1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/ssd-resnet34-1200-onnx/README.html">
     ssd-resnet34-1200-onnx
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/ssd300/README.html">
     ssd300
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/ssd512/README.html">
     ssd512
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/ssd_mobilenet_v1_coco/README.html">
     ssd_mobilenet_v1_coco
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/ssd_mobilenet_v1_fpn_coco/README.html">
     ssd_mobilenet_v1_fpn_coco
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/ssdlite_mobilenet_v2/README.html">
     ssdlite_mobilenet_v2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/swin-tiny-patch4-window7-224/README.html">
     swin-tiny-patch4-window7-224
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/t2t-vit-14/README.html">
     t2t-vit-14
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/text-recognition-resnet-fc/README.html">
     text-recognition-resnet-fc
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/ultra-lightweight-face-detection-rfb-320/README.html">
     ultra-lightweight-face-detection-rfb-320
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/ultra-lightweight-face-detection-slim-320/README.html">
     ultra-lightweight-face-detection-slim-320
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/vehicle-license-plate-detection-barrier-0123/README.html">
     vehicle-license-plate-detection-barrier-0123
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/vehicle-reid-0001/README.html">
     vehicle-reid-0001
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/vgg16/README.html">
     vgg16
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/vgg19/README.html">
     vgg19
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/vitstr-small-patch16-224/README.html">
     vitstr-small-patch16-224
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/wav2vec2-base/README.html">
     wav2vec2-base
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/wavernn/README.html">
     wavernn (composite)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/yolact-resnet50-fpn-pytorch/README.html">
     yolact-resnet50-fpn-pytorch
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/yolo-v1-tiny-tf/README.html">
     yolo-v1-tiny-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/yolo-v2-tf/README.html">
     yolo-v2-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/yolo-v2-tiny-tf/README.html">
     yolo-v2-tiny-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/yolo-v3-onnx/README.html">
     yolo-v3-onnx
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/yolo-v3-tf/README.html">
     yolo-v3-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/yolo-v3-tiny-onnx/README.html">
     yolo-v3-tiny-onnx
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/yolo-v3-tiny-tf/README.html">
     yolo-v3-tiny-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/yolo-v4-tf/README.html">
     yolo-v4-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/yolo-v4-tiny-tf/README.html">
     yolo-v4-tiny-tf
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/yolof/README.html">
     yolof
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../../models/public/yolox-tiny/README.html">
     yolox-tiny
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Demo Applications
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../../README.html">
   Open Model Zoo Demos
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="../../3d_segmentation_demo/python/README.html">
     3D Segmentation Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../action_recognition_demo/python/README.html">
     Action Recognition Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../background_subtraction_demo/cpp_gapi/README.html">
     G-API Background Subtraction Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../background_subtraction_demo/python/README.html">
     Background subtraction Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../bert_named_entity_recognition_demo/python/README.html">
     BERT Named Entity Recognition Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../bert_question_answering_demo/python/README.html">
     BERT Question Answering Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../bert_question_answering_embedding_demo/python/README.html">
     BERT Question Answering Embedding Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../classification_benchmark_demo/cpp/README.html">
     Classification Benchmark C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../classification_demo/python/README.html">
     Classification Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../colorization_demo/python/README.html">
     Colorization Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../crossroad_camera_demo/cpp/README.html">
     Crossroad Camera C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../deblurring_demo/python/README.html">
     Image Deblurring Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../face_detection_mtcnn_demo/cpp_gapi/README.html">
     G-API Face Detection MTCNN Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../face_detection_mtcnn_demo/python/README.html">
     Face Detection MTCNN Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../face_recognition_demo/python/README.html">
     Face Recognition Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../formula_recognition_demo/python/README.html">
     Formula Recognition Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../gaze_estimation_demo/cpp/README.html">
     Gaze Estimation Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../gaze_estimation_demo/cpp_gapi/README.html">
     G-API Gaze Estimation Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../gesture_recognition_demo/cpp_gapi/README.html">
     G-API Gesture Recognition Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../gesture_recognition_demo/python/README.html">
     Gesture Recognition Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../gpt2_text_prediction_demo/python/README.html">
     GPT-2 Text Prediction Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../handwritten_text_recognition_demo/python/README.html">
     Handwritten Text Recognition Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../human_pose_estimation_3d_demo/python/README.html">
     3D Human Pose Estimation Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../human_pose_estimation_demo/cpp/README.html">
     Human Pose Estimation C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../human_pose_estimation_demo/python/README.html">
     Human Pose Estimation Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../image_inpainting_demo/python/README.html">
     Image Inpainting Python Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../image_processing_demo/cpp/README.html">
     Image Processing C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../image_retrieval_demo/python/README.html">
     Image Retrieval Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../image_translation_demo/python/README.html">
     Image Translation Demo
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Instance Segmentation Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../interactive_face_detection_demo/cpp/README.html">
     Interactive Face Detection C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../interactive_face_detection_demo/cpp_gapi/README.html">
     G-API Interactive Face Detection Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../machine_translation_demo/python/README.html">
     Machine Translation Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../mask_rcnn_demo/cpp/README.html">
     TensorFlow* Object Detection Mask R-CNNs Segmentation C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../monodepth_demo/python/README.html">
     MonoDepth Python Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../mri_reconstruction_demo/cpp/README.html">
     MRI Reconstruction C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../mri_reconstruction_demo/python/README.html">
     MRI Reconstruction Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../multi_camera_multi_target_tracking_demo/python/README.html">
     Multi Camera Multi Target Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../multi_channel_face_detection_demo/cpp/README.html">
     Multi-Channel Face Detection C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../multi_channel_human_pose_estimation_demo/cpp/README.html">
     Multi-Channel Human Pose Estimation C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../multi_channel_object_detection_demo_yolov3/cpp/README.html">
     Multi-Channel Object Detection Yolov3 C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../noise_suppression_demo/cpp/README.html">
     Noise Suppression C++* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../noise_suppression_demo/python/README.html">
     Noise Suppression Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../object_detection_demo/cpp/README.html">
     Object Detection C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../object_detection_demo/python/README.html">
     Object Detection Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../pedestrian_tracker_demo/cpp/README.html">
     Pedestrian Tracker C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../place_recognition_demo/python/README.html">
     Place Recognition Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../security_barrier_camera_demo/cpp/README.html">
     Security Barrier Camera C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../segmentation_demo/cpp/README.html">
     Image Segmentation C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../segmentation_demo/python/README.html">
     Image Segmentation Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../single_human_pose_estimation_demo/python/README.html">
     Single Human Pose Estimation Demo (top-down pipeline)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../smart_classroom_demo/cpp/README.html">
     Smart Classroom C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../smart_classroom_demo/cpp_gapi/README.html">
     Smart Classroom C++ G-API Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../smartlab_demo/python/README.html">
     Smartlab Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../social_distance_demo/cpp/README.html">
     Social Distance C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../sound_classification_demo/python/README.html">
     Sound Classification Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../speech_recognition_deepspeech_demo/python/README.html">
     Speech Recognition DeepSpeech Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../speech_recognition_quartznet_demo/python/README.html">
     Speech Recognition QuartzNet Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../speech_recognition_wav2vec_demo/python/README.html">
     Speech Recognition Wav2Vec Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../text_detection_demo/cpp/README.html">
     Text Detection C++ Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../text_spotting_demo/python/README.html">
     Text Spotting Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../text_to_speech_demo/python/README.html">
     Text-to-speech Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../time_series_forecasting_demo/python/README.html">
     Time Series Forecasting Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../whiteboard_inpainting_demo/python/README.html">
     Whiteboard Inpainting Python* Demo
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../common/python/openvino/model_zoo/model_api/adapters/ovms_adapter.html">
     OpenVINO Model Server Adapter
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Model API
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../common/python/openvino/model_zoo/model_api/adapters/ovms_adapter.html">
   OpenVINO Model Server Adapter
  </a>
 </li>
</ul>

  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-it-works">
   How It Works
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-api">
   Model API
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#preparing-to-run">
   Preparing to Run
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#supported-models">
     Supported Models
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#running">
   Running
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#running-with-openvino-model-server">
   Running with OpenVINO Model Server
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#demo-output">
   Demo Output
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#see-also">
   See Also
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                <div class="tocsection download-docs">
  <div class="dropdown sst-dropdown">
    <button class="button bttn-prm button-size-m" data-display="static" type="button" id="download-options"
      data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
      Download Docs
    </button>
    <div class="dropdown-menu" aria-labelledby="download-options">
      <a class="dropdown-item" href="#" onclick="window.print()">.pdf</a>
      <a id="download-zip-btn" class="dropdown-item" href="#">.zip</a>
    </div>
  </div>
</div>
              </div>
              
            
          </div>
          

          
          
              
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">

<div class="tocsection editthispage">
    <a href="None">
        <i class="fas fa-pencil-alt"></i> Edit this page
    </a>
</div>

            
                <div>
                  
  <section id="instance-segmentation-python-demo">
<h1>Instance Segmentation Python* Demo<a class="headerlink" href="#instance-segmentation-python-demo" title="Permalink to this headline">Â¶</a></h1>
<p><img alt="example" src="../../../_images/instance_segmentation.gif" /></p>
<p>This demo shows how to perform instance segmentation using OpenVINO.</p>
<blockquote>
<div><p><strong>NOTE</strong>: Only batch size of 1 is supported.</p>
</div></blockquote>
<section id="how-it-works">
<h2>How It Works<a class="headerlink" href="#how-it-works" title="Permalink to this headline">Â¶</a></h2>
<p>The demo application expects an instance segmentation model in the Intermediate Representation (IR) format with the following constraints:</p>
<ol class="arabic simple">
<li><p>for instance segmentation models based on <code class="docutils literal notranslate"><span class="pre">Mask</span> <span class="pre">RCNN</span></code> approach:</p>
<ul class="simple">
<li><p>Two inputs: <code class="docutils literal notranslate"><span class="pre">im_data</span></code> for input image and <code class="docutils literal notranslate"><span class="pre">im_info</span></code> for meta-information about the image (actual height, width and scale).</p></li>
<li><p>At least four outputs including:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">boxes</span></code> with absolute bounding box coordinates of the input image</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scores</span></code> with confidence scores for all bounding boxes</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">classes</span></code> with object class IDs for all bounding boxes</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">raw_masks</span></code> with fixed-size segmentation heat maps for all classes of all bounding boxes</p></li>
</ul>
</li>
</ul>
</li>
<li><p>for instance segmentation models based on <code class="docutils literal notranslate"><span class="pre">YOLACT</span></code> approach:</p>
<ul class="simple">
<li><p>Single input for input image.</p></li>
<li><p>At least four outputs including:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">boxes</span></code> with normalized in [0, 1] range bounding box coordinates</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">conf</span></code> with confidence scores for each class for all boxes</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mask</span></code> with fixed-size mask channels for all boxes.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">proto</span></code> with fixed-size segmentation heat maps prototypes for all boxes.</p></li>
</ul>
</li>
</ul>
</li>
</ol>
<p>As input, the demo application accepts a path to a single image file, a video file or a numeric ID of a web camera specified with a command-line argument <code class="docutils literal notranslate"><span class="pre">-i</span></code></p>
<p>The demo workflow is the following:</p>
<ol class="arabic simple">
<li><p>The demo application reads image/video frames one by one, resizes them to fit into the input image blob of the network (<code class="docutils literal notranslate"><span class="pre">im_data</span></code>).</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">im_info</span></code> input blob passes resulting resolution and scale of a pre-processed image to the network to perform inference if network has <code class="docutils literal notranslate"><span class="pre">im_info</span></code> input.</p></li>
<li><p>The demo visualizes the resulting instance segmentation masks. Certain command-line options affect the visualization:</p>
<ul class="simple">
<li><p>If you specify <code class="docutils literal notranslate"><span class="pre">--show_boxes</span></code> and <code class="docutils literal notranslate"><span class="pre">--show_scores</span></code> arguments, bounding boxes and confidence scores are also shown.</p></li>
<li><p>By default, tracking is used to show object instance with the same color throughout the whole video.
It assumes more or less static scene with instances in two frames being a part of the same track if intersection over union of the masks is greater than the 0.5 threshold. To disable tracking, specify the <code class="docutils literal notranslate"><span class="pre">--no_track</span></code> argument.</p></li>
</ul>
</li>
</ol>
<blockquote>
<div><p><strong>NOTE</strong>: By default, Open Model Zoo demos expect input with BGR channels order. If you trained your model to work with RGB order, you need to manually rearrange the default channels order in the demo application or reconvert your model using the Model Optimizer tool with the <code class="docutils literal notranslate"><span class="pre">--reverse_input_channels</span></code> argument specified. For more information about the argument, refer to <strong>When to Reverse Input Channels</strong> section of [Embedding Preprocessing Computation](&#64;ref openvino_docs_MO_DG_Additional_Optimization_Use_Cases).</p>
</div></blockquote>
</section>
<section id="model-api">
<h2>Model API<a class="headerlink" href="#model-api" title="Permalink to this headline">Â¶</a></h2>
<p>The demo utilizes model wrappers, adapters and pipelines from <a class="reference internal" href="../../common/python/openvino/model_zoo/model_api/README.html"><span class="doc std std-doc">Python* Model API</span></a>.</p>
<p>The generalized interface of wrappers with its unified results representation provides the support of multiple different instance segmentation model topologies in one demo.</p>
</section>
<section id="preparing-to-run">
<h2>Preparing to Run<a class="headerlink" href="#preparing-to-run" title="Permalink to this headline">Â¶</a></h2>
<p>For demo input image or video files, refer to the section <strong>Media Files Available for Demos</strong> in the <a class="reference internal" href="../../README.html"><span class="doc std std-doc">Open Model Zoo Demos Overview</span></a>.
The list of models supported by the demo is in <code class="docutils literal notranslate"><span class="pre">&lt;omz_dir&gt;/demos/instance_segmentation_demo/python/models.lst</span></code> file.
This file can be used as a parameter for <span class="xref myst">Model Downloader</span> and Converter to download and, if necessary, convert models to OpenVINO IR format (*.xml + *.bin).</p>
<p>An example of using the Model Downloader:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>omz_downloader --list models.lst
</pre></div>
</div>
<p>An example of using the Model Converter:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>omz_converter --list models.lst
</pre></div>
</div>
<section id="supported-models">
<h3>Supported Models<a class="headerlink" href="#supported-models" title="Permalink to this headline">Â¶</a></h3>
<ul class="simple">
<li><p>instance-segmentation-person-0007</p></li>
<li><p>instance-segmentation-security-0002</p></li>
<li><p>instance-segmentation-security-0091</p></li>
<li><p>instance-segmentation-security-0228</p></li>
<li><p>instance-segmentation-security-1039</p></li>
<li><p>instance-segmentation-security-1040</p></li>
<li><p>yolact-resnet50-fpn-pytorch</p></li>
</ul>
<blockquote>
<div><p><strong>NOTE</strong>: Refer to the tables <a class="reference internal" href="../../../models/intel/device_support.html"><span class="doc std std-doc">Intelâ€™s Pre-Trained Models Device Support</span></a> and <a class="reference internal" href="../../../models/public/device_support.html"><span class="doc std std-doc">Public Pre-Trained Models Device Support</span></a> for the details on models inference support at different devices.</p>
</div></blockquote>
</section>
</section>
<section id="running">
<h2>Running<a class="headerlink" href="#running" title="Permalink to this headline">Â¶</a></h2>
<p>Running the demo with <code class="docutils literal notranslate"><span class="pre">-h</span></code> shows this help message:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">usage</span><span class="p">:</span> <span class="n">instance_segmentation_demo</span><span class="o">.</span><span class="n">py</span> <span class="p">[</span><span class="o">-</span><span class="n">h</span><span class="p">]</span> <span class="o">-</span><span class="n">m</span> <span class="n">MODEL</span> <span class="p">[</span><span class="o">--</span><span class="n">adapter</span> <span class="p">{</span><span class="n">openvino</span><span class="p">,</span><span class="n">ovms</span><span class="p">}]</span> <span class="o">-</span><span class="n">i</span> <span class="n">INPUT</span> <span class="p">[</span><span class="o">-</span><span class="n">d</span> <span class="n">DEVICE</span><span class="p">]</span> <span class="o">--</span><span class="n">labels</span> <span class="n">LABELS</span> <span class="p">[</span><span class="o">-</span><span class="n">t</span> <span class="n">PROB_THRESHOLD</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">no_track</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">show_scores</span><span class="p">]</span>
                                     <span class="p">[</span><span class="o">--</span><span class="n">show_boxes</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">layout</span> <span class="n">LAYOUT</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">nireq</span> <span class="n">NUM_INFER_REQUESTS</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">nstreams</span> <span class="n">NUM_STREAMS</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">nthreads</span> <span class="n">NUM_THREADS</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">loop</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">o</span> <span class="n">OUTPUT</span><span class="p">]</span>
                                     <span class="p">[</span><span class="o">-</span><span class="n">limit</span> <span class="n">OUTPUT_LIMIT</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">no_show</span><span class="p">]</span> <span class="p">[</span><span class="o">--</span><span class="n">output_resolution</span> <span class="n">OUTPUT_RESOLUTION</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">u</span> <span class="n">UTILIZATION_MONITORS</span><span class="p">]</span> <span class="p">[</span><span class="o">-</span><span class="n">r</span><span class="p">]</span>

<span class="n">optional</span> <span class="n">arguments</span><span class="p">:</span>
  <span class="o">-</span><span class="n">h</span><span class="p">,</span> <span class="o">--</span><span class="n">help</span>            <span class="n">show</span> <span class="n">this</span> <span class="n">help</span> <span class="n">message</span> <span class="ow">and</span> <span class="n">exitz</span>

<span class="n">Options</span><span class="p">:</span>
  <span class="o">-</span><span class="n">m</span> <span class="n">MODEL</span><span class="p">,</span> <span class="o">--</span><span class="n">model</span> <span class="n">MODEL</span>
                        <span class="n">Required</span><span class="o">.</span> <span class="n">Path</span> <span class="n">to</span> <span class="n">an</span> <span class="o">.</span><span class="n">xml</span> <span class="n">file</span> <span class="k">with</span> <span class="n">a</span> <span class="n">trained</span> <span class="n">model</span> <span class="ow">or</span> <span class="n">address</span> <span class="n">of</span> <span class="n">model</span> <span class="n">inference</span> <span class="n">service</span> <span class="k">if</span> <span class="n">using</span> <span class="n">ovms</span> <span class="n">adapter</span><span class="o">.</span>
  <span class="o">--</span><span class="n">adapter</span> <span class="p">{</span><span class="n">openvino</span><span class="p">,</span><span class="n">ovms</span><span class="p">}</span>
                        <span class="n">Optional</span><span class="o">.</span> <span class="n">Specify</span> <span class="n">the</span> <span class="n">model</span> <span class="n">adapter</span><span class="o">.</span> <span class="n">Default</span> <span class="ow">is</span> <span class="n">openvino</span><span class="o">.</span>
  <span class="o">-</span><span class="n">i</span> <span class="n">INPUT</span><span class="p">,</span> <span class="o">--</span><span class="nb">input</span> <span class="n">INPUT</span>
                        <span class="n">Required</span><span class="o">.</span> <span class="n">An</span> <span class="nb">input</span> <span class="n">to</span> <span class="n">process</span><span class="o">.</span> <span class="n">The</span> <span class="nb">input</span> <span class="n">must</span> <span class="n">be</span> <span class="n">a</span> <span class="n">single</span> <span class="n">image</span><span class="p">,</span> <span class="n">a</span> <span class="n">folder</span> <span class="n">of</span> <span class="n">images</span><span class="p">,</span> <span class="n">video</span> <span class="n">file</span> <span class="ow">or</span> <span class="n">camera</span> <span class="nb">id</span><span class="o">.</span>
  <span class="o">-</span><span class="n">d</span> <span class="n">DEVICE</span><span class="p">,</span> <span class="o">--</span><span class="n">device</span> <span class="n">DEVICE</span>
                        <span class="n">Optional</span><span class="o">.</span> <span class="n">Specify</span> <span class="n">the</span> <span class="n">target</span> <span class="n">device</span> <span class="n">to</span> <span class="n">infer</span> <span class="n">on</span><span class="p">;</span> <span class="n">CPU</span><span class="p">,</span> <span class="n">GPU</span><span class="p">,</span> <span class="n">HDDL</span> <span class="ow">or</span> <span class="n">MYRIAD</span> <span class="ow">is</span> <span class="n">acceptable</span><span class="o">.</span> <span class="n">The</span> <span class="n">demo</span> <span class="n">will</span> <span class="n">look</span> <span class="k">for</span> <span class="n">a</span> <span class="n">suitable</span> <span class="n">plugin</span> <span class="k">for</span> <span class="n">device</span>
                        <span class="n">specified</span><span class="o">.</span> <span class="n">Default</span> <span class="n">value</span> <span class="ow">is</span> <span class="n">CPU</span><span class="o">.</span>

<span class="n">Common</span> <span class="n">model</span> <span class="n">options</span><span class="p">:</span>
  <span class="o">--</span><span class="n">labels</span> <span class="n">LABELS</span>       <span class="n">Required</span><span class="o">.</span> <span class="n">Path</span> <span class="n">to</span> <span class="n">a</span> <span class="n">text</span> <span class="n">file</span> <span class="k">with</span> <span class="k">class</span> <span class="nc">labels</span><span class="o">.</span>
  <span class="o">-</span><span class="n">t</span> <span class="n">PROB_THRESHOLD</span><span class="p">,</span> <span class="o">--</span><span class="n">prob_threshold</span> <span class="n">PROB_THRESHOLD</span>
                        <span class="n">Optional</span><span class="o">.</span> <span class="n">Probability</span> <span class="n">threshold</span> <span class="k">for</span> <span class="n">detections</span> <span class="n">filtering</span><span class="o">.</span>
  <span class="o">--</span><span class="n">no_track</span>            <span class="n">Optional</span><span class="o">.</span> <span class="n">Disable</span> <span class="nb">object</span> <span class="n">tracking</span> <span class="k">for</span> <span class="n">video</span><span class="o">/</span><span class="n">camera</span> <span class="nb">input</span><span class="o">.</span>
  <span class="o">--</span><span class="n">show_scores</span>         <span class="n">Optional</span><span class="o">.</span> <span class="n">Show</span> <span class="n">detection</span> <span class="n">scores</span><span class="o">.</span>
  <span class="o">--</span><span class="n">show_boxes</span>          <span class="n">Optional</span><span class="o">.</span> <span class="n">Show</span> <span class="n">bounding</span> <span class="n">boxes</span><span class="o">.</span>
  <span class="o">--</span><span class="n">layout</span> <span class="n">LAYOUT</span>       <span class="n">Optional</span><span class="o">.</span> <span class="n">Model</span> <span class="n">inputs</span> <span class="n">layouts</span><span class="o">.</span> <span class="n">Format</span> <span class="s2">&quot;[&lt;layout&gt;]&quot;</span> <span class="ow">or</span> <span class="s2">&quot;&lt;input1&gt;[&lt;layout1&gt;],&lt;input2&gt;[&lt;layout2&gt;]&quot;</span> <span class="ow">in</span> <span class="n">case</span> <span class="n">of</span> <span class="n">more</span> <span class="n">than</span> <span class="n">one</span> <span class="nb">input</span><span class="o">.</span> <span class="n">To</span> <span class="n">define</span>
                        <span class="n">layout</span> <span class="n">you</span> <span class="n">should</span> <span class="n">use</span> <span class="n">only</span> <span class="n">capital</span> <span class="n">letters</span>

<span class="n">Inference</span> <span class="n">options</span><span class="p">:</span>
  <span class="o">-</span><span class="n">nireq</span> <span class="n">NUM_INFER_REQUESTS</span><span class="p">,</span> <span class="o">--</span><span class="n">num_infer_requests</span> <span class="n">NUM_INFER_REQUESTS</span>
                        <span class="n">Optional</span><span class="o">.</span> <span class="n">Number</span> <span class="n">of</span> <span class="n">infer</span> <span class="n">requests</span>
  <span class="o">-</span><span class="n">nstreams</span> <span class="n">NUM_STREAMS</span><span class="p">,</span> <span class="o">--</span><span class="n">num_streams</span> <span class="n">NUM_STREAMS</span>
                        <span class="n">Optional</span><span class="o">.</span> <span class="n">Number</span> <span class="n">of</span> <span class="n">streams</span> <span class="n">to</span> <span class="n">use</span> <span class="k">for</span> <span class="n">inference</span> <span class="n">on</span> <span class="n">the</span> <span class="n">CPU</span> <span class="ow">or</span><span class="o">/</span><span class="ow">and</span> <span class="n">GPU</span> <span class="ow">in</span> <span class="n">throughput</span> <span class="n">mode</span> <span class="p">(</span><span class="k">for</span> <span class="n">HETERO</span> <span class="ow">and</span> <span class="n">MULTI</span> <span class="n">device</span> <span class="n">cases</span> <span class="n">use</span> <span class="nb">format</span>
                        <span class="o">&lt;</span><span class="n">device1</span><span class="o">&gt;</span><span class="p">:</span><span class="o">&lt;</span><span class="n">nstreams1</span><span class="o">&gt;</span><span class="p">,</span><span class="o">&lt;</span><span class="n">device2</span><span class="o">&gt;</span><span class="p">:</span><span class="o">&lt;</span><span class="n">nstreams2</span><span class="o">&gt;</span> <span class="ow">or</span> <span class="n">just</span> <span class="o">&lt;</span><span class="n">nstreams</span><span class="o">&gt;</span><span class="p">)</span><span class="o">.</span>
  <span class="o">-</span><span class="n">nthreads</span> <span class="n">NUM_THREADS</span><span class="p">,</span> <span class="o">--</span><span class="n">num_threads</span> <span class="n">NUM_THREADS</span>
                        <span class="n">Optional</span><span class="o">.</span> <span class="n">Number</span> <span class="n">of</span> <span class="n">threads</span> <span class="n">to</span> <span class="n">use</span> <span class="k">for</span> <span class="n">inference</span> <span class="n">on</span> <span class="n">CPU</span> <span class="p">(</span><span class="n">including</span> <span class="n">HETERO</span> <span class="n">cases</span><span class="p">)</span><span class="o">.</span>

<span class="n">Input</span><span class="o">/</span><span class="n">output</span> <span class="n">options</span><span class="p">:</span>
  <span class="o">--</span><span class="n">loop</span>                <span class="n">Optional</span><span class="o">.</span> <span class="n">Enable</span> <span class="n">reading</span> <span class="n">the</span> <span class="nb">input</span> <span class="ow">in</span> <span class="n">a</span> <span class="n">loop</span><span class="o">.</span>
  <span class="o">-</span><span class="n">o</span> <span class="n">OUTPUT</span><span class="p">,</span> <span class="o">--</span><span class="n">output</span> <span class="n">OUTPUT</span>
                        <span class="n">Optional</span><span class="o">.</span> <span class="n">Name</span> <span class="n">of</span> <span class="n">the</span> <span class="n">output</span> <span class="n">file</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="n">to</span> <span class="n">save</span><span class="o">.</span>
  <span class="o">-</span><span class="n">limit</span> <span class="n">OUTPUT_LIMIT</span><span class="p">,</span> <span class="o">--</span><span class="n">output_limit</span> <span class="n">OUTPUT_LIMIT</span>
                        <span class="n">Optional</span><span class="o">.</span> <span class="n">Number</span> <span class="n">of</span> <span class="n">frames</span> <span class="n">to</span> <span class="n">store</span> <span class="ow">in</span> <span class="n">output</span><span class="o">.</span> <span class="n">If</span> <span class="mi">0</span> <span class="ow">is</span> <span class="nb">set</span><span class="p">,</span> <span class="nb">all</span> <span class="n">frames</span> <span class="n">are</span> <span class="n">stored</span><span class="o">.</span>
  <span class="o">--</span><span class="n">no_show</span>             <span class="n">Optional</span><span class="o">.</span> <span class="n">Don</span><span class="s1">&#39;t show output.</span>
  <span class="o">--</span><span class="n">output_resolution</span> <span class="n">OUTPUT_RESOLUTION</span>
                        <span class="n">Optional</span><span class="o">.</span> <span class="n">Specify</span> <span class="n">the</span> <span class="n">maximum</span> <span class="n">output</span> <span class="n">window</span> <span class="n">resolution</span> <span class="ow">in</span> <span class="p">(</span><span class="n">width</span> <span class="n">x</span> <span class="n">height</span><span class="p">)</span> <span class="nb">format</span><span class="o">.</span> <span class="n">Example</span><span class="p">:</span> <span class="mi">1280</span><span class="n">x720</span><span class="o">.</span> <span class="n">Input</span> <span class="n">frame</span> <span class="n">size</span> <span class="n">used</span> <span class="n">by</span> <span class="n">default</span><span class="o">.</span>
  <span class="o">-</span><span class="n">u</span> <span class="n">UTILIZATION_MONITORS</span><span class="p">,</span> <span class="o">--</span><span class="n">utilization_monitors</span> <span class="n">UTILIZATION_MONITORS</span>
                        <span class="n">Optional</span><span class="o">.</span> <span class="n">List</span> <span class="n">of</span> <span class="n">monitors</span> <span class="n">to</span> <span class="n">show</span> <span class="n">initially</span><span class="o">.</span>

<span class="n">Debug</span> <span class="n">options</span><span class="p">:</span>
  <span class="o">-</span><span class="n">r</span><span class="p">,</span> <span class="o">--</span><span class="n">raw_output_message</span>
                        <span class="n">Optional</span><span class="o">.</span> <span class="n">Output</span> <span class="n">inference</span> <span class="n">results</span> <span class="n">raw</span> <span class="n">values</span> <span class="n">showing</span><span class="o">.</span>
</pre></div>
</div>
<p>To run the demo, please provide paths to the model in the IR format, to a file with class labels, and to an input video, image, or folder with images:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3 instance_segmentation_demo/instance_segmentation_demo.py <span class="se">\</span>
    -m &lt;path_to_model&gt;/instance-segmentation-security-0228.xml <span class="se">\</span>
    --label &lt;omz_dir&gt;/data/dataset_classes/coco_80cl_bkgr.txt <span class="se">\</span>
    -i <span class="m">0</span>
</pre></div>
</div>
<blockquote>
<div><p><strong>NOTE</strong>: If you provide a single image as an input, the demo processes and renders it quickly, then exits. To continuously visualize inference results on the screen, apply the <code class="docutils literal notranslate"><span class="pre">loop</span></code> option, which enforces processing a single image in a loop.</p>
</div></blockquote>
<p>You can save processed results to a Motion JPEG AVI file or separate JPEG or PNG files using the <code class="docutils literal notranslate"><span class="pre">-o</span></code> option:</p>
<ul class="simple">
<li><p>To save processed results in an AVI file, specify the name of the output file with <code class="docutils literal notranslate"><span class="pre">avi</span></code> extension, for example: <code class="docutils literal notranslate"><span class="pre">-o</span> <span class="pre">output.avi</span></code>.</p></li>
<li><p>To save processed results as images, specify the template name of the output image file with <code class="docutils literal notranslate"><span class="pre">jpg</span></code> or <code class="docutils literal notranslate"><span class="pre">png</span></code> extension, for example: <code class="docutils literal notranslate"><span class="pre">-o</span> <span class="pre">output_%03d.jpg</span></code>. The actual file names are constructed from the template at runtime by replacing regular expression <code class="docutils literal notranslate"><span class="pre">%03d</span></code> with the frame number, resulting in the following: <code class="docutils literal notranslate"><span class="pre">output_000.jpg</span></code>, <code class="docutils literal notranslate"><span class="pre">output_001.jpg</span></code>, and so on.
To avoid disk space overrun in case of continuous input stream, like camera, you can limit the amount of data stored in the output file(s) with the <code class="docutils literal notranslate"><span class="pre">limit</span></code> option. The default value is 1000. To change it, you can apply the <code class="docutils literal notranslate"><span class="pre">-limit</span> <span class="pre">N</span></code> option, where <code class="docutils literal notranslate"><span class="pre">N</span></code> is the number of frames to store.</p></li>
</ul>
<blockquote>
<div><p><strong>NOTE</strong>: Windows* systems may not have the Motion JPEG codec installed by default. If this is the case, you can download OpenCV FFMPEG back end using the PowerShell script provided with the OpenVINO â„¢ install package and located at <code class="docutils literal notranslate"><span class="pre">&lt;INSTALL_DIR&gt;/opencv/ffmpeg-download.ps1</span></code>. The script should be run with administrative privileges if OpenVINO â„¢ is installed in a system protected folder (this is a typical case). Alternatively, you can save results as images.</p>
</div></blockquote>
</section>
<section id="running-with-openvino-model-server">
<h2>Running with OpenVINO Model Server<a class="headerlink" href="#running-with-openvino-model-server" title="Permalink to this headline">Â¶</a></h2>
<p>You can also run this demo with model served in <a class="reference external" href="https://github.com/openvinotoolkit/model_server">OpenVINO Model Server</a>. Refer to <a class="reference internal" href="../../common/python/openvino/model_zoo/model_api/adapters/ovms_adapter.html"><span class="doc std std-doc"><code class="docutils literal notranslate"><span class="pre">OVMSAdapter</span></code></span></a> to learn about running demos with OVMS.</p>
<p>Exemplary command:</p>
<div class="highlight-sh notranslate"><div class="highlight"><pre><span></span>python3 instance_segmentation_demo/instance_segmentation_demo.py <span class="se">\</span>
    -m localhost:9000/models/instance_segmentation <span class="se">\</span>
    --label &lt;omz_dir&gt;/data/dataset_classes/coco_80cl_bkgr.txt <span class="se">\</span>
    -i <span class="m">0</span>
    --adapter ovms
</pre></div>
</div>
</section>
<section id="demo-output">
<h2>Demo Output<a class="headerlink" href="#demo-output" title="Permalink to this headline">Â¶</a></h2>
<p>The application uses OpenCV to display resulting instance segmentation masks.
The demo reports</p>
<ul class="simple">
<li><p><strong>FPS</strong>: average rate of video frame processing (frames per second).</p></li>
<li><p><strong>Latency</strong>: average time required to process one frame (from reading the frame to displaying the results).</p></li>
<li><p>Latency for each of the following pipeline stages:</p>
<ul>
<li><p><strong>Decoding</strong> â€” capturing input data.</p></li>
<li><p><strong>Preprocessing</strong> â€” data preparation for inference.</p></li>
<li><p><strong>Inference</strong> â€” infering input data (images) and getting a result.</p></li>
<li><p><strong>Postrocessing</strong> â€” preparation inference result for output.</p></li>
<li><p><strong>Rendering</strong> â€” generating output image.</p></li>
</ul>
</li>
</ul>
<p>You can use these metrics to measure application-level performance.</p>
</section>
<section id="see-also">
<h2>See Also<a class="headerlink" href="#see-also" title="Permalink to this headline">Â¶</a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="../../README.html"><span class="doc std std-doc">Open Model Zoo Demos</span></a></p></li>
<li><p><a class="reference external" href="https://docs.openvino.ai/latest/openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html">Model Optimizer</a></p></li>
<li><p><span class="xref myst">Model Downloader</span></p></li>
</ul>
</section>
</section>


                </div>
            
            
                <div class='prev-next-bottom'>
                  
    <a class='button bttn-sec button-size-l' id="prev-link" href="../../image_translation_demo/python/README.html" title="previous page">Prev</a>
    <a class='button bttn-sec button-size-l' id="next-link" href="../../interactive_face_detection_demo/cpp/README.html" title="next page">Next</a>

                </div>
            
          </main>
          

      </div>
    </div>
  
  <script src="../../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, IntelÂ®.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.2.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>